{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>DataLab Cup 1: Text Feature Engineering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import joblib\n",
    "import threading\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. To load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/train.csv')\n",
    "test_data  = pd.read_csv('../dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. To extract the features from the dataset\n",
    "\n",
    "將一些我們想要用到的feature從dataset中提取出來。以下為提取的特徵:\n",
    "\n",
    "- title\n",
    "- time(year/month/day/hour/minute/second)\n",
    "- number of images (num_img)\n",
    "- number of videos (num_video)\n",
    "- author name\n",
    "- topic\n",
    "- channel\n",
    "- length of content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "* beautiful soup\n",
    "    - conda install -c conda-forge beautifulsoup4\n",
    "    \n",
    "<br>\n",
    "\n",
    "* vadersentiment\n",
    "    - conda install -c conda-forge vadersentiment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the attribute of the 'title', 'year/month/date/day/hour/minute/second/is_weekend', 'num_img', 'num_video', 'author name', 'topic', 'channel', 'content length', 'title_sentiment'\n",
    "\n",
    "def preprocessor(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "    # 1. to find the 'title' (body > h1)\n",
    "    title = soup.find('h1').string.strip().lower()\n",
    "\n",
    "    # 2. to find time(body > div > span > time)\n",
    "    \n",
    "    date_string = soup.find('time')\n",
    "    try:\n",
    "        date_string = date_string['datetime']\n",
    "    except:\n",
    "        date_string = 'wed, 10 oct 2014 15:00:43 +0000'\n",
    "        \n",
    "    date_string = date_string.strip().lower()\n",
    "    datetimes = datetime.strptime(date_string, '%a, %d %b %Y %H:%M:%S %z')\n",
    "    \n",
    "    year = datetimes.year\n",
    "    month = datetimes.month\n",
    "    date = datetimes.day\n",
    "    day = pd.Timestamp(str(year)+'-'+str(month)+'-'+str(date)).dayofweek+1\n",
    "    is_weekend = 1 if (day==6 or day==7) else 0\n",
    "    hour = datetimes.hour\n",
    "    minute = datetimes.minute\n",
    "    second = datetimes.second\n",
    "\n",
    "    # 3. to find the number of images\n",
    "    num_img  = len(soup.find_all('img'))\n",
    "    \n",
    "\n",
    "    # 4. to find the number of videos\n",
    "    num_video = len(soup.find_all('iframe'))\n",
    "    \n",
    "    # 5. to find the author name\n",
    "    article_info = soup.find('div', class_='article-info')\n",
    "    author = article_info.find('span', class_='author_name') or article_info.find('span', class_='byline basic')\n",
    "\n",
    "    if (author != None):\n",
    "        if (author.find('a') != None):\n",
    "            author = author.find('a')\n",
    "            author_name = author.get_text().lower()\n",
    "        else :\n",
    "            author_name = author.get_text().lower()\n",
    "    else :\n",
    "        author_name = 'not found'\n",
    "\n",
    "    # 6. to find the article topic\n",
    "    footer = soup.find('footer', class_='article-topics')\n",
    "    topic = footer.get_text().split(': ')[1]\n",
    "    \n",
    "    # 7. to find the channel\n",
    "    channel = soup.find('article')['data-channel'].strip().lower()\n",
    "    \n",
    "    \n",
    "    # 8. to find the content length\n",
    "    content = soup.body.find('section', class_='article-content').get_text()\n",
    "    len_content = len(content)\n",
    "\n",
    "    # print('topic = ', topic, type(topic))\n",
    "    \n",
    "    # 9. to find the sentiment of title\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    title_sentiment = analyzer.polarity_scores(topic)\n",
    "    sentiment_neg = title_sentiment['neg']\n",
    "    sentiment_neu = title_sentiment['neu']\n",
    "    sentiment_pos = title_sentiment['pos']\n",
    "    sentiment_compound = title_sentiment['compound']\n",
    "\n",
    "    return title, author_name, channel, topic, year, month, date, day, is_weekend, hour, minute, second, num_img, num_video, len_content, sentiment_neg, sentiment_neu, sentiment_pos, sentiment_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_list = []\n",
    "feature_test_list = []\n",
    "\n",
    "for content in (train_data['Page content']):\n",
    "    feature_train_list.append(preprocessor(content))\n",
    "for content in (test_data['Page content']):\n",
    "    feature_test_list.append(preprocessor(content))\n",
    "\n",
    "df_train_x = pd.DataFrame(\n",
    "        feature_train_list, \n",
    "                columns=['title', 'author_name', 'channel', 'topic', 'year', 'month', 'date', 'day', \\\n",
    "                 'is_weekend', 'hour', 'minute', 'second', 'num_img', 'num_video', 'len_content', \\\n",
    "                 'sentiment_neg', 'sentiment_neu', 'sentiment_pos', 'sentiment_compound']).values\n",
    "df_test_x = pd.DataFrame(\n",
    "        feature_test_list, \n",
    "        columns=['title', 'author_name', 'channel', 'topic', 'year', 'month', 'date', 'day', \\\n",
    "                 'is_weekend', 'hour', 'minute', 'second', 'num_img', 'num_video', 'len_content', \\\n",
    "                 'sentiment_neg', 'sentiment_neu', 'sentiment_pos', 'sentiment_compound']).values\n",
    "\n",
    "df_train_y = train_data['Popularity'].values\n",
    "df_train_y[df_train_y == -1] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 . Preprocessing - Word Stemming\n",
    "\n",
    " WordNetLemmatizer(Lemmatization): Stem the words will better performance, while time-consuming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /users/student/mr111//mfhsieh22/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /users/student/mr111//mfhsieh22/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def word_stemming(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    lm = WordNetLemmatizer()\n",
    "    words = re.split('\\s', text.strip())\n",
    "    lemmatized_words = [lm.lemmatize(word) for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-5 Create TF-IDF feature representation ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('drop process', 'drop', [0, 2, 10, 11, 12]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [3]),\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgb_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('drop process', 'drop', [0, 2, 10, 11, 12, 15, 16, 17, 18]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [3])\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n",
    "cat_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('drop process', 'drop', [0, 2, 10, 11, 12]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,1), lowercase=False), [3])\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n",
    "ada_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('drop process', 'drop', [0, 2, 10, 11, 12]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [3])\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfc_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('drop process', 'drop', [0, 2, 10, 11, 12]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [3])\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting_transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('title name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [0]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [1]),\n",
    "        ('channel name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [2]),\n",
    "        ('topic name process' , TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=(1,2), lowercase=False), [3])\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model training\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- CatBoost\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_xgb = Pipeline([('vect', xgb_transformer), ('clf', XGBClassifier())])\n",
    "# pipeline_lgb = Pipeline([('vect', lgb_transformer), ('clf',  LGBMClassifier())])\n",
    "# pipeline_cat = Pipeline([('vect', cat_transformer), ('clf',  CatBoostClassifier())])\n",
    "# pipeline_ada = Pipeline([('vect', ada_transformer), ('clf',  AdaBoostClassifier())])\n",
    "# pipeline_rfc = Pipeline([('vect', rfc_transformer), ('clf',  RandomForestClassifier())])\n",
    "pipeline_xgb = XGBClassifier()\n",
    "pipeline_lgb = LGBMClassifier()\n",
    "pipeline_cat = CatBoostClassifier()\n",
    "pipeline_ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=0))\n",
    "pipeline_rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(X_train, y_train, clf):\n",
    "\n",
    "    score = cross_validate(clf, X_train, y_train, scoring='roc_auc', return_train_score=True, return_estimator=True, cv=2)\n",
    "    print('train score: {:.6f} (+/-{:.6f})'.format(\n",
    "        np.mean(score['train_score']), np.std(score['train_score'])))\n",
    "    print('valid score: {:.6f} (+/-{:.6f})'.format(\n",
    "        np.mean(score['test_score']), np.std(score['test_score'])))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, np.mean(score['train_score']), np.mean(score['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To contruct the grid search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(ct, X_train, y_train, clf, param_grid, verbose_=False):\n",
    "    \n",
    "    X_train_ct = ct.fit_transform(X_train)\n",
    "    \n",
    "    # to report the grid search information\n",
    "    if(verbose_):\n",
    "        gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=2, return_train_score=True, verbose = 3)\n",
    "    else:\n",
    "        gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=5, return_train_score=True)\n",
    "    \n",
    "    gs.fit(X_train_ct, y_train)\n",
    "    \n",
    "    results, idx = gs.cv_results_, gs.best_index_\n",
    "    print('train score: {:.6f} (+/-{:.6f})'.format(results['mean_train_score'][idx], results['std_train_score'][idx]))\n",
    "    print('valid score: {:.6f} (+/-{:.6f})'.format(results['mean_test_score'][idx], results['std_test_score'][idx]))\n",
    "    print('best params:', gs.best_params_)\n",
    "    return gs.best_params_, gs.best_estimator_, results['mean_test_score'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - to store the best parameter to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_storage(dict_path, file_name, best_param, best_validation, remaining_dict, best_estimator_list=None):\n",
    "    if not os.path.exists(dict_path):\n",
    "        os.makedirs(dict_path)\n",
    "        \n",
    "    file_path = os.path.join(dict_path, file_name + \".txt\")\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(f'The features: {remaining_dict}\\n')\n",
    "        file.write(f'The best parameter: {best_param}\\n')\n",
    "        file.write(f'ngram_range : {ngram_range_}\\n')\n",
    "        if not (best_estimator_list==None):\n",
    "            file.write('The best estimator_list: ')\n",
    "            for i in range(len(best_estimator_list)):\n",
    "                file.write(f' {best_estimator_list[i][0]}')\n",
    "            file.write('\\n')\n",
    "        file.write(f'The best validation: {best_validation}\\n')\n",
    "        file.write('--------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1-1. Grid sizing for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END gamma=1.1, lambda=2.4, learning_rate=0.14, max_depth=7, n_estimators=97;, score=(train=0.821, test=0.584) total time=   8.7s\n",
      "[CV 2/2] END gamma=1.1, lambda=2.4, learning_rate=0.14, max_depth=7, n_estimators=97;, score=(train=0.825, test=0.585) total time=   8.8s\n",
      "train score: 0.823161 (+/-0.002146)\n",
      "valid score: 0.584373 (+/-0.000395)\n",
      "best params: {'gamma': 1.1, 'lambda': 2.4, 'learning_rate': 0.14, 'max_depth': 7, 'n_estimators': 97}\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'gamma' : [1.1],\n",
    "    'lambda' : [2.4],\n",
    "    'n_estimators': [97],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate' : [0.14],\n",
    "}\n",
    "\n",
    "if (1):\n",
    "    best_xgb_param, best_xgb, best_xgb_valid = grid_search_cv(xgb_transformer, df_train_x, df_train_y, pipeline_xgb, param_grid_xgb, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1-2. Training for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.783027 (+/-0.003699)\n",
      "valid score: 0.589135 (+/-0.005340)\n"
     ]
    }
   ],
   "source": [
    "param_static_xgb = {\n",
    "    'gamma' : 1.2,\n",
    "    'lambda' : 2.5,\n",
    "    'n_estimators': 97,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate' : 0.141,\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 0\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    xgboost = Pipeline([('vect', xgb_transformer), ('clf', best_xgb)])\n",
    "else :\n",
    "    xgboost = Pipeline([('vect', xgb_transformer), ('clf', XGBClassifier(**param_static_xgb))])\n",
    "    \n",
    "_ = training(df_train_x, df_train_y, xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-1. Grid sizing for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 2/2] END learning_rate=0.0131, n_estimators=230, objective=poisson;, score=(train=0.689, test=0.594) total time=   3.1s\n",
      "[CV 1/2] END learning_rate=0.0131, n_estimators=231, objective=regression;, score=(train=0.732, test=0.592) total time=   3.1s\n",
      "[CV 1/2] END learning_rate=0.0131, n_estimators=231, objective=poisson;, score=(train=0.690, test=0.592) total time=   3.2s\n",
      "[CV 2/2] END learning_rate=0.0131, n_estimators=230, objective=regression;, score=(train=0.731, test=0.591) total time=   3.2s\n",
      "[CV 2/2] END learning_rate=0.13, n_estimators=230, objective=regression;, score=(train=0.927, test=0.567) total time=   3.0s\n",
      "[CV 1/2] END learning_rate=0.0131, n_estimators=230, objective=poisson;, score=(train=0.690, test=0.592) total time=   3.3s\n",
      "[CV 2/2] END learning_rate=0.0131, n_estimators=231, objective=poisson;, score=(train=0.689, test=0.594) total time=   3.3s\n",
      "[CV 2/2] END learning_rate=0.0131, n_estimators=231, objective=regression;, score=(train=0.731, test=0.591) total time=   3.3s\n",
      "[CV 1/2] END learning_rate=0.0131, n_estimators=230, objective=regression;, score=(train=0.732, test=0.592) total time=   3.4s\n",
      "[CV 1/2] END learning_rate=0.13, n_estimators=231, objective=regression;, score=(train=0.932, test=0.569) total time=   3.1s\n",
      "[CV 2/2] END learning_rate=0.13, n_estimators=230, objective=poisson;, score=(train=0.869, test=0.580) total time=   3.2s\n",
      "[CV 2/2] END learning_rate=0.13, n_estimators=231, objective=regression;, score=(train=0.927, test=0.567) total time=   3.0s\n",
      "[CV 2/2] END learning_rate=0.13, n_estimators=231, objective=poisson;, score=(train=0.869, test=0.580) total time=   3.1s\n",
      "[CV 1/2] END learning_rate=0.13, n_estimators=230, objective=regression;, score=(train=0.931, test=0.569) total time=   3.1s\n",
      "[CV 1/2] END learning_rate=0.13, n_estimators=231, objective=poisson;, score=(train=0.872, test=0.576) total time=   3.2s\n",
      "[CV 1/2] END learning_rate=0.13, n_estimators=230, objective=poisson;, score=(train=0.871, test=0.576) total time=   3.2s\n",
      "train score: 0.689440 (+/-0.000485)\n",
      "valid score: 0.593020 (+/-0.000761)\n",
      "best params: {'learning_rate': 0.0131, 'n_estimators': 231, 'objective': 'poisson'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_lgbm = {\n",
    "    'learning_rate' : [0.13, 0.0131], \n",
    "    'n_estimators' : [230, 231],\n",
    "    'objective' : ['regression', 'poisson']\n",
    "}\n",
    "\n",
    "if (1):\n",
    "    best_lgbm_param, best_lgbm, best_lgbm_valid = grid_search_cv(lgb_transformer, df_train_x, df_train_y, pipeline_lgb, param_grid_lgbm, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-2. Training for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.664134 (+/-0.002286)\n",
      "valid score: 0.597305 (+/-0.008708)\n"
     ]
    }
   ],
   "source": [
    "params_static_lgbm = {\n",
    "    'random_state': 0, \n",
    "    'learning_rate' : 0.013,\n",
    "    'n_estimators' : 230,\n",
    "    'n_jobs' : -1,\n",
    "    'objective' : 'poisson'\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    lgbm = Pipeline([('vect', lgb_transformer), ('clf', best_lgbm)])\n",
    "else :\n",
    "    lgbm = Pipeline([('vect', lgb_transformer), ('clf', LGBMClassifier(**params_static_lgbm))])\n",
    "\n",
    "\n",
    "_ = training(df_train_x, df_train_y, lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-3-1. Grid sizing for Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "0:\tlearn: 0.6925111\ttotal: 829ms\tremaining: 9m 39s\n",
      "0:\tlearn: 0.6926031\ttotal: 839ms\tremaining: 9m 46s\n",
      "1:\tlearn: 0.6920114\ttotal: 1.54s\tremaining: 8m 58s\n",
      "1:\tlearn: 0.6921981\ttotal: 1.55s\tremaining: 9m\n",
      "2:\tlearn: 0.6915026\ttotal: 2.28s\tremaining: 8m 50s\n",
      "2:\tlearn: 0.6909394\ttotal: 2.28s\tremaining: 8m 50s\n",
      "3:\tlearn: 0.6909922\ttotal: 3.02s\tremaining: 8m 45s\n",
      "3:\tlearn: 0.6906376\ttotal: 3.03s\tremaining: 8m 47s\n",
      "4:\tlearn: 0.6902948\ttotal: 3.74s\tremaining: 8m 39s\n",
      "4:\tlearn: 0.6901053\ttotal: 3.79s\tremaining: 8m 47s\n",
      "5:\tlearn: 0.6899069\ttotal: 4.45s\tremaining: 8m 34s\n",
      "5:\tlearn: 0.6898346\ttotal: 4.54s\tremaining: 8m 44s\n",
      "6:\tlearn: 0.6896002\ttotal: 5.13s\tremaining: 8m 28s\n",
      "6:\tlearn: 0.6894964\ttotal: 5.3s\tremaining: 8m 45s\n",
      "7:\tlearn: 0.6889079\ttotal: 5.86s\tremaining: 8m 26s\n",
      "7:\tlearn: 0.6890035\ttotal: 6.02s\tremaining: 8m 40s\n",
      "8:\tlearn: 0.6884298\ttotal: 6.56s\tremaining: 8m 23s\n",
      "8:\tlearn: 0.6885649\ttotal: 6.7s\tremaining: 8m 34s\n",
      "9:\tlearn: 0.6878762\ttotal: 7.26s\tremaining: 8m 20s\n",
      "9:\tlearn: 0.6879378\ttotal: 7.43s\tremaining: 8m 32s\n",
      "10:\tlearn: 0.6866951\ttotal: 7.96s\tremaining: 8m 18s\n",
      "10:\tlearn: 0.6876908\ttotal: 8.11s\tremaining: 8m 28s\n",
      "11:\tlearn: 0.6863049\ttotal: 8.66s\tremaining: 8m 16s\n",
      "11:\tlearn: 0.6871965\ttotal: 8.84s\tremaining: 8m 26s\n",
      "12:\tlearn: 0.6859142\ttotal: 9.34s\tremaining: 8m 13s\n",
      "12:\tlearn: 0.6868117\ttotal: 9.52s\tremaining: 8m 23s\n",
      "13:\tlearn: 0.6856999\ttotal: 10.1s\tremaining: 8m 12s\n",
      "13:\tlearn: 0.6864099\ttotal: 10.3s\tremaining: 8m 22s\n",
      "14:\tlearn: 0.6853576\ttotal: 10.8s\tremaining: 8m 11s\n",
      "14:\tlearn: 0.6861511\ttotal: 11s\tremaining: 8m 20s\n",
      "15:\tlearn: 0.6850273\ttotal: 11.5s\tremaining: 8m 10s\n",
      "15:\tlearn: 0.6857670\ttotal: 11.7s\tremaining: 8m 22s\n",
      "16:\tlearn: 0.6844973\ttotal: 12.2s\tremaining: 8m 9s\n",
      "16:\tlearn: 0.6853471\ttotal: 12.4s\tremaining: 8m 18s\n",
      "17:\tlearn: 0.6839653\ttotal: 12.9s\tremaining: 8m 9s\n",
      "17:\tlearn: 0.6850599\ttotal: 13.2s\tremaining: 8m 19s\n",
      "18:\tlearn: 0.6849007\ttotal: 13.3s\tremaining: 7m 55s\n",
      "18:\tlearn: 0.6833611\ttotal: 13.7s\tremaining: 8m 9s\n",
      "19:\tlearn: 0.6844780\ttotal: 13.8s\tremaining: 7m 50s\n",
      "19:\tlearn: 0.6830719\ttotal: 14.4s\tremaining: 8m 7s\n",
      "20:\tlearn: 0.6842333\ttotal: 14.6s\tremaining: 7m 52s\n",
      "20:\tlearn: 0.6824398\ttotal: 15.1s\tremaining: 8m 7s\n",
      "21:\tlearn: 0.6840258\ttotal: 15.2s\tremaining: 7m 49s\n",
      "21:\tlearn: 0.6821091\ttotal: 15.8s\tremaining: 8m 7s\n",
      "22:\tlearn: 0.6835857\ttotal: 16s\tremaining: 7m 50s\n",
      "22:\tlearn: 0.6817568\ttotal: 16.5s\tremaining: 8m 5s\n",
      "23:\tlearn: 0.6831269\ttotal: 16.8s\tremaining: 7m 52s\n",
      "24:\tlearn: 0.6829564\ttotal: 16.9s\tremaining: 7m 35s\n",
      "23:\tlearn: 0.6813720\ttotal: 17.1s\tremaining: 8m 2s\n",
      "25:\tlearn: 0.6824354\ttotal: 17.6s\tremaining: 7m 35s\n",
      "24:\tlearn: 0.6810568\ttotal: 17.7s\tremaining: 7m 59s\n",
      "26:\tlearn: 0.6819334\ttotal: 18.3s\tremaining: 7m 35s\n",
      "25:\tlearn: 0.6808516\ttotal: 18.4s\tremaining: 7m 56s\n",
      "26:\tlearn: 0.6806510\ttotal: 18.6s\tremaining: 7m 44s\n",
      "27:\tlearn: 0.6816928\ttotal: 19s\tremaining: 7m 36s\n",
      "27:\tlearn: 0.6802808\ttotal: 19.3s\tremaining: 7m 43s\n",
      "28:\tlearn: 0.6813948\ttotal: 19.7s\tremaining: 7m 36s\n",
      "28:\tlearn: 0.6799688\ttotal: 20s\tremaining: 7m 43s\n",
      "29:\tlearn: 0.6811106\ttotal: 20.4s\tremaining: 7m 36s\n",
      "29:\tlearn: 0.6796284\ttotal: 20.7s\tremaining: 7m 41s\n",
      "30:\tlearn: 0.6807754\ttotal: 21.2s\tremaining: 7m 36s\n",
      "30:\tlearn: 0.6791416\ttotal: 21.3s\tremaining: 7m 40s\n",
      "31:\tlearn: 0.6802591\ttotal: 21.9s\tremaining: 7m 36s\n",
      "31:\tlearn: 0.6788728\ttotal: 21.9s\tremaining: 7m 37s\n",
      "32:\tlearn: 0.6798487\ttotal: 22.6s\tremaining: 7m 36s\n",
      "32:\tlearn: 0.6783355\ttotal: 22.6s\tremaining: 7m 36s\n",
      "33:\tlearn: 0.6796435\ttotal: 23.3s\tremaining: 7m 36s\n",
      "33:\tlearn: 0.6777347\ttotal: 23.3s\tremaining: 7m 36s\n",
      "34:\tlearn: 0.6772267\ttotal: 24.1s\tremaining: 7m 36s\n",
      "34:\tlearn: 0.6794102\ttotal: 24.1s\tremaining: 7m 36s\n",
      "35:\tlearn: 0.6769232\ttotal: 24.8s\tremaining: 7m 37s\n",
      "35:\tlearn: 0.6785972\ttotal: 24.8s\tremaining: 7m 37s\n",
      "36:\tlearn: 0.6764828\ttotal: 25.5s\tremaining: 7m 37s\n",
      "36:\tlearn: 0.6784050\ttotal: 25.5s\tremaining: 7m 37s\n",
      "37:\tlearn: 0.6760178\ttotal: 26.2s\tremaining: 7m 37s\n",
      "37:\tlearn: 0.6781277\ttotal: 26.2s\tremaining: 7m 37s\n",
      "38:\tlearn: 0.6755744\ttotal: 26.9s\tremaining: 7m 36s\n",
      "38:\tlearn: 0.6778498\ttotal: 26.9s\tremaining: 7m 36s\n",
      "39:\tlearn: 0.6752303\ttotal: 27.7s\tremaining: 7m 36s\n",
      "39:\tlearn: 0.6772021\ttotal: 27.7s\tremaining: 7m 36s\n",
      "40:\tlearn: 0.6746629\ttotal: 28.4s\tremaining: 7m 35s\n",
      "40:\tlearn: 0.6768530\ttotal: 28.4s\tremaining: 7m 36s\n",
      "41:\tlearn: 0.6742143\ttotal: 29.1s\tremaining: 7m 35s\n",
      "41:\tlearn: 0.6766486\ttotal: 29.1s\tremaining: 7m 36s\n",
      "42:\tlearn: 0.6734481\ttotal: 29.7s\tremaining: 7m 34s\n",
      "42:\tlearn: 0.6763543\ttotal: 29.8s\tremaining: 7m 35s\n",
      "43:\tlearn: 0.6730568\ttotal: 30.5s\tremaining: 7m 34s\n",
      "43:\tlearn: 0.6760090\ttotal: 30.6s\tremaining: 7m 35s\n",
      "44:\tlearn: 0.6727199\ttotal: 31.1s\tremaining: 7m 33s\n",
      "44:\tlearn: 0.6756609\ttotal: 31.3s\tremaining: 7m 35s\n",
      "45:\tlearn: 0.6725732\ttotal: 31.9s\tremaining: 7m 32s\n",
      "45:\tlearn: 0.6753445\ttotal: 32s\tremaining: 7m 35s\n",
      "46:\tlearn: 0.6752730\ttotal: 32s\tremaining: 7m 25s\n",
      "46:\tlearn: 0.6723220\ttotal: 32.6s\tremaining: 7m 32s\n",
      "47:\tlearn: 0.6750861\ttotal: 32.7s\tremaining: 7m 24s\n",
      "47:\tlearn: 0.6715452\ttotal: 33.3s\tremaining: 7m 31s\n",
      "48:\tlearn: 0.6748554\ttotal: 33.4s\tremaining: 7m 23s\n",
      "48:\tlearn: 0.6712725\ttotal: 34s\tremaining: 7m 31s\n",
      "49:\tlearn: 0.6746311\ttotal: 34.2s\tremaining: 7m 24s\n",
      "49:\tlearn: 0.6709011\ttotal: 34.7s\tremaining: 7m 30s\n",
      "50:\tlearn: 0.6743475\ttotal: 34.9s\tremaining: 7m 23s\n",
      "50:\tlearn: 0.6707325\ttotal: 35.4s\tremaining: 7m 30s\n",
      "51:\tlearn: 0.6741346\ttotal: 35.6s\tremaining: 7m 23s\n",
      "51:\tlearn: 0.6701587\ttotal: 36.1s\tremaining: 7m 29s\n",
      "52:\tlearn: 0.6738818\ttotal: 36.3s\tremaining: 7m 23s\n",
      "52:\tlearn: 0.6697664\ttotal: 36.8s\tremaining: 7m 28s\n",
      "53:\tlearn: 0.6734281\ttotal: 37.1s\tremaining: 7m 24s\n",
      "53:\tlearn: 0.6694434\ttotal: 37.4s\tremaining: 7m 27s\n",
      "54:\tlearn: 0.6732534\ttotal: 37.9s\tremaining: 7m 24s\n",
      "54:\tlearn: 0.6693356\ttotal: 38s\tremaining: 7m 25s\n",
      "55:\tlearn: 0.6729104\ttotal: 38.6s\tremaining: 7m 23s\n",
      "55:\tlearn: 0.6689490\ttotal: 38.7s\tremaining: 7m 25s\n",
      "56:\tlearn: 0.6724731\ttotal: 39.3s\tremaining: 7m 23s\n",
      "56:\tlearn: 0.6687441\ttotal: 39.4s\tremaining: 7m 23s\n",
      "57:\tlearn: 0.6720064\ttotal: 40s\tremaining: 7m 22s\n",
      "57:\tlearn: 0.6683348\ttotal: 40s\tremaining: 7m 22s\n",
      "58:\tlearn: 0.6677903\ttotal: 40.7s\tremaining: 7m 22s\n",
      "58:\tlearn: 0.6715159\ttotal: 40.7s\tremaining: 7m 22s\n",
      "59:\tlearn: 0.6674645\ttotal: 41.4s\tremaining: 7m 21s\n",
      "59:\tlearn: 0.6713028\ttotal: 41.6s\tremaining: 7m 23s\n",
      "60:\tlearn: 0.6712090\ttotal: 41.7s\tremaining: 7m 17s\n",
      "60:\tlearn: 0.6671711\ttotal: 42.1s\tremaining: 7m 21s\n",
      "61:\tlearn: 0.6709441\ttotal: 42.5s\tremaining: 7m 17s\n",
      "61:\tlearn: 0.6668286\ttotal: 42.7s\tremaining: 7m 19s\n",
      "62:\tlearn: 0.6707559\ttotal: 43.2s\tremaining: 7m 16s\n",
      "62:\tlearn: 0.6666823\ttotal: 43.3s\tremaining: 7m 17s\n",
      "63:\tlearn: 0.6704467\ttotal: 43.9s\tremaining: 7m 16s\n",
      "63:\tlearn: 0.6663433\ttotal: 43.9s\tremaining: 7m 16s\n",
      "64:\tlearn: 0.6702838\ttotal: 44.6s\tremaining: 7m 15s\n",
      "64:\tlearn: 0.6659099\ttotal: 44.6s\tremaining: 7m 16s\n",
      "65:\tlearn: 0.6700875\ttotal: 45.4s\tremaining: 7m 15s\n",
      "65:\tlearn: 0.6656975\ttotal: 45.4s\tremaining: 7m 15s\n",
      "66:\tlearn: 0.6651609\ttotal: 46.1s\tremaining: 7m 15s\n",
      "66:\tlearn: 0.6699340\ttotal: 46.1s\tremaining: 7m 15s\n",
      "67:\tlearn: 0.6649087\ttotal: 46.8s\tremaining: 7m 15s\n",
      "67:\tlearn: 0.6696105\ttotal: 46.8s\tremaining: 7m 15s\n",
      "68:\tlearn: 0.6644911\ttotal: 47.5s\tremaining: 7m 14s\n",
      "68:\tlearn: 0.6694221\ttotal: 47.6s\tremaining: 7m 15s\n",
      "69:\tlearn: 0.6641191\ttotal: 48.3s\tremaining: 7m 14s\n",
      "69:\tlearn: 0.6692032\ttotal: 48.3s\tremaining: 7m 14s\n",
      "70:\tlearn: 0.6639472\ttotal: 49s\tremaining: 7m 13s\n",
      "70:\tlearn: 0.6690246\ttotal: 49s\tremaining: 7m 14s\n",
      "71:\tlearn: 0.6633255\ttotal: 49.7s\tremaining: 7m 13s\n",
      "71:\tlearn: 0.6688458\ttotal: 49.7s\tremaining: 7m 13s\n",
      "72:\tlearn: 0.6631094\ttotal: 50.4s\tremaining: 7m 12s\n",
      "72:\tlearn: 0.6686395\ttotal: 50.5s\tremaining: 7m 13s\n",
      "73:\tlearn: 0.6628618\ttotal: 51.1s\tremaining: 7m 12s\n",
      "73:\tlearn: 0.6685412\ttotal: 51.2s\tremaining: 7m 13s\n",
      "74:\tlearn: 0.6625838\ttotal: 51.8s\tremaining: 7m 11s\n",
      "74:\tlearn: 0.6681962\ttotal: 51.9s\tremaining: 7m 12s\n",
      "75:\tlearn: 0.6624315\ttotal: 52.5s\tremaining: 7m 10s\n",
      "75:\tlearn: 0.6679557\ttotal: 52.7s\tremaining: 7m 12s\n",
      "76:\tlearn: 0.6621871\ttotal: 53.1s\tremaining: 7m 9s\n",
      "76:\tlearn: 0.6677362\ttotal: 53.5s\tremaining: 7m 12s\n",
      "77:\tlearn: 0.6618824\ttotal: 53.8s\tremaining: 7m 9s\n",
      "77:\tlearn: 0.6675751\ttotal: 54.1s\tremaining: 7m 11s\n",
      "78:\tlearn: 0.6616366\ttotal: 54.5s\tremaining: 7m 8s\n",
      "78:\tlearn: 0.6673540\ttotal: 54.8s\tremaining: 7m 10s\n",
      "79:\tlearn: 0.6613822\ttotal: 55.2s\tremaining: 7m 8s\n",
      "79:\tlearn: 0.6671994\ttotal: 55.6s\tremaining: 7m 10s\n",
      "80:\tlearn: 0.6612930\ttotal: 55.8s\tremaining: 7m 6s\n",
      "80:\tlearn: 0.6670293\ttotal: 56.3s\tremaining: 7m 10s\n",
      "81:\tlearn: 0.6609571\ttotal: 56.5s\tremaining: 7m 5s\n",
      "81:\tlearn: 0.6669089\ttotal: 57s\tremaining: 7m 9s\n",
      "82:\tlearn: 0.6605582\ttotal: 57.1s\tremaining: 7m 4s\n",
      "82:\tlearn: 0.6667310\ttotal: 57.7s\tremaining: 7m 8s\n",
      "83:\tlearn: 0.6603944\ttotal: 57.7s\tremaining: 7m 3s\n",
      "83:\tlearn: 0.6664127\ttotal: 58.4s\tremaining: 7m 8s\n",
      "84:\tlearn: 0.6600005\ttotal: 58.5s\tremaining: 7m 3s\n",
      "84:\tlearn: 0.6661878\ttotal: 59.1s\tremaining: 7m 7s\n",
      "85:\tlearn: 0.6596852\ttotal: 59.2s\tremaining: 7m 2s\n",
      "85:\tlearn: 0.6659822\ttotal: 59.8s\tremaining: 7m 6s\n",
      "86:\tlearn: 0.6595080\ttotal: 59.8s\tremaining: 7m 1s\n",
      "87:\tlearn: 0.6592953\ttotal: 1m\tremaining: 7m\n",
      "86:\tlearn: 0.6657098\ttotal: 1m\tremaining: 7m 6s\n",
      "87:\tlearn: 0.6654872\ttotal: 1m 1s\tremaining: 7m 5s\n",
      "88:\tlearn: 0.6590077\ttotal: 1m 1s\tremaining: 7m\n",
      "88:\tlearn: 0.6652690\ttotal: 1m 1s\tremaining: 7m 5s\n",
      "89:\tlearn: 0.6588580\ttotal: 1m 1s\tremaining: 6m 59s\n",
      "90:\tlearn: 0.6587261\ttotal: 1m 2s\tremaining: 6m 59s\n",
      "89:\tlearn: 0.6651318\ttotal: 1m 2s\tremaining: 7m 4s\n",
      "90:\tlearn: 0.6649497\ttotal: 1m 3s\tremaining: 7m 4s\n",
      "91:\tlearn: 0.6586254\ttotal: 1m 3s\tremaining: 6m 58s\n",
      "91:\tlearn: 0.6647428\ttotal: 1m 4s\tremaining: 7m 3s\n",
      "92:\tlearn: 0.6582758\ttotal: 1m 4s\tremaining: 6m 58s\n",
      "92:\tlearn: 0.6645945\ttotal: 1m 4s\tremaining: 7m 2s\n",
      "93:\tlearn: 0.6580719\ttotal: 1m 4s\tremaining: 6m 58s\n",
      "93:\tlearn: 0.6644506\ttotal: 1m 5s\tremaining: 7m 2s\n",
      "94:\tlearn: 0.6578532\ttotal: 1m 5s\tremaining: 6m 57s\n",
      "94:\tlearn: 0.6642733\ttotal: 1m 6s\tremaining: 7m 1s\n",
      "95:\tlearn: 0.6576607\ttotal: 1m 6s\tremaining: 6m 56s\n",
      "96:\tlearn: 0.6575466\ttotal: 1m 6s\tremaining: 6m 55s\n",
      "95:\tlearn: 0.6639789\ttotal: 1m 6s\tremaining: 7m\n",
      "97:\tlearn: 0.6573267\ttotal: 1m 7s\tremaining: 6m 55s\n",
      "96:\tlearn: 0.6636792\ttotal: 1m 7s\tremaining: 7m\n",
      "98:\tlearn: 0.6570721\ttotal: 1m 8s\tremaining: 6m 54s\n",
      "97:\tlearn: 0.6636060\ttotal: 1m 8s\tremaining: 7m\n",
      "99:\tlearn: 0.6567563\ttotal: 1m 9s\tremaining: 6m 54s\n",
      "98:\tlearn: 0.6634474\ttotal: 1m 9s\tremaining: 6m 59s\n",
      "100:\tlearn: 0.6563225\ttotal: 1m 9s\tremaining: 6m 53s\n",
      "99:\tlearn: 0.6633131\ttotal: 1m 9s\tremaining: 6m 59s\n",
      "101:\tlearn: 0.6561611\ttotal: 1m 10s\tremaining: 6m 52s\n",
      "100:\tlearn: 0.6631079\ttotal: 1m 10s\tremaining: 6m 58s\n",
      "102:\tlearn: 0.6556360\ttotal: 1m 11s\tremaining: 6m 52s\n",
      "101:\tlearn: 0.6628332\ttotal: 1m 11s\tremaining: 6m 58s\n",
      "103:\tlearn: 0.6555003\ttotal: 1m 11s\tremaining: 6m 51s\n",
      "102:\tlearn: 0.6626606\ttotal: 1m 12s\tremaining: 6m 57s\n",
      "104:\tlearn: 0.6553861\ttotal: 1m 12s\tremaining: 6m 51s\n",
      "103:\tlearn: 0.6624779\ttotal: 1m 12s\tremaining: 6m 57s\n",
      "105:\tlearn: 0.6553006\ttotal: 1m 13s\tremaining: 6m 50s\n",
      "104:\tlearn: 0.6624213\ttotal: 1m 13s\tremaining: 6m 57s\n",
      "106:\tlearn: 0.6551715\ttotal: 1m 13s\tremaining: 6m 49s\n",
      "105:\tlearn: 0.6623096\ttotal: 1m 14s\tremaining: 6m 56s\n",
      "107:\tlearn: 0.6549871\ttotal: 1m 14s\tremaining: 6m 48s\n",
      "106:\tlearn: 0.6620403\ttotal: 1m 15s\tremaining: 6m 55s\n",
      "108:\tlearn: 0.6548012\ttotal: 1m 15s\tremaining: 6m 47s\n",
      "107:\tlearn: 0.6617277\ttotal: 1m 15s\tremaining: 6m 55s\n",
      "109:\tlearn: 0.6546060\ttotal: 1m 15s\tremaining: 6m 46s\n",
      "108:\tlearn: 0.6613314\ttotal: 1m 16s\tremaining: 6m 54s\n",
      "110:\tlearn: 0.6543396\ttotal: 1m 16s\tremaining: 6m 45s\n",
      "111:\tlearn: 0.6539767\ttotal: 1m 17s\tremaining: 6m 45s\n",
      "109:\tlearn: 0.6610593\ttotal: 1m 17s\tremaining: 6m 54s\n",
      "110:\tlearn: 0.6609403\ttotal: 1m 17s\tremaining: 6m 53s\n",
      "112:\tlearn: 0.6539272\ttotal: 1m 17s\tremaining: 6m 44s\n",
      "113:\tlearn: 0.6538173\ttotal: 1m 18s\tremaining: 6m 44s\n",
      "111:\tlearn: 0.6607499\ttotal: 1m 18s\tremaining: 6m 53s\n",
      "114:\tlearn: 0.6536759\ttotal: 1m 19s\tremaining: 6m 43s\n",
      "112:\tlearn: 0.6602184\ttotal: 1m 19s\tremaining: 6m 52s\n",
      "115:\tlearn: 0.6530015\ttotal: 1m 20s\tremaining: 6m 43s\n",
      "113:\tlearn: 0.6599524\ttotal: 1m 20s\tremaining: 6m 52s\n",
      "116:\tlearn: 0.6527110\ttotal: 1m 20s\tremaining: 6m 43s\n",
      "114:\tlearn: 0.6597223\ttotal: 1m 20s\tremaining: 6m 51s\n",
      "117:\tlearn: 0.6526068\ttotal: 1m 21s\tremaining: 6m 42s\n",
      "115:\tlearn: 0.6595100\ttotal: 1m 21s\tremaining: 6m 50s\n",
      "118:\tlearn: 0.6524004\ttotal: 1m 22s\tremaining: 6m 41s\n",
      "116:\tlearn: 0.6592582\ttotal: 1m 22s\tremaining: 6m 50s\n",
      "119:\tlearn: 0.6523254\ttotal: 1m 23s\tremaining: 6m 41s\n",
      "117:\tlearn: 0.6591231\ttotal: 1m 23s\tremaining: 6m 49s\n",
      "120:\tlearn: 0.6521419\ttotal: 1m 23s\tremaining: 6m 40s\n",
      "118:\tlearn: 0.6588787\ttotal: 1m 23s\tremaining: 6m 48s\n",
      "121:\tlearn: 0.6520783\ttotal: 1m 24s\tremaining: 6m 39s\n",
      "119:\tlearn: 0.6585798\ttotal: 1m 24s\tremaining: 6m 48s\n",
      "122:\tlearn: 0.6519857\ttotal: 1m 25s\tremaining: 6m 39s\n",
      "120:\tlearn: 0.6584260\ttotal: 1m 25s\tremaining: 6m 47s\n",
      "123:\tlearn: 0.6518778\ttotal: 1m 25s\tremaining: 6m 38s\n",
      "121:\tlearn: 0.6580681\ttotal: 1m 25s\tremaining: 6m 47s\n",
      "124:\tlearn: 0.6513902\ttotal: 1m 26s\tremaining: 6m 37s\n",
      "122:\tlearn: 0.6578240\ttotal: 1m 26s\tremaining: 6m 46s\n",
      "125:\tlearn: 0.6513472\ttotal: 1m 27s\tremaining: 6m 37s\n",
      "123:\tlearn: 0.6576977\ttotal: 1m 27s\tremaining: 6m 45s\n",
      "126:\tlearn: 0.6512558\ttotal: 1m 27s\tremaining: 6m 36s\n",
      "124:\tlearn: 0.6575508\ttotal: 1m 28s\tremaining: 6m 45s\n",
      "127:\tlearn: 0.6510776\ttotal: 1m 28s\tremaining: 6m 36s\n",
      "125:\tlearn: 0.6573182\ttotal: 1m 28s\tremaining: 6m 44s\n",
      "128:\tlearn: 0.6509663\ttotal: 1m 29s\tremaining: 6m 35s\n",
      "126:\tlearn: 0.6572471\ttotal: 1m 29s\tremaining: 6m 44s\n",
      "129:\tlearn: 0.6507780\ttotal: 1m 30s\tremaining: 6m 34s\n",
      "127:\tlearn: 0.6570697\ttotal: 1m 30s\tremaining: 6m 43s\n",
      "130:\tlearn: 0.6506258\ttotal: 1m 30s\tremaining: 6m 33s\n",
      "128:\tlearn: 0.6568410\ttotal: 1m 31s\tremaining: 6m 43s\n",
      "131:\tlearn: 0.6505433\ttotal: 1m 31s\tremaining: 6m 32s\n",
      "129:\tlearn: 0.6567369\ttotal: 1m 31s\tremaining: 6m 42s\n",
      "132:\tlearn: 0.6504531\ttotal: 1m 31s\tremaining: 6m 32s\n",
      "130:\tlearn: 0.6566524\ttotal: 1m 32s\tremaining: 6m 41s\n",
      "133:\tlearn: 0.6502324\ttotal: 1m 32s\tremaining: 6m 31s\n",
      "131:\tlearn: 0.6565810\ttotal: 1m 33s\tremaining: 6m 41s\n",
      "134:\tlearn: 0.6501653\ttotal: 1m 33s\tremaining: 6m 30s\n",
      "132:\tlearn: 0.6564342\ttotal: 1m 33s\tremaining: 6m 40s\n",
      "135:\tlearn: 0.6500789\ttotal: 1m 34s\tremaining: 6m 30s\n",
      "133:\tlearn: 0.6563717\ttotal: 1m 34s\tremaining: 6m 39s\n",
      "136:\tlearn: 0.6499875\ttotal: 1m 34s\tremaining: 6m 29s\n",
      "134:\tlearn: 0.6563075\ttotal: 1m 35s\tremaining: 6m 38s\n",
      "137:\tlearn: 0.6497113\ttotal: 1m 35s\tremaining: 6m 28s\n",
      "135:\tlearn: 0.6562528\ttotal: 1m 35s\tremaining: 6m 38s\n",
      "138:\tlearn: 0.6494830\ttotal: 1m 36s\tremaining: 6m 28s\n",
      "136:\tlearn: 0.6560732\ttotal: 1m 36s\tremaining: 6m 37s\n",
      "139:\tlearn: 0.6494003\ttotal: 1m 36s\tremaining: 6m 27s\n",
      "137:\tlearn: 0.6559654\ttotal: 1m 37s\tremaining: 6m 36s\n",
      "140:\tlearn: 0.6492959\ttotal: 1m 37s\tremaining: 6m 26s\n",
      "138:\tlearn: 0.6555473\ttotal: 1m 38s\tremaining: 6m 35s\n",
      "141:\tlearn: 0.6491975\ttotal: 1m 38s\tremaining: 6m 25s\n",
      "142:\tlearn: 0.6488481\ttotal: 1m 38s\tremaining: 6m 24s\n",
      "139:\tlearn: 0.6552119\ttotal: 1m 38s\tremaining: 6m 35s\n",
      "143:\tlearn: 0.6485729\ttotal: 1m 39s\tremaining: 6m 24s\n",
      "140:\tlearn: 0.6549945\ttotal: 1m 39s\tremaining: 6m 34s\n",
      "144:\tlearn: 0.6482609\ttotal: 1m 40s\tremaining: 6m 24s\n",
      "141:\tlearn: 0.6549320\ttotal: 1m 40s\tremaining: 6m 34s\n",
      "142:\tlearn: 0.6548445\ttotal: 1m 41s\tremaining: 6m 33s\n",
      "145:\tlearn: 0.6481155\ttotal: 1m 41s\tremaining: 6m 23s\n",
      "146:\tlearn: 0.6480376\ttotal: 1m 41s\tremaining: 6m 23s\n",
      "143:\tlearn: 0.6547893\ttotal: 1m 41s\tremaining: 6m 33s\n",
      "147:\tlearn: 0.6479846\ttotal: 1m 42s\tremaining: 6m 22s\n",
      "144:\tlearn: 0.6547034\ttotal: 1m 42s\tremaining: 6m 32s\n",
      "148:\tlearn: 0.6478290\ttotal: 1m 43s\tremaining: 6m 22s\n",
      "145:\tlearn: 0.6545728\ttotal: 1m 43s\tremaining: 6m 32s\n",
      "149:\tlearn: 0.6475211\ttotal: 1m 44s\tremaining: 6m 21s\n",
      "146:\tlearn: 0.6544908\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "150:\tlearn: 0.6473604\ttotal: 1m 44s\tremaining: 6m 20s\n",
      "147:\tlearn: 0.6544082\ttotal: 1m 44s\tremaining: 6m 31s\n",
      "151:\tlearn: 0.6472779\ttotal: 1m 45s\tremaining: 6m 20s\n",
      "148:\tlearn: 0.6542395\ttotal: 1m 45s\tremaining: 6m 30s\n",
      "152:\tlearn: 0.6471654\ttotal: 1m 46s\tremaining: 6m 19s\n",
      "149:\tlearn: 0.6542005\ttotal: 1m 46s\tremaining: 6m 29s\n",
      "153:\tlearn: 0.6471288\ttotal: 1m 46s\tremaining: 6m 18s\n",
      "150:\tlearn: 0.6539475\ttotal: 1m 47s\tremaining: 6m 29s\n",
      "154:\tlearn: 0.6469879\ttotal: 1m 47s\tremaining: 6m 18s\n",
      "151:\tlearn: 0.6539069\ttotal: 1m 47s\tremaining: 6m 28s\n",
      "155:\tlearn: 0.6469287\ttotal: 1m 48s\tremaining: 6m 17s\n",
      "152:\tlearn: 0.6535498\ttotal: 1m 48s\tremaining: 6m 27s\n",
      "156:\tlearn: 0.6468281\ttotal: 1m 48s\tremaining: 6m 16s\n",
      "153:\tlearn: 0.6534690\ttotal: 1m 49s\tremaining: 6m 27s\n",
      "157:\tlearn: 0.6466113\ttotal: 1m 49s\tremaining: 6m 16s\n",
      "154:\tlearn: 0.6533069\ttotal: 1m 49s\tremaining: 6m 26s\n",
      "158:\tlearn: 0.6464906\ttotal: 1m 50s\tremaining: 6m 15s\n",
      "155:\tlearn: 0.6530392\ttotal: 1m 50s\tremaining: 6m 25s\n",
      "159:\tlearn: 0.6463533\ttotal: 1m 51s\tremaining: 6m 14s\n",
      "156:\tlearn: 0.6525860\ttotal: 1m 51s\tremaining: 6m 25s\n",
      "160:\tlearn: 0.6461800\ttotal: 1m 51s\tremaining: 6m 14s\n",
      "157:\tlearn: 0.6523240\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "161:\tlearn: 0.6460119\ttotal: 1m 52s\tremaining: 6m 13s\n",
      "158:\tlearn: 0.6522671\ttotal: 1m 52s\tremaining: 6m 24s\n",
      "162:\tlearn: 0.6458272\ttotal: 1m 53s\tremaining: 6m 12s\n",
      "159:\tlearn: 0.6521349\ttotal: 1m 53s\tremaining: 6m 23s\n",
      "163:\tlearn: 0.6455515\ttotal: 1m 53s\tremaining: 6m 11s\n",
      "160:\tlearn: 0.6519622\ttotal: 1m 54s\tremaining: 6m 22s\n",
      "164:\tlearn: 0.6454830\ttotal: 1m 54s\tremaining: 6m 10s\n",
      "165:\tlearn: 0.6453038\ttotal: 1m 54s\tremaining: 6m 9s\n",
      "161:\tlearn: 0.6518847\ttotal: 1m 54s\tremaining: 6m 21s\n",
      "166:\tlearn: 0.6451993\ttotal: 1m 55s\tremaining: 6m 9s\n",
      "162:\tlearn: 0.6517566\ttotal: 1m 55s\tremaining: 6m 21s\n",
      "167:\tlearn: 0.6450469\ttotal: 1m 56s\tremaining: 6m 8s\n",
      "163:\tlearn: 0.6516561\ttotal: 1m 56s\tremaining: 6m 20s\n",
      "168:\tlearn: 0.6448386\ttotal: 1m 57s\tremaining: 6m 7s\n",
      "164:\tlearn: 0.6512665\ttotal: 1m 57s\tremaining: 6m 20s\n",
      "169:\tlearn: 0.6447375\ttotal: 1m 57s\tremaining: 6m 7s\n",
      "165:\tlearn: 0.6511226\ttotal: 1m 57s\tremaining: 6m 19s\n",
      "170:\tlearn: 0.6445986\ttotal: 1m 58s\tremaining: 6m 6s\n",
      "166:\tlearn: 0.6510321\ttotal: 1m 58s\tremaining: 6m 18s\n",
      "171:\tlearn: 0.6445586\ttotal: 1m 59s\tremaining: 6m 5s\n",
      "167:\tlearn: 0.6509480\ttotal: 1m 59s\tremaining: 6m 17s\n",
      "172:\tlearn: 0.6444432\ttotal: 1m 59s\tremaining: 6m 5s\n",
      "168:\tlearn: 0.6508517\ttotal: 1m 59s\tremaining: 6m 16s\n",
      "173:\tlearn: 0.6442392\ttotal: 2m\tremaining: 6m 4s\n",
      "169:\tlearn: 0.6507583\ttotal: 2m\tremaining: 6m 16s\n",
      "174:\tlearn: 0.6441296\ttotal: 2m 1s\tremaining: 6m 4s\n",
      "170:\tlearn: 0.6506842\ttotal: 2m 1s\tremaining: 6m 15s\n",
      "175:\tlearn: 0.6440817\ttotal: 2m 2s\tremaining: 6m 3s\n",
      "171:\tlearn: 0.6506075\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "176:\tlearn: 0.6440236\ttotal: 2m 2s\tremaining: 6m 2s\n",
      "172:\tlearn: 0.6504402\ttotal: 2m 2s\tremaining: 6m 14s\n",
      "177:\tlearn: 0.6438880\ttotal: 2m 3s\tremaining: 6m 2s\n",
      "173:\tlearn: 0.6502673\ttotal: 2m 3s\tremaining: 6m 13s\n",
      "178:\tlearn: 0.6438293\ttotal: 2m 4s\tremaining: 6m 1s\n",
      "174:\tlearn: 0.6500922\ttotal: 2m 4s\tremaining: 6m 13s\n",
      "179:\tlearn: 0.6436972\ttotal: 2m 4s\tremaining: 6m\n",
      "175:\tlearn: 0.6499572\ttotal: 2m 5s\tremaining: 6m 12s\n",
      "180:\tlearn: 0.6435109\ttotal: 2m 5s\tremaining: 6m\n",
      "176:\tlearn: 0.6498507\ttotal: 2m 5s\tremaining: 6m 11s\n",
      "181:\tlearn: 0.6432921\ttotal: 2m 6s\tremaining: 5m 59s\n",
      "177:\tlearn: 0.6496957\ttotal: 2m 6s\tremaining: 6m 10s\n",
      "182:\tlearn: 0.6431265\ttotal: 2m 7s\tremaining: 5m 58s\n",
      "178:\tlearn: 0.6495664\ttotal: 2m 7s\tremaining: 6m 10s\n",
      "183:\tlearn: 0.6430034\ttotal: 2m 7s\tremaining: 5m 58s\n",
      "179:\tlearn: 0.6493463\ttotal: 2m 7s\tremaining: 6m 9s\n",
      "184:\tlearn: 0.6429125\ttotal: 2m 8s\tremaining: 5m 57s\n",
      "180:\tlearn: 0.6492300\ttotal: 2m 8s\tremaining: 6m 9s\n",
      "185:\tlearn: 0.6428099\ttotal: 2m 8s\tremaining: 5m 56s\n",
      "181:\tlearn: 0.6491258\ttotal: 2m 9s\tremaining: 6m 8s\n",
      "186:\tlearn: 0.6427317\ttotal: 2m 9s\tremaining: 5m 55s\n",
      "182:\tlearn: 0.6489822\ttotal: 2m 10s\tremaining: 6m 7s\n",
      "187:\tlearn: 0.6426449\ttotal: 2m 10s\tremaining: 5m 54s\n",
      "183:\tlearn: 0.6488716\ttotal: 2m 10s\tremaining: 6m 7s\n",
      "188:\tlearn: 0.6425132\ttotal: 2m 10s\tremaining: 5m 53s\n",
      "189:\tlearn: 0.6424763\ttotal: 2m 11s\tremaining: 5m 53s\n",
      "184:\tlearn: 0.6487841\ttotal: 2m 11s\tremaining: 6m 6s\n",
      "190:\tlearn: 0.6423581\ttotal: 2m 12s\tremaining: 5m 52s\n",
      "185:\tlearn: 0.6484488\ttotal: 2m 12s\tremaining: 6m 5s\n",
      "191:\tlearn: 0.6422458\ttotal: 2m 12s\tremaining: 5m 51s\n",
      "186:\tlearn: 0.6483953\ttotal: 2m 13s\tremaining: 6m 5s\n",
      "192:\tlearn: 0.6421499\ttotal: 2m 13s\tremaining: 5m 51s\n",
      "187:\tlearn: 0.6482004\ttotal: 2m 13s\tremaining: 6m 4s\n",
      "193:\tlearn: 0.6420892\ttotal: 2m 14s\tremaining: 5m 50s\n",
      "188:\tlearn: 0.6481347\ttotal: 2m 14s\tremaining: 6m 3s\n",
      "194:\tlearn: 0.6418964\ttotal: 2m 15s\tremaining: 5m 49s\n",
      "189:\tlearn: 0.6479159\ttotal: 2m 15s\tremaining: 6m 3s\n",
      "195:\tlearn: 0.6418574\ttotal: 2m 15s\tremaining: 5m 49s\n",
      "190:\tlearn: 0.6478144\ttotal: 2m 15s\tremaining: 6m 2s\n",
      "196:\tlearn: 0.6417630\ttotal: 2m 16s\tremaining: 5m 48s\n",
      "191:\tlearn: 0.6477159\ttotal: 2m 16s\tremaining: 6m 1s\n",
      "197:\tlearn: 0.6417050\ttotal: 2m 17s\tremaining: 5m 47s\n",
      "192:\tlearn: 0.6476018\ttotal: 2m 17s\tremaining: 6m\n",
      "198:\tlearn: 0.6415997\ttotal: 2m 17s\tremaining: 5m 47s\n",
      "193:\tlearn: 0.6474156\ttotal: 2m 18s\tremaining: 6m\n",
      "199:\tlearn: 0.6415316\ttotal: 2m 18s\tremaining: 5m 46s\n",
      "194:\tlearn: 0.6473274\ttotal: 2m 18s\tremaining: 5m 59s\n",
      "200:\tlearn: 0.6414812\ttotal: 2m 19s\tremaining: 5m 45s\n",
      "195:\tlearn: 0.6472264\ttotal: 2m 19s\tremaining: 5m 59s\n",
      "201:\tlearn: 0.6413518\ttotal: 2m 20s\tremaining: 5m 45s\n",
      "196:\tlearn: 0.6471454\ttotal: 2m 20s\tremaining: 5m 58s\n",
      "202:\tlearn: 0.6412392\ttotal: 2m 20s\tremaining: 5m 44s\n",
      "197:\tlearn: 0.6469785\ttotal: 2m 21s\tremaining: 5m 57s\n",
      "203:\tlearn: 0.6411909\ttotal: 2m 21s\tremaining: 5m 43s\n",
      "198:\tlearn: 0.6468461\ttotal: 2m 21s\tremaining: 5m 57s\n",
      "204:\tlearn: 0.6411260\ttotal: 2m 21s\tremaining: 5m 42s\n",
      "199:\tlearn: 0.6467859\ttotal: 2m 22s\tremaining: 5m 56s\n",
      "205:\tlearn: 0.6410031\ttotal: 2m 22s\tremaining: 5m 42s\n",
      "200:\tlearn: 0.6467277\ttotal: 2m 23s\tremaining: 5m 55s\n",
      "206:\tlearn: 0.6409481\ttotal: 2m 23s\tremaining: 5m 41s\n",
      "201:\tlearn: 0.6466847\ttotal: 2m 23s\tremaining: 5m 54s\n",
      "207:\tlearn: 0.6408312\ttotal: 2m 24s\tremaining: 5m 40s\n",
      "202:\tlearn: 0.6465957\ttotal: 2m 24s\tremaining: 5m 54s\n",
      "208:\tlearn: 0.6406750\ttotal: 2m 24s\tremaining: 5m 40s\n",
      "203:\tlearn: 0.6465468\ttotal: 2m 25s\tremaining: 5m 53s\n",
      "209:\tlearn: 0.6405316\ttotal: 2m 25s\tremaining: 5m 39s\n",
      "204:\tlearn: 0.6464519\ttotal: 2m 26s\tremaining: 5m 52s\n",
      "210:\tlearn: 0.6404468\ttotal: 2m 26s\tremaining: 5m 38s\n",
      "205:\tlearn: 0.6464034\ttotal: 2m 26s\tremaining: 5m 51s\n",
      "211:\tlearn: 0.6403766\ttotal: 2m 26s\tremaining: 5m 37s\n",
      "206:\tlearn: 0.6462996\ttotal: 2m 27s\tremaining: 5m 51s\n",
      "212:\tlearn: 0.6403374\ttotal: 2m 27s\tremaining: 5m 37s\n",
      "207:\tlearn: 0.6462178\ttotal: 2m 28s\tremaining: 5m 50s\n",
      "213:\tlearn: 0.6402891\ttotal: 2m 28s\tremaining: 5m 36s\n",
      "208:\tlearn: 0.6461436\ttotal: 2m 28s\tremaining: 5m 49s\n",
      "214:\tlearn: 0.6402262\ttotal: 2m 28s\tremaining: 5m 35s\n",
      "209:\tlearn: 0.6460444\ttotal: 2m 29s\tremaining: 5m 48s\n",
      "215:\tlearn: 0.6401917\ttotal: 2m 29s\tremaining: 5m 35s\n",
      "210:\tlearn: 0.6458805\ttotal: 2m 30s\tremaining: 5m 48s\n",
      "216:\tlearn: 0.6400913\ttotal: 2m 30s\tremaining: 5m 34s\n",
      "211:\tlearn: 0.6458008\ttotal: 2m 30s\tremaining: 5m 47s\n",
      "217:\tlearn: 0.6400221\ttotal: 2m 30s\tremaining: 5m 33s\n",
      "218:\tlearn: 0.6399415\ttotal: 2m 31s\tremaining: 5m 33s\n",
      "212:\tlearn: 0.6457403\ttotal: 2m 31s\tremaining: 5m 46s\n",
      "219:\tlearn: 0.6398901\ttotal: 2m 32s\tremaining: 5m 32s\n",
      "213:\tlearn: 0.6456234\ttotal: 2m 32s\tremaining: 5m 46s\n",
      "220:\tlearn: 0.6398361\ttotal: 2m 33s\tremaining: 5m 31s\n",
      "214:\tlearn: 0.6455655\ttotal: 2m 33s\tremaining: 5m 45s\n",
      "221:\tlearn: 0.6397512\ttotal: 2m 33s\tremaining: 5m 31s\n",
      "215:\tlearn: 0.6454072\ttotal: 2m 33s\tremaining: 5m 44s\n",
      "222:\tlearn: 0.6396749\ttotal: 2m 34s\tremaining: 5m 30s\n",
      "216:\tlearn: 0.6453741\ttotal: 2m 34s\tremaining: 5m 43s\n",
      "223:\tlearn: 0.6395077\ttotal: 2m 35s\tremaining: 5m 29s\n",
      "217:\tlearn: 0.6453450\ttotal: 2m 35s\tremaining: 5m 43s\n",
      "224:\tlearn: 0.6394581\ttotal: 2m 35s\tremaining: 5m 28s\n",
      "218:\tlearn: 0.6452808\ttotal: 2m 36s\tremaining: 5m 42s\n",
      "225:\tlearn: 0.6393214\ttotal: 2m 36s\tremaining: 5m 28s\n",
      "219:\tlearn: 0.6452036\ttotal: 2m 36s\tremaining: 5m 41s\n",
      "226:\tlearn: 0.6392013\ttotal: 2m 37s\tremaining: 5m 27s\n",
      "220:\tlearn: 0.6451341\ttotal: 2m 37s\tremaining: 5m 41s\n",
      "227:\tlearn: 0.6389943\ttotal: 2m 37s\tremaining: 5m 26s\n",
      "221:\tlearn: 0.6449904\ttotal: 2m 38s\tremaining: 5m 40s\n",
      "228:\tlearn: 0.6388932\ttotal: 2m 38s\tremaining: 5m 25s\n",
      "222:\tlearn: 0.6449131\ttotal: 2m 39s\tremaining: 5m 40s\n",
      "229:\tlearn: 0.6388580\ttotal: 2m 39s\tremaining: 5m 25s\n",
      "223:\tlearn: 0.6448047\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "230:\tlearn: 0.6386891\ttotal: 2m 39s\tremaining: 5m 24s\n",
      "224:\tlearn: 0.6447409\ttotal: 2m 40s\tremaining: 5m 38s\n",
      "231:\tlearn: 0.6386086\ttotal: 2m 40s\tremaining: 5m 23s\n",
      "225:\tlearn: 0.6446265\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "232:\tlearn: 0.6385602\ttotal: 2m 41s\tremaining: 5m 22s\n",
      "226:\tlearn: 0.6445645\ttotal: 2m 41s\tremaining: 5m 37s\n",
      "233:\tlearn: 0.6385146\ttotal: 2m 41s\tremaining: 5m 22s\n",
      "227:\tlearn: 0.6443729\ttotal: 2m 42s\tremaining: 5m 36s\n",
      "234:\tlearn: 0.6382914\ttotal: 2m 42s\tremaining: 5m 21s\n",
      "228:\tlearn: 0.6442248\ttotal: 2m 43s\tremaining: 5m 35s\n",
      "235:\tlearn: 0.6382540\ttotal: 2m 43s\tremaining: 5m 20s\n",
      "229:\tlearn: 0.6441649\ttotal: 2m 43s\tremaining: 5m 35s\n",
      "236:\tlearn: 0.6381350\ttotal: 2m 43s\tremaining: 5m 20s\n",
      "237:\tlearn: 0.6380787\ttotal: 2m 44s\tremaining: 5m 19s\n",
      "230:\tlearn: 0.6440477\ttotal: 2m 44s\tremaining: 5m 34s\n",
      "238:\tlearn: 0.6380112\ttotal: 2m 45s\tremaining: 5m 19s\n",
      "231:\tlearn: 0.6439095\ttotal: 2m 45s\tremaining: 5m 33s\n",
      "239:\tlearn: 0.6379657\ttotal: 2m 46s\tremaining: 5m 18s\n",
      "232:\tlearn: 0.6437898\ttotal: 2m 46s\tremaining: 5m 33s\n",
      "240:\tlearn: 0.6379354\ttotal: 2m 46s\tremaining: 5m 17s\n",
      "233:\tlearn: 0.6437128\ttotal: 2m 46s\tremaining: 5m 32s\n",
      "241:\tlearn: 0.6378969\ttotal: 2m 47s\tremaining: 5m 17s\n",
      "234:\tlearn: 0.6436142\ttotal: 2m 47s\tremaining: 5m 31s\n",
      "242:\tlearn: 0.6377945\ttotal: 2m 48s\tremaining: 5m 16s\n",
      "235:\tlearn: 0.6432920\ttotal: 2m 48s\tremaining: 5m 31s\n",
      "243:\tlearn: 0.6376994\ttotal: 2m 48s\tremaining: 5m 15s\n",
      "236:\tlearn: 0.6430544\ttotal: 2m 49s\tremaining: 5m 30s\n",
      "244:\tlearn: 0.6376057\ttotal: 2m 49s\tremaining: 5m 15s\n",
      "237:\tlearn: 0.6430025\ttotal: 2m 49s\tremaining: 5m 29s\n",
      "245:\tlearn: 0.6375646\ttotal: 2m 50s\tremaining: 5m 14s\n",
      "238:\tlearn: 0.6428813\ttotal: 2m 50s\tremaining: 5m 28s\n",
      "246:\tlearn: 0.6372396\ttotal: 2m 51s\tremaining: 5m 13s\n",
      "239:\tlearn: 0.6428419\ttotal: 2m 51s\tremaining: 5m 28s\n",
      "247:\tlearn: 0.6371557\ttotal: 2m 51s\tremaining: 5m 13s\n",
      "240:\tlearn: 0.6427386\ttotal: 2m 51s\tremaining: 5m 27s\n",
      "248:\tlearn: 0.6370742\ttotal: 2m 52s\tremaining: 5m 12s\n",
      "241:\tlearn: 0.6426086\ttotal: 2m 52s\tremaining: 5m 26s\n",
      "249:\tlearn: 0.6370022\ttotal: 2m 53s\tremaining: 5m 11s\n",
      "242:\tlearn: 0.6425722\ttotal: 2m 53s\tremaining: 5m 26s\n",
      "250:\tlearn: 0.6368711\ttotal: 2m 53s\tremaining: 5m 10s\n",
      "243:\tlearn: 0.6423735\ttotal: 2m 54s\tremaining: 5m 25s\n",
      "251:\tlearn: 0.6367582\ttotal: 2m 54s\tremaining: 5m 10s\n",
      "244:\tlearn: 0.6423012\ttotal: 2m 54s\tremaining: 5m 24s\n",
      "252:\tlearn: 0.6366962\ttotal: 2m 55s\tremaining: 5m 9s\n",
      "245:\tlearn: 0.6422503\ttotal: 2m 55s\tremaining: 5m 24s\n",
      "253:\tlearn: 0.6364835\ttotal: 2m 55s\tremaining: 5m 8s\n",
      "246:\tlearn: 0.6420791\ttotal: 2m 56s\tremaining: 5m 23s\n",
      "254:\tlearn: 0.6364478\ttotal: 2m 56s\tremaining: 5m 8s\n",
      "247:\tlearn: 0.6419769\ttotal: 2m 57s\tremaining: 5m 22s\n",
      "255:\tlearn: 0.6364150\ttotal: 2m 57s\tremaining: 5m 7s\n",
      "248:\tlearn: 0.6418835\ttotal: 2m 57s\tremaining: 5m 21s\n",
      "256:\tlearn: 0.6363387\ttotal: 2m 57s\tremaining: 5m 6s\n",
      "249:\tlearn: 0.6417914\ttotal: 2m 58s\tremaining: 5m 21s\n",
      "257:\tlearn: 0.6362484\ttotal: 2m 58s\tremaining: 5m 5s\n",
      "250:\tlearn: 0.6416296\ttotal: 2m 59s\tremaining: 5m 20s\n",
      "258:\tlearn: 0.6362122\ttotal: 2m 59s\tremaining: 5m 5s\n",
      "251:\tlearn: 0.6415760\ttotal: 2m 59s\tremaining: 5m 19s\n",
      "259:\tlearn: 0.6361592\ttotal: 2m 59s\tremaining: 5m 4s\n",
      "260:\tlearn: 0.6361349\ttotal: 2m 59s\tremaining: 5m 2s\n",
      "252:\tlearn: 0.6414685\ttotal: 3m\tremaining: 5m 19s\n",
      "261:\tlearn: 0.6360700\ttotal: 3m\tremaining: 5m 1s\n",
      "253:\tlearn: 0.6414297\ttotal: 3m 1s\tremaining: 5m 18s\n",
      "262:\tlearn: 0.6359861\ttotal: 3m 1s\tremaining: 5m 1s\n",
      "254:\tlearn: 0.6413906\ttotal: 3m 1s\tremaining: 5m 17s\n",
      "263:\tlearn: 0.6358465\ttotal: 3m 1s\tremaining: 5m\n",
      "264:\tlearn: 0.6356560\ttotal: 3m 2s\tremaining: 4m 59s\n",
      "255:\tlearn: 0.6413510\ttotal: 3m 2s\tremaining: 5m 16s\n",
      "256:\tlearn: 0.6412906\ttotal: 3m 3s\tremaining: 5m 16s\n",
      "265:\tlearn: 0.6355729\ttotal: 3m 3s\tremaining: 4m 59s\n",
      "257:\tlearn: 0.6409873\ttotal: 3m 4s\tremaining: 5m 15s\n",
      "266:\tlearn: 0.6354797\ttotal: 3m 4s\tremaining: 4m 58s\n",
      "258:\tlearn: 0.6409404\ttotal: 3m 4s\tremaining: 5m 14s\n",
      "267:\tlearn: 0.6353976\ttotal: 3m 4s\tremaining: 4m 57s\n",
      "268:\tlearn: 0.6353514\ttotal: 3m 5s\tremaining: 4m 57s\n",
      "259:\tlearn: 0.6408669\ttotal: 3m 5s\tremaining: 5m 14s\n",
      "269:\tlearn: 0.6353245\ttotal: 3m 6s\tremaining: 4m 56s\n",
      "260:\tlearn: 0.6408053\ttotal: 3m 6s\tremaining: 5m 13s\n",
      "261:\tlearn: 0.6407647\ttotal: 3m 7s\tremaining: 5m 12s\n",
      "270:\tlearn: 0.6352997\ttotal: 3m 7s\tremaining: 4m 56s\n",
      "262:\tlearn: 0.6404544\ttotal: 3m 7s\tremaining: 5m 12s\n",
      "271:\tlearn: 0.6352274\ttotal: 3m 7s\tremaining: 4m 55s\n",
      "263:\tlearn: 0.6404225\ttotal: 3m 8s\tremaining: 5m 11s\n",
      "272:\tlearn: 0.6351858\ttotal: 3m 8s\tremaining: 4m 54s\n",
      "273:\tlearn: 0.6351186\ttotal: 3m 9s\tremaining: 4m 54s\n",
      "264:\tlearn: 0.6403486\ttotal: 3m 9s\tremaining: 5m 10s\n",
      "265:\tlearn: 0.6402474\ttotal: 3m 10s\tremaining: 5m 10s\n",
      "274:\tlearn: 0.6350802\ttotal: 3m 10s\tremaining: 4m 53s\n",
      "266:\tlearn: 0.6402026\ttotal: 3m 10s\tremaining: 5m 9s\n",
      "275:\tlearn: 0.6349573\ttotal: 3m 10s\tremaining: 4m 53s\n",
      "267:\tlearn: 0.6401636\ttotal: 3m 11s\tremaining: 5m 8s\n",
      "276:\tlearn: 0.6348755\ttotal: 3m 11s\tremaining: 4m 52s\n",
      "268:\tlearn: 0.6400450\ttotal: 3m 12s\tremaining: 5m 8s\n",
      "277:\tlearn: 0.6348412\ttotal: 3m 12s\tremaining: 4m 51s\n",
      "269:\tlearn: 0.6399566\ttotal: 3m 12s\tremaining: 5m 7s\n",
      "278:\tlearn: 0.6347967\ttotal: 3m 12s\tremaining: 4m 51s\n",
      "270:\tlearn: 0.6397714\ttotal: 3m 13s\tremaining: 5m 6s\n",
      "279:\tlearn: 0.6346909\ttotal: 3m 13s\tremaining: 4m 50s\n",
      "271:\tlearn: 0.6393433\ttotal: 3m 14s\tremaining: 5m 5s\n",
      "280:\tlearn: 0.6346550\ttotal: 3m 14s\tremaining: 4m 49s\n",
      "281:\tlearn: 0.6343058\ttotal: 3m 15s\tremaining: 4m 49s\n",
      "272:\tlearn: 0.6392409\ttotal: 3m 15s\tremaining: 5m 5s\n",
      "282:\tlearn: 0.6342231\ttotal: 3m 15s\tremaining: 4m 48s\n",
      "273:\tlearn: 0.6392041\ttotal: 3m 15s\tremaining: 5m 4s\n",
      "283:\tlearn: 0.6341669\ttotal: 3m 16s\tremaining: 4m 47s\n",
      "274:\tlearn: 0.6391497\ttotal: 3m 16s\tremaining: 5m 3s\n",
      "284:\tlearn: 0.6339893\ttotal: 3m 17s\tremaining: 4m 47s\n",
      "275:\tlearn: 0.6391148\ttotal: 3m 17s\tremaining: 5m 3s\n",
      "285:\tlearn: 0.6339582\ttotal: 3m 17s\tremaining: 4m 46s\n",
      "276:\tlearn: 0.6390254\ttotal: 3m 18s\tremaining: 5m 2s\n",
      "286:\tlearn: 0.6338974\ttotal: 3m 18s\tremaining: 4m 45s\n",
      "277:\tlearn: 0.6388857\ttotal: 3m 18s\tremaining: 5m 1s\n",
      "287:\tlearn: 0.6336079\ttotal: 3m 19s\tremaining: 4m 45s\n",
      "278:\tlearn: 0.6388085\ttotal: 3m 19s\tremaining: 5m 1s\n",
      "288:\tlearn: 0.6335270\ttotal: 3m 20s\tremaining: 4m 44s\n",
      "279:\tlearn: 0.6386075\ttotal: 3m 20s\tremaining: 5m\n",
      "289:\tlearn: 0.6334983\ttotal: 3m 20s\tremaining: 4m 43s\n",
      "280:\tlearn: 0.6385450\ttotal: 3m 20s\tremaining: 4m 59s\n",
      "290:\tlearn: 0.6334533\ttotal: 3m 21s\tremaining: 4m 43s\n",
      "281:\tlearn: 0.6384105\ttotal: 3m 21s\tremaining: 4m 58s\n",
      "291:\tlearn: 0.6333870\ttotal: 3m 22s\tremaining: 4m 42s\n",
      "282:\tlearn: 0.6382980\ttotal: 3m 22s\tremaining: 4m 58s\n",
      "292:\tlearn: 0.6331506\ttotal: 3m 22s\tremaining: 4m 41s\n",
      "283:\tlearn: 0.6382615\ttotal: 3m 23s\tremaining: 4m 57s\n",
      "293:\tlearn: 0.6330296\ttotal: 3m 23s\tremaining: 4m 41s\n",
      "284:\tlearn: 0.6382123\ttotal: 3m 23s\tremaining: 4m 56s\n",
      "294:\tlearn: 0.6329975\ttotal: 3m 24s\tremaining: 4m 40s\n",
      "285:\tlearn: 0.6381222\ttotal: 3m 24s\tremaining: 4m 56s\n",
      "295:\tlearn: 0.6329336\ttotal: 3m 24s\tremaining: 4m 39s\n",
      "286:\tlearn: 0.6380424\ttotal: 3m 25s\tremaining: 4m 55s\n",
      "296:\tlearn: 0.6329089\ttotal: 3m 25s\tremaining: 4m 38s\n",
      "287:\tlearn: 0.6379980\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "297:\tlearn: 0.6328440\ttotal: 3m 26s\tremaining: 4m 38s\n",
      "288:\tlearn: 0.6379523\ttotal: 3m 26s\tremaining: 4m 54s\n",
      "298:\tlearn: 0.6326419\ttotal: 3m 26s\tremaining: 4m 37s\n",
      "289:\tlearn: 0.6379112\ttotal: 3m 27s\tremaining: 4m 53s\n",
      "299:\tlearn: 0.6325593\ttotal: 3m 27s\tremaining: 4m 36s\n",
      "290:\tlearn: 0.6378545\ttotal: 3m 28s\tremaining: 4m 52s\n",
      "300:\tlearn: 0.6325087\ttotal: 3m 28s\tremaining: 4m 36s\n",
      "291:\tlearn: 0.6377661\ttotal: 3m 28s\tremaining: 4m 51s\n",
      "301:\tlearn: 0.6324261\ttotal: 3m 28s\tremaining: 4m 35s\n",
      "292:\tlearn: 0.6376769\ttotal: 3m 29s\tremaining: 4m 51s\n",
      "302:\tlearn: 0.6323293\ttotal: 3m 29s\tremaining: 4m 34s\n",
      "293:\tlearn: 0.6374758\ttotal: 3m 30s\tremaining: 4m 50s\n",
      "303:\tlearn: 0.6322814\ttotal: 3m 30s\tremaining: 4m 34s\n",
      "294:\tlearn: 0.6373617\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "304:\tlearn: 0.6322371\ttotal: 3m 31s\tremaining: 4m 33s\n",
      "295:\tlearn: 0.6372690\ttotal: 3m 31s\tremaining: 4m 49s\n",
      "305:\tlearn: 0.6321642\ttotal: 3m 31s\tremaining: 4m 32s\n",
      "296:\tlearn: 0.6372526\ttotal: 3m 32s\tremaining: 4m 48s\n",
      "306:\tlearn: 0.6321183\ttotal: 3m 32s\tremaining: 4m 32s\n",
      "307:\tlearn: 0.6320346\ttotal: 3m 33s\tremaining: 4m 31s\n",
      "297:\tlearn: 0.6370226\ttotal: 3m 33s\tremaining: 4m 47s\n",
      "308:\tlearn: 0.6318662\ttotal: 3m 33s\tremaining: 4m 30s\n",
      "298:\tlearn: 0.6369325\ttotal: 3m 34s\tremaining: 4m 47s\n",
      "309:\tlearn: 0.6316386\ttotal: 3m 34s\tremaining: 4m 30s\n",
      "299:\tlearn: 0.6368279\ttotal: 3m 34s\tremaining: 4m 46s\n",
      "310:\tlearn: 0.6316102\ttotal: 3m 35s\tremaining: 4m 29s\n",
      "300:\tlearn: 0.6367715\ttotal: 3m 35s\tremaining: 4m 45s\n",
      "311:\tlearn: 0.6315282\ttotal: 3m 36s\tremaining: 4m 28s\n",
      "301:\tlearn: 0.6367233\ttotal: 3m 36s\tremaining: 4m 45s\n",
      "312:\tlearn: 0.6314652\ttotal: 3m 36s\tremaining: 4m 28s\n",
      "302:\tlearn: 0.6365748\ttotal: 3m 36s\tremaining: 4m 44s\n",
      "313:\tlearn: 0.6314214\ttotal: 3m 37s\tremaining: 4m 27s\n",
      "303:\tlearn: 0.6363113\ttotal: 3m 37s\tremaining: 4m 43s\n",
      "314:\tlearn: 0.6313513\ttotal: 3m 38s\tremaining: 4m 26s\n",
      "304:\tlearn: 0.6362099\ttotal: 3m 38s\tremaining: 4m 42s\n",
      "315:\tlearn: 0.6312812\ttotal: 3m 38s\tremaining: 4m 26s\n",
      "305:\tlearn: 0.6361848\ttotal: 3m 39s\tremaining: 4m 42s\n",
      "316:\tlearn: 0.6312324\ttotal: 3m 39s\tremaining: 4m 25s\n",
      "306:\tlearn: 0.6360924\ttotal: 3m 39s\tremaining: 4m 41s\n",
      "317:\tlearn: 0.6311914\ttotal: 3m 40s\tremaining: 4m 24s\n",
      "307:\tlearn: 0.6360695\ttotal: 3m 40s\tremaining: 4m 40s\n",
      "318:\tlearn: 0.6311406\ttotal: 3m 40s\tremaining: 4m 23s\n",
      "308:\tlearn: 0.6359044\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "319:\tlearn: 0.6310934\ttotal: 3m 41s\tremaining: 4m 23s\n",
      "309:\tlearn: 0.6358677\ttotal: 3m 41s\tremaining: 4m 39s\n",
      "320:\tlearn: 0.6310423\ttotal: 3m 42s\tremaining: 4m 22s\n",
      "310:\tlearn: 0.6358242\ttotal: 3m 42s\tremaining: 4m 38s\n",
      "321:\tlearn: 0.6309831\ttotal: 3m 43s\tremaining: 4m 21s\n",
      "311:\tlearn: 0.6356941\ttotal: 3m 43s\tremaining: 4m 37s\n",
      "322:\tlearn: 0.6309583\ttotal: 3m 43s\tremaining: 4m 21s\n",
      "312:\tlearn: 0.6356423\ttotal: 3m 44s\tremaining: 4m 37s\n",
      "323:\tlearn: 0.6309113\ttotal: 3m 44s\tremaining: 4m 20s\n",
      "313:\tlearn: 0.6355500\ttotal: 3m 44s\tremaining: 4m 36s\n",
      "324:\tlearn: 0.6307425\ttotal: 3m 45s\tremaining: 4m 19s\n",
      "314:\tlearn: 0.6354829\ttotal: 3m 45s\tremaining: 4m 35s\n",
      "325:\tlearn: 0.6307039\ttotal: 3m 45s\tremaining: 4m 19s\n",
      "315:\tlearn: 0.6354228\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "326:\tlearn: 0.6306333\ttotal: 3m 46s\tremaining: 4m 18s\n",
      "316:\tlearn: 0.6353412\ttotal: 3m 46s\tremaining: 4m 34s\n",
      "327:\tlearn: 0.6305784\ttotal: 3m 47s\tremaining: 4m 17s\n",
      "317:\tlearn: 0.6352999\ttotal: 3m 47s\tremaining: 4m 33s\n",
      "328:\tlearn: 0.6305326\ttotal: 3m 48s\tremaining: 4m 17s\n",
      "318:\tlearn: 0.6352396\ttotal: 3m 48s\tremaining: 4m 32s\n",
      "329:\tlearn: 0.6304645\ttotal: 3m 48s\tremaining: 4m 16s\n",
      "319:\tlearn: 0.6351739\ttotal: 3m 49s\tremaining: 4m 32s\n",
      "330:\tlearn: 0.6304273\ttotal: 3m 49s\tremaining: 4m 15s\n",
      "320:\tlearn: 0.6351074\ttotal: 3m 49s\tremaining: 4m 31s\n",
      "331:\tlearn: 0.6303406\ttotal: 3m 50s\tremaining: 4m 14s\n",
      "321:\tlearn: 0.6350144\ttotal: 3m 50s\tremaining: 4m 30s\n",
      "332:\tlearn: 0.6302352\ttotal: 3m 50s\tremaining: 4m 14s\n",
      "322:\tlearn: 0.6349789\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "333:\tlearn: 0.6301819\ttotal: 3m 51s\tremaining: 4m 13s\n",
      "323:\tlearn: 0.6348861\ttotal: 3m 51s\tremaining: 4m 29s\n",
      "334:\tlearn: 0.6299275\ttotal: 3m 52s\tremaining: 4m 12s\n",
      "324:\tlearn: 0.6348504\ttotal: 3m 52s\tremaining: 4m 28s\n",
      "335:\tlearn: 0.6298744\ttotal: 3m 52s\tremaining: 4m 12s\n",
      "325:\tlearn: 0.6347820\ttotal: 3m 53s\tremaining: 4m 27s\n",
      "336:\tlearn: 0.6298238\ttotal: 3m 53s\tremaining: 4m 11s\n",
      "326:\tlearn: 0.6346136\ttotal: 3m 54s\tremaining: 4m 27s\n",
      "337:\tlearn: 0.6297733\ttotal: 3m 54s\tremaining: 4m 10s\n",
      "338:\tlearn: 0.6297176\ttotal: 3m 54s\tremaining: 4m 9s\n",
      "327:\tlearn: 0.6345524\ttotal: 3m 54s\tremaining: 4m 26s\n",
      "339:\tlearn: 0.6296818\ttotal: 3m 55s\tremaining: 4m 9s\n",
      "328:\tlearn: 0.6344981\ttotal: 3m 55s\tremaining: 4m 25s\n",
      "340:\tlearn: 0.6295846\ttotal: 3m 56s\tremaining: 4m 8s\n",
      "329:\tlearn: 0.6344290\ttotal: 3m 56s\tremaining: 4m 24s\n",
      "341:\tlearn: 0.6295324\ttotal: 3m 56s\tremaining: 4m 7s\n",
      "330:\tlearn: 0.6342598\ttotal: 3m 57s\tremaining: 4m 24s\n",
      "342:\tlearn: 0.6295120\ttotal: 3m 57s\tremaining: 4m 7s\n",
      "331:\tlearn: 0.6340797\ttotal: 3m 57s\tremaining: 4m 23s\n",
      "343:\tlearn: 0.6294665\ttotal: 3m 58s\tremaining: 4m 6s\n",
      "332:\tlearn: 0.6340196\ttotal: 3m 58s\tremaining: 4m 22s\n",
      "344:\tlearn: 0.6293974\ttotal: 3m 58s\tremaining: 4m 5s\n",
      "333:\tlearn: 0.6339302\ttotal: 3m 59s\tremaining: 4m 22s\n",
      "345:\tlearn: 0.6293334\ttotal: 3m 59s\tremaining: 4m 5s\n",
      "334:\tlearn: 0.6338876\ttotal: 4m\tremaining: 4m 21s\n",
      "346:\tlearn: 0.6292726\ttotal: 4m\tremaining: 4m 4s\n",
      "335:\tlearn: 0.6338689\ttotal: 4m\tremaining: 4m 20s\n",
      "347:\tlearn: 0.6291955\ttotal: 4m\tremaining: 4m 3s\n",
      "336:\tlearn: 0.6338413\ttotal: 4m 1s\tremaining: 4m 20s\n",
      "348:\tlearn: 0.6291127\ttotal: 4m 1s\tremaining: 4m 2s\n",
      "337:\tlearn: 0.6338187\ttotal: 4m 2s\tremaining: 4m 19s\n",
      "349:\tlearn: 0.6290667\ttotal: 4m 2s\tremaining: 4m 2s\n",
      "350:\tlearn: 0.6288819\ttotal: 4m 2s\tremaining: 4m 1s\n",
      "338:\tlearn: 0.6337810\ttotal: 4m 3s\tremaining: 4m 18s\n",
      "351:\tlearn: 0.6287192\ttotal: 4m 3s\tremaining: 4m\n",
      "339:\tlearn: 0.6337147\ttotal: 4m 3s\tremaining: 4m 18s\n",
      "352:\tlearn: 0.6286323\ttotal: 4m 4s\tremaining: 4m\n",
      "340:\tlearn: 0.6336557\ttotal: 4m 4s\tremaining: 4m 17s\n",
      "353:\tlearn: 0.6285746\ttotal: 4m 5s\tremaining: 3m 59s\n",
      "341:\tlearn: 0.6335597\ttotal: 4m 5s\tremaining: 4m 16s\n",
      "354:\tlearn: 0.6285017\ttotal: 4m 5s\tremaining: 3m 58s\n",
      "342:\tlearn: 0.6334717\ttotal: 4m 5s\tremaining: 4m 16s\n",
      "355:\tlearn: 0.6283394\ttotal: 4m 6s\tremaining: 3m 58s\n",
      "343:\tlearn: 0.6334295\ttotal: 4m 6s\tremaining: 4m 15s\n",
      "356:\tlearn: 0.6282913\ttotal: 4m 7s\tremaining: 3m 57s\n",
      "344:\tlearn: 0.6333967\ttotal: 4m 7s\tremaining: 4m 14s\n",
      "357:\tlearn: 0.6282197\ttotal: 4m 7s\tremaining: 3m 56s\n",
      "345:\tlearn: 0.6332766\ttotal: 4m 8s\tremaining: 4m 13s\n",
      "358:\tlearn: 0.6281863\ttotal: 4m 8s\tremaining: 3m 56s\n",
      "346:\tlearn: 0.6330916\ttotal: 4m 8s\tremaining: 4m 13s\n",
      "359:\tlearn: 0.6280717\ttotal: 4m 9s\tremaining: 3m 55s\n",
      "347:\tlearn: 0.6330314\ttotal: 4m 9s\tremaining: 4m 12s\n",
      "360:\tlearn: 0.6278599\ttotal: 4m 9s\tremaining: 3m 54s\n",
      "348:\tlearn: 0.6327516\ttotal: 4m 10s\tremaining: 4m 11s\n",
      "361:\tlearn: 0.6278008\ttotal: 4m 10s\tremaining: 3m 53s\n",
      "349:\tlearn: 0.6325745\ttotal: 4m 11s\tremaining: 4m 11s\n",
      "362:\tlearn: 0.6277446\ttotal: 4m 11s\tremaining: 3m 53s\n",
      "350:\tlearn: 0.6325083\ttotal: 4m 11s\tremaining: 4m 10s\n",
      "363:\tlearn: 0.6276143\ttotal: 4m 11s\tremaining: 3m 52s\n",
      "364:\tlearn: 0.6275559\ttotal: 4m 12s\tremaining: 3m 51s\n",
      "351:\tlearn: 0.6323792\ttotal: 4m 12s\tremaining: 4m 9s\n",
      "365:\tlearn: 0.6275013\ttotal: 4m 13s\tremaining: 3m 51s\n",
      "352:\tlearn: 0.6322613\ttotal: 4m 13s\tremaining: 4m 9s\n",
      "366:\tlearn: 0.6274540\ttotal: 4m 13s\tremaining: 3m 50s\n",
      "353:\tlearn: 0.6321787\ttotal: 4m 14s\tremaining: 4m 8s\n",
      "367:\tlearn: 0.6274118\ttotal: 4m 14s\tremaining: 3m 49s\n",
      "354:\tlearn: 0.6320738\ttotal: 4m 14s\tremaining: 4m 7s\n",
      "368:\tlearn: 0.6273876\ttotal: 4m 15s\tremaining: 3m 49s\n",
      "355:\tlearn: 0.6319594\ttotal: 4m 15s\tremaining: 4m 6s\n",
      "369:\tlearn: 0.6273648\ttotal: 4m 16s\tremaining: 3m 48s\n",
      "356:\tlearn: 0.6319259\ttotal: 4m 16s\tremaining: 4m 6s\n",
      "370:\tlearn: 0.6272852\ttotal: 4m 16s\tremaining: 3m 47s\n",
      "357:\tlearn: 0.6318446\ttotal: 4m 17s\tremaining: 4m 5s\n",
      "371:\tlearn: 0.6271917\ttotal: 4m 17s\tremaining: 3m 47s\n",
      "358:\tlearn: 0.6317070\ttotal: 4m 17s\tremaining: 4m 4s\n",
      "372:\tlearn: 0.6271368\ttotal: 4m 18s\tremaining: 3m 46s\n",
      "359:\tlearn: 0.6315003\ttotal: 4m 18s\tremaining: 4m 4s\n",
      "373:\tlearn: 0.6270788\ttotal: 4m 18s\tremaining: 3m 45s\n",
      "360:\tlearn: 0.6314514\ttotal: 4m 19s\tremaining: 4m 3s\n",
      "374:\tlearn: 0.6270212\ttotal: 4m 19s\tremaining: 3m 45s\n",
      "361:\tlearn: 0.6313866\ttotal: 4m 19s\tremaining: 4m 2s\n",
      "375:\tlearn: 0.6269928\ttotal: 4m 20s\tremaining: 3m 44s\n",
      "362:\tlearn: 0.6312805\ttotal: 4m 20s\tremaining: 4m 1s\n",
      "376:\tlearn: 0.6269489\ttotal: 4m 21s\tremaining: 3m 43s\n",
      "363:\tlearn: 0.6312374\ttotal: 4m 21s\tremaining: 4m 1s\n",
      "377:\tlearn: 0.6269202\ttotal: 4m 21s\tremaining: 3m 42s\n",
      "364:\tlearn: 0.6310453\ttotal: 4m 22s\tremaining: 4m\n",
      "378:\tlearn: 0.6267906\ttotal: 4m 22s\tremaining: 3m 42s\n",
      "365:\tlearn: 0.6309900\ttotal: 4m 22s\tremaining: 3m 59s\n",
      "379:\tlearn: 0.6266287\ttotal: 4m 23s\tremaining: 3m 41s\n",
      "366:\tlearn: 0.6309335\ttotal: 4m 23s\tremaining: 3m 59s\n",
      "380:\tlearn: 0.6265713\ttotal: 4m 23s\tremaining: 3m 40s\n",
      "367:\tlearn: 0.6308981\ttotal: 4m 24s\tremaining: 3m 58s\n",
      "381:\tlearn: 0.6265190\ttotal: 4m 24s\tremaining: 3m 40s\n",
      "368:\tlearn: 0.6308470\ttotal: 4m 24s\tremaining: 3m 57s\n",
      "382:\tlearn: 0.6264745\ttotal: 4m 25s\tremaining: 3m 39s\n",
      "369:\tlearn: 0.6308137\ttotal: 4m 25s\tremaining: 3m 56s\n",
      "383:\tlearn: 0.6264281\ttotal: 4m 25s\tremaining: 3m 38s\n",
      "370:\tlearn: 0.6307319\ttotal: 4m 26s\tremaining: 3m 56s\n",
      "384:\tlearn: 0.6262176\ttotal: 4m 26s\tremaining: 3m 38s\n",
      "371:\tlearn: 0.6306017\ttotal: 4m 27s\tremaining: 3m 55s\n",
      "385:\tlearn: 0.6261697\ttotal: 4m 27s\tremaining: 3m 37s\n",
      "372:\tlearn: 0.6305676\ttotal: 4m 27s\tremaining: 3m 54s\n",
      "386:\tlearn: 0.6260979\ttotal: 4m 27s\tremaining: 3m 36s\n",
      "373:\tlearn: 0.6304783\ttotal: 4m 28s\tremaining: 3m 54s\n",
      "387:\tlearn: 0.6259870\ttotal: 4m 28s\tremaining: 3m 36s\n",
      "374:\tlearn: 0.6304419\ttotal: 4m 29s\tremaining: 3m 53s\n",
      "388:\tlearn: 0.6259598\ttotal: 4m 29s\tremaining: 3m 35s\n",
      "375:\tlearn: 0.6303982\ttotal: 4m 30s\tremaining: 3m 52s\n",
      "389:\tlearn: 0.6259285\ttotal: 4m 30s\tremaining: 3m 34s\n",
      "376:\tlearn: 0.6303506\ttotal: 4m 30s\tremaining: 3m 51s\n",
      "390:\tlearn: 0.6258452\ttotal: 4m 30s\tremaining: 3m 34s\n",
      "377:\tlearn: 0.6302687\ttotal: 4m 31s\tremaining: 3m 51s\n",
      "391:\tlearn: 0.6257941\ttotal: 4m 31s\tremaining: 3m 33s\n",
      "378:\tlearn: 0.6301482\ttotal: 4m 32s\tremaining: 3m 50s\n",
      "392:\tlearn: 0.6257235\ttotal: 4m 32s\tremaining: 3m 32s\n",
      "379:\tlearn: 0.6300976\ttotal: 4m 32s\tremaining: 3m 49s\n",
      "393:\tlearn: 0.6256978\ttotal: 4m 33s\tremaining: 3m 32s\n",
      "380:\tlearn: 0.6300116\ttotal: 4m 33s\tremaining: 3m 49s\n",
      "394:\tlearn: 0.6256596\ttotal: 4m 33s\tremaining: 3m 31s\n",
      "381:\tlearn: 0.6299584\ttotal: 4m 34s\tremaining: 3m 48s\n",
      "395:\tlearn: 0.6256019\ttotal: 4m 34s\tremaining: 3m 30s\n",
      "382:\tlearn: 0.6299181\ttotal: 4m 35s\tremaining: 3m 47s\n",
      "396:\tlearn: 0.6255792\ttotal: 4m 35s\tremaining: 3m 29s\n",
      "383:\tlearn: 0.6298242\ttotal: 4m 35s\tremaining: 3m 46s\n",
      "397:\tlearn: 0.6255610\ttotal: 4m 35s\tremaining: 3m 29s\n",
      "384:\tlearn: 0.6297494\ttotal: 4m 36s\tremaining: 3m 46s\n",
      "398:\tlearn: 0.6255405\ttotal: 4m 36s\tremaining: 3m 28s\n",
      "385:\tlearn: 0.6296496\ttotal: 4m 37s\tremaining: 3m 45s\n",
      "399:\tlearn: 0.6255077\ttotal: 4m 37s\tremaining: 3m 27s\n",
      "386:\tlearn: 0.6295892\ttotal: 4m 37s\tremaining: 3m 44s\n",
      "400:\tlearn: 0.6254787\ttotal: 4m 37s\tremaining: 3m 27s\n",
      "387:\tlearn: 0.6295410\ttotal: 4m 38s\tremaining: 3m 44s\n",
      "401:\tlearn: 0.6253311\ttotal: 4m 38s\tremaining: 3m 26s\n",
      "388:\tlearn: 0.6295153\ttotal: 4m 39s\tremaining: 3m 43s\n",
      "402:\tlearn: 0.6253038\ttotal: 4m 39s\tremaining: 3m 25s\n",
      "389:\tlearn: 0.6294563\ttotal: 4m 39s\tremaining: 3m 42s\n",
      "403:\tlearn: 0.6252006\ttotal: 4m 40s\tremaining: 3m 25s\n",
      "390:\tlearn: 0.6294135\ttotal: 4m 40s\tremaining: 3m 41s\n",
      "404:\tlearn: 0.6251690\ttotal: 4m 40s\tremaining: 3m 24s\n",
      "391:\tlearn: 0.6293506\ttotal: 4m 41s\tremaining: 3m 41s\n",
      "405:\tlearn: 0.6250988\ttotal: 4m 41s\tremaining: 3m 23s\n",
      "392:\tlearn: 0.6292952\ttotal: 4m 42s\tremaining: 3m 40s\n",
      "406:\tlearn: 0.6248260\ttotal: 4m 42s\tremaining: 3m 23s\n",
      "407:\tlearn: 0.6247546\ttotal: 4m 42s\tremaining: 3m 22s\n",
      "393:\tlearn: 0.6291850\ttotal: 4m 42s\tremaining: 3m 39s\n",
      "408:\tlearn: 0.6246551\ttotal: 4m 43s\tremaining: 3m 21s\n",
      "394:\tlearn: 0.6291140\ttotal: 4m 43s\tremaining: 3m 38s\n",
      "409:\tlearn: 0.6246019\ttotal: 4m 44s\tremaining: 3m 21s\n",
      "395:\tlearn: 0.6290699\ttotal: 4m 44s\tremaining: 3m 38s\n",
      "410:\tlearn: 0.6244391\ttotal: 4m 44s\tremaining: 3m 20s\n",
      "396:\tlearn: 0.6290255\ttotal: 4m 45s\tremaining: 3m 37s\n",
      "411:\tlearn: 0.6243604\ttotal: 4m 45s\tremaining: 3m 19s\n",
      "397:\tlearn: 0.6289666\ttotal: 4m 45s\tremaining: 3m 36s\n",
      "412:\tlearn: 0.6242796\ttotal: 4m 46s\tremaining: 3m 19s\n",
      "398:\tlearn: 0.6289229\ttotal: 4m 46s\tremaining: 3m 36s\n",
      "413:\tlearn: 0.6242145\ttotal: 4m 47s\tremaining: 3m 18s\n",
      "399:\tlearn: 0.6288739\ttotal: 4m 47s\tremaining: 3m 35s\n",
      "414:\tlearn: 0.6241916\ttotal: 4m 47s\tremaining: 3m 17s\n",
      "400:\tlearn: 0.6287972\ttotal: 4m 47s\tremaining: 3m 34s\n",
      "415:\tlearn: 0.6241084\ttotal: 4m 48s\tremaining: 3m 16s\n",
      "401:\tlearn: 0.6287565\ttotal: 4m 48s\tremaining: 3m 33s\n",
      "416:\tlearn: 0.6240660\ttotal: 4m 49s\tremaining: 3m 16s\n",
      "402:\tlearn: 0.6287238\ttotal: 4m 49s\tremaining: 3m 33s\n",
      "417:\tlearn: 0.6240135\ttotal: 4m 49s\tremaining: 3m 15s\n",
      "403:\tlearn: 0.6286958\ttotal: 4m 50s\tremaining: 3m 32s\n",
      "418:\tlearn: 0.6239596\ttotal: 4m 50s\tremaining: 3m 14s\n",
      "404:\tlearn: 0.6285916\ttotal: 4m 50s\tremaining: 3m 31s\n",
      "419:\tlearn: 0.6239126\ttotal: 4m 51s\tremaining: 3m 14s\n",
      "405:\tlearn: 0.6284888\ttotal: 4m 51s\tremaining: 3m 31s\n",
      "420:\tlearn: 0.6238622\ttotal: 4m 52s\tremaining: 3m 13s\n",
      "406:\tlearn: 0.6284650\ttotal: 4m 52s\tremaining: 3m 30s\n",
      "421:\tlearn: 0.6238408\ttotal: 4m 52s\tremaining: 3m 12s\n",
      "407:\tlearn: 0.6284162\ttotal: 4m 52s\tremaining: 3m 29s\n",
      "422:\tlearn: 0.6237791\ttotal: 4m 53s\tremaining: 3m 12s\n",
      "408:\tlearn: 0.6283445\ttotal: 4m 53s\tremaining: 3m 28s\n",
      "423:\tlearn: 0.6235965\ttotal: 4m 54s\tremaining: 3m 11s\n",
      "409:\tlearn: 0.6282795\ttotal: 4m 54s\tremaining: 3m 28s\n",
      "424:\tlearn: 0.6235101\ttotal: 4m 54s\tremaining: 3m 10s\n",
      "410:\tlearn: 0.6282076\ttotal: 4m 54s\tremaining: 3m 27s\n",
      "425:\tlearn: 0.6234154\ttotal: 4m 55s\tremaining: 3m 10s\n",
      "411:\tlearn: 0.6281167\ttotal: 4m 55s\tremaining: 3m 26s\n",
      "426:\tlearn: 0.6232930\ttotal: 4m 56s\tremaining: 3m 9s\n",
      "412:\tlearn: 0.6280682\ttotal: 4m 56s\tremaining: 3m 25s\n",
      "427:\tlearn: 0.6232649\ttotal: 4m 57s\tremaining: 3m 8s\n",
      "413:\tlearn: 0.6280171\ttotal: 4m 57s\tremaining: 3m 25s\n",
      "428:\tlearn: 0.6232208\ttotal: 4m 57s\tremaining: 3m 8s\n",
      "414:\tlearn: 0.6279366\ttotal: 4m 57s\tremaining: 3m 24s\n",
      "429:\tlearn: 0.6231862\ttotal: 4m 58s\tremaining: 3m 7s\n",
      "415:\tlearn: 0.6278311\ttotal: 4m 58s\tremaining: 3m 23s\n",
      "430:\tlearn: 0.6230099\ttotal: 4m 59s\tremaining: 3m 6s\n",
      "416:\tlearn: 0.6277598\ttotal: 4m 59s\tremaining: 3m 23s\n",
      "431:\tlearn: 0.6229507\ttotal: 4m 59s\tremaining: 3m 5s\n",
      "417:\tlearn: 0.6277269\ttotal: 5m\tremaining: 3m 22s\n",
      "432:\tlearn: 0.6229141\ttotal: 5m\tremaining: 3m 5s\n",
      "418:\tlearn: 0.6276950\ttotal: 5m\tremaining: 3m 21s\n",
      "433:\tlearn: 0.6227955\ttotal: 5m 1s\tremaining: 3m 4s\n",
      "419:\tlearn: 0.6275950\ttotal: 5m 1s\tremaining: 3m 20s\n",
      "434:\tlearn: 0.6226903\ttotal: 5m 1s\tremaining: 3m 3s\n",
      "420:\tlearn: 0.6275358\ttotal: 5m 2s\tremaining: 3m 20s\n",
      "435:\tlearn: 0.6225491\ttotal: 5m 2s\tremaining: 3m 3s\n",
      "421:\tlearn: 0.6272349\ttotal: 5m 2s\tremaining: 3m 19s\n",
      "436:\tlearn: 0.6222934\ttotal: 5m 3s\tremaining: 3m 2s\n",
      "422:\tlearn: 0.6272036\ttotal: 5m 3s\tremaining: 3m 18s\n",
      "437:\tlearn: 0.6222529\ttotal: 5m 4s\tremaining: 3m 1s\n",
      "423:\tlearn: 0.6270969\ttotal: 5m 4s\tremaining: 3m 18s\n",
      "438:\tlearn: 0.6221754\ttotal: 5m 4s\tremaining: 3m 1s\n",
      "424:\tlearn: 0.6270665\ttotal: 5m 5s\tremaining: 3m 17s\n",
      "439:\tlearn: 0.6220536\ttotal: 5m 5s\tremaining: 3m\n",
      "425:\tlearn: 0.6270330\ttotal: 5m 5s\tremaining: 3m 16s\n",
      "440:\tlearn: 0.6219998\ttotal: 5m 5s\tremaining: 2m 59s\n",
      "426:\tlearn: 0.6269296\ttotal: 5m 6s\tremaining: 3m 16s\n",
      "441:\tlearn: 0.6219491\ttotal: 5m 6s\tremaining: 2m 59s\n",
      "427:\tlearn: 0.6268692\ttotal: 5m 7s\tremaining: 3m 15s\n",
      "442:\tlearn: 0.6218286\ttotal: 5m 7s\tremaining: 2m 58s\n",
      "428:\tlearn: 0.6268259\ttotal: 5m 8s\tremaining: 3m 14s\n",
      "443:\tlearn: 0.6217926\ttotal: 5m 8s\tremaining: 2m 57s\n",
      "429:\tlearn: 0.6267764\ttotal: 5m 8s\tremaining: 3m 13s\n",
      "444:\tlearn: 0.6215929\ttotal: 5m 8s\tremaining: 2m 56s\n",
      "430:\tlearn: 0.6267425\ttotal: 5m 9s\tremaining: 3m 13s\n",
      "445:\tlearn: 0.6215574\ttotal: 5m 9s\tremaining: 2m 56s\n",
      "431:\tlearn: 0.6266901\ttotal: 5m 10s\tremaining: 3m 12s\n",
      "446:\tlearn: 0.6215272\ttotal: 5m 10s\tremaining: 2m 55s\n",
      "432:\tlearn: 0.6266264\ttotal: 5m 10s\tremaining: 3m 11s\n",
      "447:\tlearn: 0.6214947\ttotal: 5m 10s\tremaining: 2m 54s\n",
      "448:\tlearn: 0.6214327\ttotal: 5m 11s\tremaining: 2m 54s\n",
      "433:\tlearn: 0.6265378\ttotal: 5m 11s\tremaining: 3m 10s\n",
      "449:\tlearn: 0.6213888\ttotal: 5m 12s\tremaining: 2m 53s\n",
      "434:\tlearn: 0.6265075\ttotal: 5m 12s\tremaining: 3m 10s\n",
      "450:\tlearn: 0.6212949\ttotal: 5m 13s\tremaining: 2m 52s\n",
      "435:\tlearn: 0.6264535\ttotal: 5m 13s\tremaining: 3m 9s\n",
      "451:\tlearn: 0.6212407\ttotal: 5m 13s\tremaining: 2m 52s\n",
      "436:\tlearn: 0.6264049\ttotal: 5m 13s\tremaining: 3m 8s\n",
      "452:\tlearn: 0.6211528\ttotal: 5m 14s\tremaining: 2m 51s\n",
      "437:\tlearn: 0.6263648\ttotal: 5m 14s\tremaining: 3m 8s\n",
      "453:\tlearn: 0.6211086\ttotal: 5m 15s\tremaining: 2m 50s\n",
      "438:\tlearn: 0.6263066\ttotal: 5m 15s\tremaining: 3m 7s\n",
      "454:\tlearn: 0.6210267\ttotal: 5m 15s\tremaining: 2m 50s\n",
      "439:\tlearn: 0.6262021\ttotal: 5m 15s\tremaining: 3m 6s\n",
      "455:\tlearn: 0.6209726\ttotal: 5m 16s\tremaining: 2m 49s\n",
      "440:\tlearn: 0.6261673\ttotal: 5m 16s\tremaining: 3m 5s\n",
      "456:\tlearn: 0.6208780\ttotal: 5m 17s\tremaining: 2m 48s\n",
      "441:\tlearn: 0.6260612\ttotal: 5m 17s\tremaining: 3m 5s\n",
      "457:\tlearn: 0.6208142\ttotal: 5m 17s\tremaining: 2m 48s\n",
      "442:\tlearn: 0.6260133\ttotal: 5m 18s\tremaining: 3m 4s\n",
      "458:\tlearn: 0.6206602\ttotal: 5m 18s\tremaining: 2m 47s\n",
      "443:\tlearn: 0.6259733\ttotal: 5m 18s\tremaining: 3m 3s\n",
      "459:\tlearn: 0.6206268\ttotal: 5m 19s\tremaining: 2m 46s\n",
      "444:\tlearn: 0.6258749\ttotal: 5m 19s\tremaining: 3m 3s\n",
      "460:\tlearn: 0.6205614\ttotal: 5m 20s\tremaining: 2m 45s\n",
      "445:\tlearn: 0.6257947\ttotal: 5m 20s\tremaining: 3m 2s\n",
      "461:\tlearn: 0.6204499\ttotal: 5m 20s\tremaining: 2m 45s\n",
      "446:\tlearn: 0.6257725\ttotal: 5m 21s\tremaining: 3m 1s\n",
      "462:\tlearn: 0.6203852\ttotal: 5m 21s\tremaining: 2m 44s\n",
      "447:\tlearn: 0.6257157\ttotal: 5m 21s\tremaining: 3m\n",
      "463:\tlearn: 0.6202505\ttotal: 5m 22s\tremaining: 2m 43s\n",
      "448:\tlearn: 0.6256715\ttotal: 5m 22s\tremaining: 3m\n",
      "464:\tlearn: 0.6201867\ttotal: 5m 22s\tremaining: 2m 43s\n",
      "449:\tlearn: 0.6255981\ttotal: 5m 23s\tremaining: 2m 59s\n",
      "465:\tlearn: 0.6201244\ttotal: 5m 23s\tremaining: 2m 42s\n",
      "450:\tlearn: 0.6255314\ttotal: 5m 23s\tremaining: 2m 58s\n",
      "466:\tlearn: 0.6200737\ttotal: 5m 24s\tremaining: 2m 41s\n",
      "451:\tlearn: 0.6255000\ttotal: 5m 24s\tremaining: 2m 58s\n",
      "467:\tlearn: 0.6199538\ttotal: 5m 25s\tremaining: 2m 41s\n",
      "452:\tlearn: 0.6254378\ttotal: 5m 25s\tremaining: 2m 57s\n",
      "468:\tlearn: 0.6199237\ttotal: 5m 25s\tremaining: 2m 40s\n",
      "453:\tlearn: 0.6253237\ttotal: 5m 26s\tremaining: 2m 56s\n",
      "469:\tlearn: 0.6198698\ttotal: 5m 26s\tremaining: 2m 39s\n",
      "454:\tlearn: 0.6252248\ttotal: 5m 26s\tremaining: 2m 56s\n",
      "470:\tlearn: 0.6197329\ttotal: 5m 27s\tremaining: 2m 39s\n",
      "455:\tlearn: 0.6250667\ttotal: 5m 27s\tremaining: 2m 55s\n",
      "471:\tlearn: 0.6196459\ttotal: 5m 27s\tremaining: 2m 38s\n",
      "472:\tlearn: 0.6195965\ttotal: 5m 28s\tremaining: 2m 37s\n",
      "456:\tlearn: 0.6250082\ttotal: 5m 28s\tremaining: 2m 54s\n",
      "473:\tlearn: 0.6195582\ttotal: 5m 29s\tremaining: 2m 36s\n",
      "457:\tlearn: 0.6249639\ttotal: 5m 29s\tremaining: 2m 53s\n",
      "474:\tlearn: 0.6194163\ttotal: 5m 29s\tremaining: 2m 36s\n",
      "458:\tlearn: 0.6249312\ttotal: 5m 29s\tremaining: 2m 53s\n",
      "475:\tlearn: 0.6193680\ttotal: 5m 30s\tremaining: 2m 35s\n",
      "459:\tlearn: 0.6248848\ttotal: 5m 30s\tremaining: 2m 52s\n",
      "476:\tlearn: 0.6192956\ttotal: 5m 31s\tremaining: 2m 34s\n",
      "460:\tlearn: 0.6248517\ttotal: 5m 31s\tremaining: 2m 51s\n",
      "461:\tlearn: 0.6247381\ttotal: 5m 32s\tremaining: 2m 51s\n",
      "477:\tlearn: 0.6192564\ttotal: 5m 32s\tremaining: 2m 34s\n",
      "478:\tlearn: 0.6191892\ttotal: 5m 32s\tremaining: 2m 33s\n",
      "462:\tlearn: 0.6247148\ttotal: 5m 32s\tremaining: 2m 50s\n",
      "479:\tlearn: 0.6191415\ttotal: 5m 33s\tremaining: 2m 32s\n",
      "463:\tlearn: 0.6246656\ttotal: 5m 33s\tremaining: 2m 49s\n",
      "480:\tlearn: 0.6190327\ttotal: 5m 34s\tremaining: 2m 32s\n",
      "464:\tlearn: 0.6246094\ttotal: 5m 34s\tremaining: 2m 48s\n",
      "481:\tlearn: 0.6189539\ttotal: 5m 34s\tremaining: 2m 31s\n",
      "465:\tlearn: 0.6245794\ttotal: 5m 35s\tremaining: 2m 48s\n",
      "482:\tlearn: 0.6189050\ttotal: 5m 35s\tremaining: 2m 30s\n",
      "466:\tlearn: 0.6244539\ttotal: 5m 35s\tremaining: 2m 47s\n",
      "483:\tlearn: 0.6187772\ttotal: 5m 36s\tremaining: 2m 30s\n",
      "467:\tlearn: 0.6243903\ttotal: 5m 36s\tremaining: 2m 46s\n",
      "484:\tlearn: 0.6187083\ttotal: 5m 36s\tremaining: 2m 29s\n",
      "468:\tlearn: 0.6243323\ttotal: 5m 37s\tremaining: 2m 46s\n",
      "485:\tlearn: 0.6185960\ttotal: 5m 37s\tremaining: 2m 28s\n",
      "469:\tlearn: 0.6242809\ttotal: 5m 38s\tremaining: 2m 45s\n",
      "486:\tlearn: 0.6185512\ttotal: 5m 38s\tremaining: 2m 27s\n",
      "470:\tlearn: 0.6242449\ttotal: 5m 38s\tremaining: 2m 44s\n",
      "487:\tlearn: 0.6184343\ttotal: 5m 38s\tremaining: 2m 27s\n",
      "471:\tlearn: 0.6241827\ttotal: 5m 39s\tremaining: 2m 43s\n",
      "488:\tlearn: 0.6183833\ttotal: 5m 39s\tremaining: 2m 26s\n",
      "472:\tlearn: 0.6241240\ttotal: 5m 40s\tremaining: 2m 43s\n",
      "489:\tlearn: 0.6183543\ttotal: 5m 40s\tremaining: 2m 25s\n",
      "473:\tlearn: 0.6241001\ttotal: 5m 40s\tremaining: 2m 42s\n",
      "490:\tlearn: 0.6183246\ttotal: 5m 40s\tremaining: 2m 25s\n",
      "474:\tlearn: 0.6239330\ttotal: 5m 41s\tremaining: 2m 41s\n",
      "491:\tlearn: 0.6182304\ttotal: 5m 41s\tremaining: 2m 24s\n",
      "475:\tlearn: 0.6238788\ttotal: 5m 42s\tremaining: 2m 41s\n",
      "492:\tlearn: 0.6181699\ttotal: 5m 42s\tremaining: 2m 23s\n",
      "476:\tlearn: 0.6238509\ttotal: 5m 42s\tremaining: 2m 40s\n",
      "493:\tlearn: 0.6181110\ttotal: 5m 42s\tremaining: 2m 22s\n",
      "494:\tlearn: 0.6180646\ttotal: 5m 43s\tremaining: 2m 22s\n",
      "477:\tlearn: 0.6237940\ttotal: 5m 43s\tremaining: 2m 39s\n",
      "478:\tlearn: 0.6237720\ttotal: 5m 44s\tremaining: 2m 38s\n",
      "495:\tlearn: 0.6180219\ttotal: 5m 44s\tremaining: 2m 21s\n",
      "496:\tlearn: 0.6179662\ttotal: 5m 45s\tremaining: 2m 20s\n",
      "479:\tlearn: 0.6235655\ttotal: 5m 45s\tremaining: 2m 38s\n",
      "497:\tlearn: 0.6178911\ttotal: 5m 45s\tremaining: 2m 20s\n",
      "480:\tlearn: 0.6234943\ttotal: 5m 45s\tremaining: 2m 37s\n",
      "498:\tlearn: 0.6178401\ttotal: 5m 46s\tremaining: 2m 19s\n",
      "481:\tlearn: 0.6234427\ttotal: 5m 46s\tremaining: 2m 36s\n",
      "499:\tlearn: 0.6177897\ttotal: 5m 47s\tremaining: 2m 18s\n",
      "482:\tlearn: 0.6232511\ttotal: 5m 47s\tremaining: 2m 36s\n",
      "500:\tlearn: 0.6177449\ttotal: 5m 47s\tremaining: 2m 18s\n",
      "483:\tlearn: 0.6231688\ttotal: 5m 48s\tremaining: 2m 35s\n",
      "501:\tlearn: 0.6176654\ttotal: 5m 48s\tremaining: 2m 17s\n",
      "484:\tlearn: 0.6230952\ttotal: 5m 48s\tremaining: 2m 34s\n",
      "502:\tlearn: 0.6176108\ttotal: 5m 49s\tremaining: 2m 16s\n",
      "485:\tlearn: 0.6230122\ttotal: 5m 49s\tremaining: 2m 33s\n",
      "503:\tlearn: 0.6175437\ttotal: 5m 49s\tremaining: 2m 16s\n",
      "486:\tlearn: 0.6229429\ttotal: 5m 50s\tremaining: 2m 33s\n",
      "504:\tlearn: 0.6174864\ttotal: 5m 50s\tremaining: 2m 15s\n",
      "487:\tlearn: 0.6228816\ttotal: 5m 50s\tremaining: 2m 32s\n",
      "505:\tlearn: 0.6174274\ttotal: 5m 51s\tremaining: 2m 14s\n",
      "488:\tlearn: 0.6228510\ttotal: 5m 51s\tremaining: 2m 31s\n",
      "506:\tlearn: 0.6173931\ttotal: 5m 52s\tremaining: 2m 14s\n",
      "489:\tlearn: 0.6228128\ttotal: 5m 52s\tremaining: 2m 30s\n",
      "507:\tlearn: 0.6171716\ttotal: 5m 52s\tremaining: 2m 13s\n",
      "490:\tlearn: 0.6227554\ttotal: 5m 52s\tremaining: 2m 30s\n",
      "508:\tlearn: 0.6171484\ttotal: 5m 53s\tremaining: 2m 12s\n",
      "491:\tlearn: 0.6227251\ttotal: 5m 53s\tremaining: 2m 29s\n",
      "509:\tlearn: 0.6171276\ttotal: 5m 54s\tremaining: 2m 11s\n",
      "492:\tlearn: 0.6226764\ttotal: 5m 54s\tremaining: 2m 28s\n",
      "510:\tlearn: 0.6170813\ttotal: 5m 54s\tremaining: 2m 11s\n",
      "493:\tlearn: 0.6226147\ttotal: 5m 55s\tremaining: 2m 28s\n",
      "511:\tlearn: 0.6170628\ttotal: 5m 55s\tremaining: 2m 10s\n",
      "494:\tlearn: 0.6225605\ttotal: 5m 55s\tremaining: 2m 27s\n",
      "512:\tlearn: 0.6170400\ttotal: 5m 56s\tremaining: 2m 9s\n",
      "495:\tlearn: 0.6225095\ttotal: 5m 56s\tremaining: 2m 26s\n",
      "513:\tlearn: 0.6169158\ttotal: 5m 56s\tremaining: 2m 9s\n",
      "496:\tlearn: 0.6223321\ttotal: 5m 57s\tremaining: 2m 25s\n",
      "514:\tlearn: 0.6168751\ttotal: 5m 57s\tremaining: 2m 8s\n",
      "497:\tlearn: 0.6222625\ttotal: 5m 58s\tremaining: 2m 25s\n",
      "515:\tlearn: 0.6168223\ttotal: 5m 58s\tremaining: 2m 7s\n",
      "498:\tlearn: 0.6222071\ttotal: 5m 58s\tremaining: 2m 24s\n",
      "516:\tlearn: 0.6167678\ttotal: 5m 58s\tremaining: 2m 7s\n",
      "499:\tlearn: 0.6221548\ttotal: 5m 59s\tremaining: 2m 23s\n",
      "517:\tlearn: 0.6166916\ttotal: 5m 59s\tremaining: 2m 6s\n",
      "500:\tlearn: 0.6221299\ttotal: 6m\tremaining: 2m 23s\n",
      "518:\tlearn: 0.6166004\ttotal: 6m\tremaining: 2m 5s\n",
      "501:\tlearn: 0.6220923\ttotal: 6m\tremaining: 2m 22s\n",
      "519:\tlearn: 0.6165047\ttotal: 6m 1s\tremaining: 2m 4s\n",
      "502:\tlearn: 0.6220096\ttotal: 6m 1s\tremaining: 2m 21s\n",
      "520:\tlearn: 0.6164789\ttotal: 6m 1s\tremaining: 2m 4s\n",
      "503:\tlearn: 0.6219780\ttotal: 6m 2s\tremaining: 2m 20s\n",
      "521:\tlearn: 0.6164461\ttotal: 6m 2s\tremaining: 2m 3s\n",
      "504:\tlearn: 0.6219465\ttotal: 6m 2s\tremaining: 2m 20s\n",
      "522:\tlearn: 0.6163887\ttotal: 6m 2s\tremaining: 2m 2s\n",
      "505:\tlearn: 0.6218889\ttotal: 6m 3s\tremaining: 2m 19s\n",
      "523:\tlearn: 0.6162678\ttotal: 6m 3s\tremaining: 2m 2s\n",
      "506:\tlearn: 0.6218120\ttotal: 6m 4s\tremaining: 2m 18s\n",
      "524:\tlearn: 0.6162142\ttotal: 6m 4s\tremaining: 2m 1s\n",
      "507:\tlearn: 0.6217649\ttotal: 6m 5s\tremaining: 2m 17s\n",
      "525:\tlearn: 0.6161828\ttotal: 6m 5s\tremaining: 2m\n",
      "508:\tlearn: 0.6217318\ttotal: 6m 5s\tremaining: 2m 17s\n",
      "526:\tlearn: 0.6161365\ttotal: 6m 5s\tremaining: 2m\n",
      "527:\tlearn: 0.6160927\ttotal: 6m 6s\tremaining: 1m 59s\n",
      "509:\tlearn: 0.6215941\ttotal: 6m 6s\tremaining: 2m 16s\n",
      "528:\tlearn: 0.6159999\ttotal: 6m 7s\tremaining: 1m 58s\n",
      "510:\tlearn: 0.6215367\ttotal: 6m 7s\tremaining: 2m 15s\n",
      "529:\tlearn: 0.6159605\ttotal: 6m 7s\tremaining: 1m 57s\n",
      "511:\tlearn: 0.6215115\ttotal: 6m 8s\tremaining: 2m 15s\n",
      "530:\tlearn: 0.6159248\ttotal: 6m 8s\tremaining: 1m 57s\n",
      "512:\tlearn: 0.6213210\ttotal: 6m 8s\tremaining: 2m 14s\n",
      "531:\tlearn: 0.6158062\ttotal: 6m 9s\tremaining: 1m 56s\n",
      "513:\tlearn: 0.6212363\ttotal: 6m 9s\tremaining: 2m 13s\n",
      "532:\tlearn: 0.6157254\ttotal: 6m 9s\tremaining: 1m 55s\n",
      "514:\tlearn: 0.6211627\ttotal: 6m 10s\tremaining: 2m 12s\n",
      "533:\tlearn: 0.6156705\ttotal: 6m 10s\tremaining: 1m 55s\n",
      "515:\tlearn: 0.6211121\ttotal: 6m 10s\tremaining: 2m 12s\n",
      "534:\tlearn: 0.6156297\ttotal: 6m 11s\tremaining: 1m 54s\n",
      "516:\tlearn: 0.6210650\ttotal: 6m 11s\tremaining: 2m 11s\n",
      "535:\tlearn: 0.6155072\ttotal: 6m 12s\tremaining: 1m 53s\n",
      "517:\tlearn: 0.6210065\ttotal: 6m 12s\tremaining: 2m 10s\n",
      "536:\tlearn: 0.6154572\ttotal: 6m 12s\tremaining: 1m 53s\n",
      "518:\tlearn: 0.6209753\ttotal: 6m 12s\tremaining: 2m 10s\n",
      "537:\tlearn: 0.6154287\ttotal: 6m 13s\tremaining: 1m 52s\n",
      "519:\tlearn: 0.6208570\ttotal: 6m 13s\tremaining: 2m 9s\n",
      "538:\tlearn: 0.6153651\ttotal: 6m 14s\tremaining: 1m 51s\n",
      "520:\tlearn: 0.6208106\ttotal: 6m 14s\tremaining: 2m 8s\n",
      "539:\tlearn: 0.6153250\ttotal: 6m 14s\tremaining: 1m 51s\n",
      "521:\tlearn: 0.6206600\ttotal: 6m 15s\tremaining: 2m 7s\n",
      "540:\tlearn: 0.6152554\ttotal: 6m 15s\tremaining: 1m 50s\n",
      "522:\tlearn: 0.6205289\ttotal: 6m 15s\tremaining: 2m 7s\n",
      "541:\tlearn: 0.6152266\ttotal: 6m 16s\tremaining: 1m 49s\n",
      "523:\tlearn: 0.6204664\ttotal: 6m 16s\tremaining: 2m 6s\n",
      "542:\tlearn: 0.6151826\ttotal: 6m 17s\tremaining: 1m 49s\n",
      "524:\tlearn: 0.6203772\ttotal: 6m 17s\tremaining: 2m 5s\n",
      "543:\tlearn: 0.6151605\ttotal: 6m 17s\tremaining: 1m 48s\n",
      "525:\tlearn: 0.6203299\ttotal: 6m 18s\tremaining: 2m 5s\n",
      "544:\tlearn: 0.6151215\ttotal: 6m 18s\tremaining: 1m 47s\n",
      "526:\tlearn: 0.6203069\ttotal: 6m 18s\tremaining: 2m 4s\n",
      "545:\tlearn: 0.6150754\ttotal: 6m 18s\tremaining: 1m 46s\n",
      "527:\tlearn: 0.6202618\ttotal: 6m 19s\tremaining: 2m 3s\n",
      "546:\tlearn: 0.6147583\ttotal: 6m 19s\tremaining: 1m 46s\n",
      "528:\tlearn: 0.6201806\ttotal: 6m 20s\tremaining: 2m 2s\n",
      "547:\tlearn: 0.6146937\ttotal: 6m 20s\tremaining: 1m 45s\n",
      "529:\tlearn: 0.6201467\ttotal: 6m 20s\tremaining: 2m 2s\n",
      "548:\tlearn: 0.6146167\ttotal: 6m 21s\tremaining: 1m 44s\n",
      "530:\tlearn: 0.6200930\ttotal: 6m 21s\tremaining: 2m 1s\n",
      "549:\tlearn: 0.6145910\ttotal: 6m 21s\tremaining: 1m 44s\n",
      "531:\tlearn: 0.6200616\ttotal: 6m 22s\tremaining: 2m\n",
      "550:\tlearn: 0.6144826\ttotal: 6m 22s\tremaining: 1m 43s\n",
      "532:\tlearn: 0.6199152\ttotal: 6m 23s\tremaining: 2m\n",
      "551:\tlearn: 0.6144315\ttotal: 6m 23s\tremaining: 1m 42s\n",
      "533:\tlearn: 0.6198881\ttotal: 6m 23s\tremaining: 1m 59s\n",
      "552:\tlearn: 0.6143533\ttotal: 6m 23s\tremaining: 1m 42s\n",
      "534:\tlearn: 0.6198488\ttotal: 6m 24s\tremaining: 1m 58s\n",
      "553:\tlearn: 0.6143251\ttotal: 6m 24s\tremaining: 1m 41s\n",
      "535:\tlearn: 0.6198099\ttotal: 6m 25s\tremaining: 1m 57s\n",
      "554:\tlearn: 0.6143076\ttotal: 6m 25s\tremaining: 1m 40s\n",
      "555:\tlearn: 0.6142702\ttotal: 6m 25s\tremaining: 1m 39s\n",
      "536:\tlearn: 0.6197680\ttotal: 6m 25s\tremaining: 1m 57s\n",
      "556:\tlearn: 0.6142079\ttotal: 6m 26s\tremaining: 1m 39s\n",
      "537:\tlearn: 0.6197098\ttotal: 6m 26s\tremaining: 1m 56s\n",
      "557:\tlearn: 0.6141847\ttotal: 6m 27s\tremaining: 1m 38s\n",
      "538:\tlearn: 0.6196332\ttotal: 6m 27s\tremaining: 1m 55s\n",
      "558:\tlearn: 0.6141449\ttotal: 6m 28s\tremaining: 1m 37s\n",
      "539:\tlearn: 0.6195932\ttotal: 6m 28s\tremaining: 1m 55s\n",
      "559:\tlearn: 0.6140940\ttotal: 6m 28s\tremaining: 1m 37s\n",
      "540:\tlearn: 0.6195447\ttotal: 6m 29s\tremaining: 1m 54s\n",
      "560:\tlearn: 0.6140640\ttotal: 6m 29s\tremaining: 1m 36s\n",
      "541:\tlearn: 0.6194379\ttotal: 6m 29s\tremaining: 1m 53s\n",
      "561:\tlearn: 0.6140365\ttotal: 6m 30s\tremaining: 1m 35s\n",
      "542:\tlearn: 0.6193586\ttotal: 6m 30s\tremaining: 1m 52s\n",
      "562:\tlearn: 0.6139900\ttotal: 6m 30s\tremaining: 1m 35s\n",
      "543:\tlearn: 0.6192857\ttotal: 6m 31s\tremaining: 1m 52s\n",
      "563:\tlearn: 0.6139513\ttotal: 6m 31s\tremaining: 1m 34s\n",
      "544:\tlearn: 0.6192464\ttotal: 6m 32s\tremaining: 1m 51s\n",
      "564:\tlearn: 0.6138962\ttotal: 6m 32s\tremaining: 1m 33s\n",
      "545:\tlearn: 0.6191816\ttotal: 6m 32s\tremaining: 1m 50s\n",
      "565:\tlearn: 0.6138675\ttotal: 6m 32s\tremaining: 1m 33s\n",
      "546:\tlearn: 0.6191530\ttotal: 6m 33s\tremaining: 1m 50s\n",
      "566:\tlearn: 0.6138402\ttotal: 6m 33s\tremaining: 1m 32s\n",
      "547:\tlearn: 0.6190722\ttotal: 6m 34s\tremaining: 1m 49s\n",
      "567:\tlearn: 0.6137747\ttotal: 6m 34s\tremaining: 1m 31s\n",
      "568:\tlearn: 0.6137457\ttotal: 6m 34s\tremaining: 1m 30s\n",
      "548:\tlearn: 0.6189581\ttotal: 6m 34s\tremaining: 1m 48s\n",
      "549:\tlearn: 0.6188719\ttotal: 6m 35s\tremaining: 1m 47s\n",
      "569:\tlearn: 0.6137199\ttotal: 6m 35s\tremaining: 1m 30s\n",
      "550:\tlearn: 0.6188232\ttotal: 6m 36s\tremaining: 1m 47s\n",
      "570:\tlearn: 0.6136739\ttotal: 6m 36s\tremaining: 1m 29s\n",
      "571:\tlearn: 0.6134989\ttotal: 6m 37s\tremaining: 1m 28s\n",
      "551:\tlearn: 0.6187072\ttotal: 6m 37s\tremaining: 1m 46s\n",
      "572:\tlearn: 0.6134471\ttotal: 6m 37s\tremaining: 1m 28s\n",
      "552:\tlearn: 0.6186535\ttotal: 6m 37s\tremaining: 1m 45s\n",
      "573:\tlearn: 0.6134184\ttotal: 6m 38s\tremaining: 1m 27s\n",
      "553:\tlearn: 0.6185612\ttotal: 6m 38s\tremaining: 1m 45s\n",
      "574:\tlearn: 0.6132987\ttotal: 6m 39s\tremaining: 1m 26s\n",
      "554:\tlearn: 0.6185206\ttotal: 6m 39s\tremaining: 1m 44s\n",
      "575:\tlearn: 0.6132617\ttotal: 6m 39s\tremaining: 1m 26s\n",
      "555:\tlearn: 0.6184782\ttotal: 6m 39s\tremaining: 1m 43s\n",
      "576:\tlearn: 0.6132318\ttotal: 6m 40s\tremaining: 1m 25s\n",
      "556:\tlearn: 0.6184381\ttotal: 6m 40s\tremaining: 1m 42s\n",
      "577:\tlearn: 0.6131674\ttotal: 6m 41s\tremaining: 1m 24s\n",
      "557:\tlearn: 0.6183971\ttotal: 6m 41s\tremaining: 1m 42s\n",
      "578:\tlearn: 0.6131354\ttotal: 6m 41s\tremaining: 1m 23s\n",
      "558:\tlearn: 0.6183735\ttotal: 6m 42s\tremaining: 1m 41s\n",
      "579:\tlearn: 0.6131078\ttotal: 6m 42s\tremaining: 1m 23s\n",
      "559:\tlearn: 0.6183103\ttotal: 6m 42s\tremaining: 1m 40s\n",
      "580:\tlearn: 0.6129749\ttotal: 6m 43s\tremaining: 1m 22s\n",
      "560:\tlearn: 0.6181901\ttotal: 6m 43s\tremaining: 1m 39s\n",
      "581:\tlearn: 0.6129453\ttotal: 6m 44s\tremaining: 1m 21s\n",
      "561:\tlearn: 0.6180590\ttotal: 6m 44s\tremaining: 1m 39s\n",
      "582:\tlearn: 0.6129042\ttotal: 6m 44s\tremaining: 1m 21s\n",
      "562:\tlearn: 0.6179977\ttotal: 6m 45s\tremaining: 1m 38s\n",
      "583:\tlearn: 0.6128514\ttotal: 6m 45s\tremaining: 1m 20s\n",
      "563:\tlearn: 0.6178487\ttotal: 6m 45s\tremaining: 1m 37s\n",
      "584:\tlearn: 0.6127869\ttotal: 6m 45s\tremaining: 1m 19s\n",
      "564:\tlearn: 0.6178030\ttotal: 6m 46s\tremaining: 1m 37s\n",
      "585:\tlearn: 0.6127264\ttotal: 6m 46s\tremaining: 1m 19s\n",
      "565:\tlearn: 0.6177610\ttotal: 6m 47s\tremaining: 1m 36s\n",
      "586:\tlearn: 0.6126901\ttotal: 6m 47s\tremaining: 1m 18s\n",
      "566:\tlearn: 0.6177394\ttotal: 6m 47s\tremaining: 1m 35s\n",
      "587:\tlearn: 0.6126436\ttotal: 6m 48s\tremaining: 1m 17s\n",
      "567:\tlearn: 0.6177144\ttotal: 6m 48s\tremaining: 1m 34s\n",
      "588:\tlearn: 0.6126039\ttotal: 6m 48s\tremaining: 1m 17s\n",
      "568:\tlearn: 0.6175676\ttotal: 6m 49s\tremaining: 1m 34s\n",
      "589:\tlearn: 0.6125494\ttotal: 6m 49s\tremaining: 1m 16s\n",
      "569:\tlearn: 0.6175270\ttotal: 6m 50s\tremaining: 1m 33s\n",
      "590:\tlearn: 0.6125141\ttotal: 6m 50s\tremaining: 1m 15s\n",
      "570:\tlearn: 0.6174978\ttotal: 6m 50s\tremaining: 1m 32s\n",
      "591:\tlearn: 0.6124692\ttotal: 6m 50s\tremaining: 1m 14s\n",
      "571:\tlearn: 0.6174385\ttotal: 6m 51s\tremaining: 1m 32s\n",
      "592:\tlearn: 0.6124083\ttotal: 6m 51s\tremaining: 1m 14s\n",
      "572:\tlearn: 0.6174072\ttotal: 6m 52s\tremaining: 1m 31s\n",
      "593:\tlearn: 0.6123355\ttotal: 6m 52s\tremaining: 1m 13s\n",
      "573:\tlearn: 0.6173426\ttotal: 6m 52s\tremaining: 1m 30s\n",
      "594:\tlearn: 0.6122642\ttotal: 6m 52s\tremaining: 1m 12s\n",
      "574:\tlearn: 0.6172972\ttotal: 6m 53s\tremaining: 1m 29s\n",
      "595:\tlearn: 0.6122151\ttotal: 6m 53s\tremaining: 1m 12s\n",
      "575:\tlearn: 0.6172401\ttotal: 6m 54s\tremaining: 1m 29s\n",
      "596:\tlearn: 0.6121678\ttotal: 6m 54s\tremaining: 1m 11s\n",
      "576:\tlearn: 0.6172096\ttotal: 6m 54s\tremaining: 1m 28s\n",
      "597:\tlearn: 0.6121165\ttotal: 6m 54s\tremaining: 1m 10s\n",
      "577:\tlearn: 0.6171647\ttotal: 6m 55s\tremaining: 1m 27s\n",
      "598:\tlearn: 0.6120909\ttotal: 6m 55s\tremaining: 1m 10s\n",
      "578:\tlearn: 0.6171326\ttotal: 6m 56s\tremaining: 1m 26s\n",
      "599:\tlearn: 0.6120680\ttotal: 6m 56s\tremaining: 1m 9s\n",
      "579:\tlearn: 0.6170869\ttotal: 6m 56s\tremaining: 1m 26s\n",
      "600:\tlearn: 0.6120490\ttotal: 6m 56s\tremaining: 1m 8s\n",
      "580:\tlearn: 0.6169472\ttotal: 6m 57s\tremaining: 1m 25s\n",
      "601:\tlearn: 0.6120053\ttotal: 6m 57s\tremaining: 1m 7s\n",
      "581:\tlearn: 0.6169235\ttotal: 6m 58s\tremaining: 1m 24s\n",
      "602:\tlearn: 0.6119588\ttotal: 6m 58s\tremaining: 1m 7s\n",
      "582:\tlearn: 0.6168862\ttotal: 6m 59s\tremaining: 1m 24s\n",
      "603:\tlearn: 0.6119055\ttotal: 6m 59s\tremaining: 1m 6s\n",
      "583:\tlearn: 0.6168619\ttotal: 6m 59s\tremaining: 1m 23s\n",
      "604:\tlearn: 0.6118494\ttotal: 6m 59s\tremaining: 1m 5s\n",
      "584:\tlearn: 0.6168054\ttotal: 7m\tremaining: 1m 22s\n",
      "605:\tlearn: 0.6118145\ttotal: 7m\tremaining: 1m 5s\n",
      "606:\tlearn: 0.6117913\ttotal: 7m 1s\tremaining: 1m 4s\n",
      "585:\tlearn: 0.6167713\ttotal: 7m 1s\tremaining: 1m 21s\n",
      "607:\tlearn: 0.6117582\ttotal: 7m 1s\tremaining: 1m 3s\n",
      "586:\tlearn: 0.6166851\ttotal: 7m 2s\tremaining: 1m 21s\n",
      "608:\tlearn: 0.6117265\ttotal: 7m 2s\tremaining: 1m 3s\n",
      "587:\tlearn: 0.6166365\ttotal: 7m 2s\tremaining: 1m 20s\n",
      "609:\tlearn: 0.6116424\ttotal: 7m 3s\tremaining: 1m 2s\n",
      "588:\tlearn: 0.6166091\ttotal: 7m 3s\tremaining: 1m 19s\n",
      "610:\tlearn: 0.6116098\ttotal: 7m 4s\tremaining: 1m 1s\n",
      "589:\tlearn: 0.6165532\ttotal: 7m 4s\tremaining: 1m 19s\n",
      "611:\tlearn: 0.6115466\ttotal: 7m 4s\tremaining: 1m 1s\n",
      "590:\tlearn: 0.6164020\ttotal: 7m 4s\tremaining: 1m 18s\n",
      "612:\tlearn: 0.6114791\ttotal: 7m 5s\tremaining: 1m\n",
      "591:\tlearn: 0.6162739\ttotal: 7m 5s\tremaining: 1m 17s\n",
      "613:\tlearn: 0.6114112\ttotal: 7m 6s\tremaining: 59.7s\n",
      "592:\tlearn: 0.6162435\ttotal: 7m 6s\tremaining: 1m 16s\n",
      "614:\tlearn: 0.6113127\ttotal: 7m 6s\tremaining: 59s\n",
      "593:\tlearn: 0.6161374\ttotal: 7m 7s\tremaining: 1m 16s\n",
      "615:\tlearn: 0.6112544\ttotal: 7m 7s\tremaining: 58.3s\n",
      "594:\tlearn: 0.6161046\ttotal: 7m 7s\tremaining: 1m 15s\n",
      "616:\tlearn: 0.6112351\ttotal: 7m 8s\tremaining: 57.6s\n",
      "595:\tlearn: 0.6160779\ttotal: 7m 8s\tremaining: 1m 14s\n",
      "617:\tlearn: 0.6111865\ttotal: 7m 8s\tremaining: 56.9s\n",
      "596:\tlearn: 0.6160370\ttotal: 7m 9s\tremaining: 1m 14s\n",
      "618:\tlearn: 0.6111209\ttotal: 7m 9s\tremaining: 56.2s\n",
      "597:\tlearn: 0.6160095\ttotal: 7m 10s\tremaining: 1m 13s\n",
      "619:\tlearn: 0.6110538\ttotal: 7m 10s\tremaining: 55.5s\n",
      "598:\tlearn: 0.6159858\ttotal: 7m 10s\tremaining: 1m 12s\n",
      "620:\tlearn: 0.6110219\ttotal: 7m 10s\tremaining: 54.8s\n",
      "599:\tlearn: 0.6159433\ttotal: 7m 11s\tremaining: 1m 11s\n",
      "621:\tlearn: 0.6109965\ttotal: 7m 11s\tremaining: 54.1s\n",
      "622:\tlearn: 0.6109799\ttotal: 7m 12s\tremaining: 53.4s\n",
      "600:\tlearn: 0.6158533\ttotal: 7m 12s\tremaining: 1m 11s\n",
      "623:\tlearn: 0.6109488\ttotal: 7m 12s\tremaining: 52.7s\n",
      "601:\tlearn: 0.6157451\ttotal: 7m 13s\tremaining: 1m 10s\n",
      "624:\tlearn: 0.6109137\ttotal: 7m 13s\tremaining: 52s\n",
      "602:\tlearn: 0.6156767\ttotal: 7m 13s\tremaining: 1m 9s\n",
      "625:\tlearn: 0.6108672\ttotal: 7m 14s\tremaining: 51.3s\n",
      "603:\tlearn: 0.6156374\ttotal: 7m 14s\tremaining: 1m 9s\n",
      "626:\tlearn: 0.6108191\ttotal: 7m 14s\tremaining: 50.6s\n",
      "604:\tlearn: 0.6156113\ttotal: 7m 15s\tremaining: 1m 8s\n",
      "627:\tlearn: 0.6107311\ttotal: 7m 15s\tremaining: 50s\n",
      "605:\tlearn: 0.6155210\ttotal: 7m 15s\tremaining: 1m 7s\n",
      "628:\tlearn: 0.6106488\ttotal: 7m 16s\tremaining: 49.3s\n",
      "606:\tlearn: 0.6154932\ttotal: 7m 16s\tremaining: 1m 6s\n",
      "629:\tlearn: 0.6106043\ttotal: 7m 17s\tremaining: 48.6s\n",
      "607:\tlearn: 0.6154704\ttotal: 7m 17s\tremaining: 1m 6s\n",
      "630:\tlearn: 0.6105808\ttotal: 7m 17s\tremaining: 47.9s\n",
      "608:\tlearn: 0.6154468\ttotal: 7m 18s\tremaining: 1m 5s\n",
      "631:\tlearn: 0.6105322\ttotal: 7m 18s\tremaining: 47.2s\n",
      "609:\tlearn: 0.6154128\ttotal: 7m 18s\tremaining: 1m 4s\n",
      "632:\tlearn: 0.6104789\ttotal: 7m 19s\tremaining: 46.5s\n",
      "610:\tlearn: 0.6154005\ttotal: 7m 19s\tremaining: 1m 4s\n",
      "633:\tlearn: 0.6104329\ttotal: 7m 19s\tremaining: 45.8s\n",
      "611:\tlearn: 0.6153269\ttotal: 7m 20s\tremaining: 1m 3s\n",
      "634:\tlearn: 0.6103957\ttotal: 7m 20s\tremaining: 45.1s\n",
      "612:\tlearn: 0.6152257\ttotal: 7m 20s\tremaining: 1m 2s\n",
      "635:\tlearn: 0.6103259\ttotal: 7m 21s\tremaining: 44.4s\n",
      "613:\tlearn: 0.6151950\ttotal: 7m 21s\tremaining: 1m 1s\n",
      "636:\tlearn: 0.6102553\ttotal: 7m 22s\tremaining: 43.7s\n",
      "614:\tlearn: 0.6151349\ttotal: 7m 22s\tremaining: 1m 1s\n",
      "637:\tlearn: 0.6102095\ttotal: 7m 22s\tremaining: 43s\n",
      "615:\tlearn: 0.6150961\ttotal: 7m 22s\tremaining: 1m\n",
      "638:\tlearn: 0.6101201\ttotal: 7m 23s\tremaining: 42.3s\n",
      "616:\tlearn: 0.6150466\ttotal: 7m 23s\tremaining: 59.7s\n",
      "639:\tlearn: 0.6100831\ttotal: 7m 23s\tremaining: 41.6s\n",
      "617:\tlearn: 0.6149819\ttotal: 7m 24s\tremaining: 59s\n",
      "640:\tlearn: 0.6100515\ttotal: 7m 24s\tremaining: 40.9s\n",
      "618:\tlearn: 0.6149410\ttotal: 7m 25s\tremaining: 58.3s\n",
      "641:\tlearn: 0.6100172\ttotal: 7m 25s\tremaining: 40.2s\n",
      "619:\tlearn: 0.6148921\ttotal: 7m 25s\tremaining: 57.5s\n",
      "642:\tlearn: 0.6099812\ttotal: 7m 25s\tremaining: 39.5s\n",
      "643:\tlearn: 0.6099388\ttotal: 7m 26s\tremaining: 38.8s\n",
      "620:\tlearn: 0.6148492\ttotal: 7m 26s\tremaining: 56.8s\n",
      "644:\tlearn: 0.6098838\ttotal: 7m 27s\tremaining: 38.1s\n",
      "621:\tlearn: 0.6147919\ttotal: 7m 27s\tremaining: 56.1s\n",
      "645:\tlearn: 0.6098666\ttotal: 7m 27s\tremaining: 37.4s\n",
      "622:\tlearn: 0.6146795\ttotal: 7m 28s\tremaining: 55.4s\n",
      "646:\tlearn: 0.6097490\ttotal: 7m 28s\tremaining: 36.8s\n",
      "623:\tlearn: 0.6145068\ttotal: 7m 28s\tremaining: 54.7s\n",
      "647:\tlearn: 0.6096732\ttotal: 7m 29s\tremaining: 36.1s\n",
      "624:\tlearn: 0.6143380\ttotal: 7m 29s\tremaining: 54s\n",
      "648:\tlearn: 0.6096484\ttotal: 7m 30s\tremaining: 35.4s\n",
      "625:\tlearn: 0.6143118\ttotal: 7m 30s\tremaining: 53.2s\n",
      "649:\tlearn: 0.6096271\ttotal: 7m 30s\tremaining: 34.7s\n",
      "626:\tlearn: 0.6142737\ttotal: 7m 31s\tremaining: 52.5s\n",
      "650:\tlearn: 0.6095981\ttotal: 7m 31s\tremaining: 34s\n",
      "627:\tlearn: 0.6142430\ttotal: 7m 31s\tremaining: 51.8s\n",
      "651:\tlearn: 0.6095520\ttotal: 7m 32s\tremaining: 33.3s\n",
      "628:\tlearn: 0.6142163\ttotal: 7m 32s\tremaining: 51.1s\n",
      "652:\tlearn: 0.6095351\ttotal: 7m 32s\tremaining: 32.6s\n",
      "629:\tlearn: 0.6141685\ttotal: 7m 33s\tremaining: 50.4s\n",
      "653:\tlearn: 0.6095042\ttotal: 7m 33s\tremaining: 31.9s\n",
      "630:\tlearn: 0.6141267\ttotal: 7m 33s\tremaining: 49.6s\n",
      "654:\tlearn: 0.6094652\ttotal: 7m 34s\tremaining: 31.2s\n",
      "631:\tlearn: 0.6140865\ttotal: 7m 34s\tremaining: 48.9s\n",
      "655:\tlearn: 0.6094368\ttotal: 7m 34s\tremaining: 30.5s\n",
      "632:\tlearn: 0.6137344\ttotal: 7m 35s\tremaining: 48.2s\n",
      "656:\tlearn: 0.6094041\ttotal: 7m 35s\tremaining: 29.8s\n",
      "633:\tlearn: 0.6136346\ttotal: 7m 36s\tremaining: 47.5s\n",
      "657:\tlearn: 0.6093548\ttotal: 7m 36s\tremaining: 29.1s\n",
      "634:\tlearn: 0.6134078\ttotal: 7m 36s\tremaining: 46.8s\n",
      "658:\tlearn: 0.6092347\ttotal: 7m 36s\tremaining: 28.4s\n",
      "635:\tlearn: 0.6133614\ttotal: 7m 37s\tremaining: 46s\n",
      "659:\tlearn: 0.6091655\ttotal: 7m 37s\tremaining: 27.7s\n",
      "636:\tlearn: 0.6132983\ttotal: 7m 38s\tremaining: 45.3s\n",
      "660:\tlearn: 0.6090660\ttotal: 7m 38s\tremaining: 27s\n",
      "637:\tlearn: 0.6132588\ttotal: 7m 38s\tremaining: 44.6s\n",
      "661:\tlearn: 0.6089902\ttotal: 7m 38s\tremaining: 26.3s\n",
      "662:\tlearn: 0.6089278\ttotal: 7m 39s\tremaining: 25.6s\n",
      "638:\tlearn: 0.6132187\ttotal: 7m 39s\tremaining: 43.9s\n",
      "663:\tlearn: 0.6088587\ttotal: 7m 40s\tremaining: 25s\n",
      "639:\tlearn: 0.6131872\ttotal: 7m 40s\tremaining: 43.2s\n",
      "664:\tlearn: 0.6088174\ttotal: 7m 41s\tremaining: 24.3s\n",
      "640:\tlearn: 0.6131508\ttotal: 7m 41s\tremaining: 42.4s\n",
      "665:\tlearn: 0.6086453\ttotal: 7m 41s\tremaining: 23.6s\n",
      "641:\tlearn: 0.6131017\ttotal: 7m 41s\tremaining: 41.7s\n",
      "666:\tlearn: 0.6085930\ttotal: 7m 42s\tremaining: 22.9s\n",
      "642:\tlearn: 0.6130675\ttotal: 7m 42s\tremaining: 41s\n",
      "667:\tlearn: 0.6085592\ttotal: 7m 43s\tremaining: 22.2s\n",
      "643:\tlearn: 0.6130310\ttotal: 7m 43s\tremaining: 40.3s\n",
      "668:\tlearn: 0.6084994\ttotal: 7m 43s\tremaining: 21.5s\n",
      "644:\tlearn: 0.6129434\ttotal: 7m 44s\tremaining: 39.6s\n",
      "669:\tlearn: 0.6084461\ttotal: 7m 44s\tremaining: 20.8s\n",
      "645:\tlearn: 0.6128767\ttotal: 7m 44s\tremaining: 38.8s\n",
      "670:\tlearn: 0.6084154\ttotal: 7m 45s\tremaining: 20.1s\n",
      "646:\tlearn: 0.6128301\ttotal: 7m 45s\tremaining: 38.1s\n",
      "671:\tlearn: 0.6083464\ttotal: 7m 45s\tremaining: 19.4s\n",
      "647:\tlearn: 0.6128149\ttotal: 7m 46s\tremaining: 37.4s\n",
      "672:\tlearn: 0.6082987\ttotal: 7m 46s\tremaining: 18.7s\n",
      "648:\tlearn: 0.6127729\ttotal: 7m 46s\tremaining: 36.7s\n",
      "673:\tlearn: 0.6082320\ttotal: 7m 47s\tremaining: 18s\n",
      "649:\tlearn: 0.6127399\ttotal: 7m 47s\tremaining: 36s\n",
      "674:\tlearn: 0.6082052\ttotal: 7m 47s\tremaining: 17.3s\n",
      "650:\tlearn: 0.6126999\ttotal: 7m 48s\tremaining: 35.3s\n",
      "675:\tlearn: 0.6081779\ttotal: 7m 48s\tremaining: 16.6s\n",
      "651:\tlearn: 0.6126467\ttotal: 7m 49s\tremaining: 34.5s\n",
      "676:\tlearn: 0.6080585\ttotal: 7m 49s\tremaining: 15.9s\n",
      "652:\tlearn: 0.6126166\ttotal: 7m 49s\tremaining: 33.8s\n",
      "677:\tlearn: 0.6079707\ttotal: 7m 49s\tremaining: 15.2s\n",
      "653:\tlearn: 0.6125315\ttotal: 7m 50s\tremaining: 33.1s\n",
      "678:\tlearn: 0.6079084\ttotal: 7m 50s\tremaining: 14.6s\n",
      "654:\tlearn: 0.6124249\ttotal: 7m 51s\tremaining: 32.4s\n",
      "679:\tlearn: 0.6078856\ttotal: 7m 51s\tremaining: 13.9s\n",
      "655:\tlearn: 0.6123890\ttotal: 7m 51s\tremaining: 31.6s\n",
      "680:\tlearn: 0.6078385\ttotal: 7m 51s\tremaining: 13.2s\n",
      "656:\tlearn: 0.6123188\ttotal: 7m 52s\tremaining: 30.9s\n",
      "681:\tlearn: 0.6078006\ttotal: 7m 52s\tremaining: 12.5s\n",
      "657:\tlearn: 0.6122603\ttotal: 7m 53s\tremaining: 30.2s\n",
      "682:\tlearn: 0.6077535\ttotal: 7m 53s\tremaining: 11.8s\n",
      "683:\tlearn: 0.6077062\ttotal: 7m 53s\tremaining: 11.1s\n",
      "658:\tlearn: 0.6122070\ttotal: 7m 53s\tremaining: 29.5s\n",
      "684:\tlearn: 0.6076649\ttotal: 7m 54s\tremaining: 10.4s\n",
      "659:\tlearn: 0.6121283\ttotal: 7m 54s\tremaining: 28.8s\n",
      "685:\tlearn: 0.6075964\ttotal: 7m 55s\tremaining: 9.7s\n",
      "660:\tlearn: 0.6120499\ttotal: 7m 55s\tremaining: 28s\n",
      "686:\tlearn: 0.6074760\ttotal: 7m 55s\tremaining: 9.01s\n",
      "661:\tlearn: 0.6120172\ttotal: 7m 56s\tremaining: 27.3s\n",
      "687:\tlearn: 0.6074520\ttotal: 7m 56s\tremaining: 8.31s\n",
      "662:\tlearn: 0.6118798\ttotal: 7m 56s\tremaining: 26.6s\n",
      "688:\tlearn: 0.6073551\ttotal: 7m 57s\tremaining: 7.62s\n",
      "663:\tlearn: 0.6118527\ttotal: 7m 57s\tremaining: 25.9s\n",
      "689:\tlearn: 0.6073067\ttotal: 7m 57s\tremaining: 6.92s\n",
      "690:\tlearn: 0.6071858\ttotal: 7m 58s\tremaining: 6.23s\n",
      "664:\tlearn: 0.6117413\ttotal: 7m 58s\tremaining: 25.2s\n",
      "691:\tlearn: 0.6071110\ttotal: 7m 58s\tremaining: 5.54s\n",
      "665:\tlearn: 0.6116964\ttotal: 7m 58s\tremaining: 24.5s\n",
      "692:\tlearn: 0.6069435\ttotal: 7m 59s\tremaining: 4.84s\n",
      "666:\tlearn: 0.6116207\ttotal: 7m 59s\tremaining: 23.7s\n",
      "693:\tlearn: 0.6069160\ttotal: 8m\tremaining: 4.15s\n",
      "667:\tlearn: 0.6115832\ttotal: 8m\tremaining: 23s\n",
      "694:\tlearn: 0.6068312\ttotal: 8m 1s\tremaining: 3.46s\n",
      "668:\tlearn: 0.6115344\ttotal: 8m 1s\tremaining: 22.3s\n",
      "695:\tlearn: 0.6067729\ttotal: 8m 1s\tremaining: 2.77s\n",
      "669:\tlearn: 0.6115111\ttotal: 8m 1s\tremaining: 21.6s\n",
      "696:\tlearn: 0.6067154\ttotal: 8m 2s\tremaining: 2.08s\n",
      "670:\tlearn: 0.6114760\ttotal: 8m 2s\tremaining: 20.9s\n",
      "697:\tlearn: 0.6066730\ttotal: 8m 3s\tremaining: 1.38s\n",
      "671:\tlearn: 0.6114257\ttotal: 8m 3s\tremaining: 20.1s\n",
      "698:\tlearn: 0.6065982\ttotal: 8m 3s\tremaining: 692ms\n",
      "672:\tlearn: 0.6113677\ttotal: 8m 4s\tremaining: 19.4s\n",
      "699:\tlearn: 0.6065645\ttotal: 8m 4s\tremaining: 0us\n",
      "673:\tlearn: 0.6113273\ttotal: 8m 4s\tremaining: 18.7s\n",
      "674:\tlearn: 0.6112706\ttotal: 8m 5s\tremaining: 18s\n",
      "[CV 2/2] END depth=12, learning_rate=0.01, n_estimators=700;, score=(train=0.830, test=0.595) total time= 8.1min\n",
      "675:\tlearn: 0.6112016\ttotal: 8m 5s\tremaining: 17.2s\n",
      "676:\tlearn: 0.6111335\ttotal: 8m 6s\tremaining: 16.5s\n",
      "677:\tlearn: 0.6110734\ttotal: 8m 6s\tremaining: 15.8s\n",
      "678:\tlearn: 0.6110095\ttotal: 8m 6s\tremaining: 15.1s\n",
      "679:\tlearn: 0.6109695\ttotal: 8m 7s\tremaining: 14.3s\n",
      "680:\tlearn: 0.6108671\ttotal: 8m 7s\tremaining: 13.6s\n",
      "681:\tlearn: 0.6106438\ttotal: 8m 8s\tremaining: 12.9s\n",
      "682:\tlearn: 0.6105999\ttotal: 8m 8s\tremaining: 12.2s\n",
      "683:\tlearn: 0.6105808\ttotal: 8m 9s\tremaining: 11.4s\n",
      "684:\tlearn: 0.6105135\ttotal: 8m 9s\tremaining: 10.7s\n",
      "685:\tlearn: 0.6104814\ttotal: 8m 9s\tremaining: 10s\n",
      "686:\tlearn: 0.6103418\ttotal: 8m 10s\tremaining: 9.28s\n",
      "687:\tlearn: 0.6103169\ttotal: 8m 10s\tremaining: 8.56s\n",
      "688:\tlearn: 0.6102561\ttotal: 8m 11s\tremaining: 7.84s\n",
      "689:\tlearn: 0.6102069\ttotal: 8m 11s\tremaining: 7.12s\n",
      "690:\tlearn: 0.6101581\ttotal: 8m 11s\tremaining: 6.41s\n",
      "691:\tlearn: 0.6101231\ttotal: 8m 12s\tremaining: 5.69s\n",
      "692:\tlearn: 0.6100584\ttotal: 8m 12s\tremaining: 4.98s\n",
      "693:\tlearn: 0.6099146\ttotal: 8m 13s\tremaining: 4.26s\n",
      "694:\tlearn: 0.6098513\ttotal: 8m 13s\tremaining: 3.55s\n",
      "695:\tlearn: 0.6098327\ttotal: 8m 14s\tremaining: 2.84s\n",
      "696:\tlearn: 0.6098046\ttotal: 8m 14s\tremaining: 2.13s\n",
      "697:\tlearn: 0.6096877\ttotal: 8m 14s\tremaining: 1.42s\n",
      "698:\tlearn: 0.6095661\ttotal: 8m 15s\tremaining: 709ms\n",
      "699:\tlearn: 0.6095117\ttotal: 8m 15s\tremaining: 0us\n",
      "[CV 1/2] END depth=12, learning_rate=0.01, n_estimators=700;, score=(train=0.818, test=0.593) total time= 8.3min\n",
      "0:\tlearn: 0.6927665\ttotal: 737ms\tremaining: 8m 34s\n",
      "1:\tlearn: 0.6925179\ttotal: 1.38s\tremaining: 8m 1s\n",
      "2:\tlearn: 0.6918448\ttotal: 2.04s\tremaining: 7m 54s\n",
      "3:\tlearn: 0.6914936\ttotal: 2.69s\tremaining: 7m 48s\n",
      "4:\tlearn: 0.6912807\ttotal: 2.72s\tremaining: 6m 18s\n",
      "5:\tlearn: 0.6909959\ttotal: 3.35s\tremaining: 6m 27s\n",
      "6:\tlearn: 0.6906743\ttotal: 4s\tremaining: 6m 36s\n",
      "7:\tlearn: 0.6902767\ttotal: 4.67s\tremaining: 6m 43s\n",
      "8:\tlearn: 0.6898365\ttotal: 5.32s\tremaining: 6m 48s\n",
      "9:\tlearn: 0.6894024\ttotal: 5.97s\tremaining: 6m 51s\n",
      "10:\tlearn: 0.6891983\ttotal: 6.61s\tremaining: 6m 53s\n",
      "11:\tlearn: 0.6889373\ttotal: 7.26s\tremaining: 6m 56s\n",
      "12:\tlearn: 0.6884954\ttotal: 7.91s\tremaining: 6m 58s\n",
      "13:\tlearn: 0.6881399\ttotal: 8.57s\tremaining: 6m 59s\n",
      "14:\tlearn: 0.6879098\ttotal: 9.22s\tremaining: 7m 1s\n",
      "15:\tlearn: 0.6874231\ttotal: 9.88s\tremaining: 7m 2s\n",
      "16:\tlearn: 0.6872056\ttotal: 10.5s\tremaining: 7m 3s\n",
      "17:\tlearn: 0.6869492\ttotal: 11.2s\tremaining: 7m 3s\n",
      "18:\tlearn: 0.6863593\ttotal: 11.9s\tremaining: 7m 5s\n",
      "19:\tlearn: 0.6860968\ttotal: 12.5s\tremaining: 7m 5s\n",
      "20:\tlearn: 0.6855852\ttotal: 13.2s\tremaining: 7m 6s\n",
      "21:\tlearn: 0.6853507\ttotal: 13.8s\tremaining: 7m 5s\n",
      "22:\tlearn: 0.6850772\ttotal: 14.5s\tremaining: 7m 6s\n",
      "23:\tlearn: 0.6848784\ttotal: 15.1s\tremaining: 7m 5s\n",
      "24:\tlearn: 0.6845787\ttotal: 15.8s\tremaining: 7m 5s\n",
      "25:\tlearn: 0.6839483\ttotal: 16.4s\tremaining: 7m 5s\n",
      "26:\tlearn: 0.6835387\ttotal: 17.1s\tremaining: 7m 5s\n",
      "27:\tlearn: 0.6832641\ttotal: 17.7s\tremaining: 7m 5s\n",
      "28:\tlearn: 0.6829155\ttotal: 18.4s\tremaining: 7m 5s\n",
      "29:\tlearn: 0.6826113\ttotal: 19s\tremaining: 7m 4s\n",
      "30:\tlearn: 0.6824597\ttotal: 19.7s\tremaining: 7m 4s\n",
      "31:\tlearn: 0.6822451\ttotal: 20.3s\tremaining: 7m 4s\n",
      "32:\tlearn: 0.6818925\ttotal: 21s\tremaining: 7m 3s\n",
      "33:\tlearn: 0.6815729\ttotal: 21.6s\tremaining: 7m 3s\n",
      "34:\tlearn: 0.6813244\ttotal: 22.3s\tremaining: 7m 3s\n",
      "35:\tlearn: 0.6811032\ttotal: 22.9s\tremaining: 7m 2s\n",
      "36:\tlearn: 0.6809371\ttotal: 23.5s\tremaining: 7m 1s\n",
      "37:\tlearn: 0.6807340\ttotal: 24.2s\tremaining: 7m 1s\n",
      "38:\tlearn: 0.6805934\ttotal: 24.8s\tremaining: 7m\n",
      "39:\tlearn: 0.6804019\ttotal: 25.5s\tremaining: 7m\n",
      "40:\tlearn: 0.6802205\ttotal: 26.1s\tremaining: 7m\n",
      "41:\tlearn: 0.6798832\ttotal: 26.8s\tremaining: 6m 59s\n",
      "42:\tlearn: 0.6797022\ttotal: 27.4s\tremaining: 6m 59s\n",
      "43:\tlearn: 0.6794058\ttotal: 28.1s\tremaining: 6m 58s\n",
      "44:\tlearn: 0.6790637\ttotal: 28.7s\tremaining: 6m 58s\n",
      "45:\tlearn: 0.6789266\ttotal: 29.4s\tremaining: 6m 57s\n",
      "46:\tlearn: 0.6787815\ttotal: 30s\tremaining: 6m 57s\n",
      "47:\tlearn: 0.6785173\ttotal: 30.7s\tremaining: 6m 56s\n",
      "48:\tlearn: 0.6782746\ttotal: 31.3s\tremaining: 6m 56s\n",
      "49:\tlearn: 0.6781051\ttotal: 32s\tremaining: 6m 55s\n",
      "50:\tlearn: 0.6779752\ttotal: 32.6s\tremaining: 6m 55s\n",
      "51:\tlearn: 0.6777399\ttotal: 33.3s\tremaining: 6m 54s\n",
      "52:\tlearn: 0.6775840\ttotal: 33.9s\tremaining: 6m 54s\n",
      "53:\tlearn: 0.6772951\ttotal: 34.6s\tremaining: 6m 53s\n",
      "54:\tlearn: 0.6770810\ttotal: 35.2s\tremaining: 6m 52s\n",
      "55:\tlearn: 0.6769894\ttotal: 35.8s\tremaining: 6m 52s\n",
      "56:\tlearn: 0.6768553\ttotal: 36.5s\tremaining: 6m 51s\n",
      "57:\tlearn: 0.6765104\ttotal: 37.1s\tremaining: 6m 50s\n",
      "58:\tlearn: 0.6763340\ttotal: 37.8s\tremaining: 6m 50s\n",
      "59:\tlearn: 0.6761409\ttotal: 38.4s\tremaining: 6m 49s\n",
      "60:\tlearn: 0.6759811\ttotal: 39.1s\tremaining: 6m 49s\n",
      "61:\tlearn: 0.6758746\ttotal: 39.7s\tremaining: 6m 48s\n",
      "62:\tlearn: 0.6756586\ttotal: 40.4s\tremaining: 6m 48s\n",
      "63:\tlearn: 0.6754477\ttotal: 41s\tremaining: 6m 47s\n",
      "64:\tlearn: 0.6751863\ttotal: 41.7s\tremaining: 6m 47s\n",
      "65:\tlearn: 0.6749197\ttotal: 42.3s\tremaining: 6m 46s\n",
      "66:\tlearn: 0.6748196\ttotal: 43s\tremaining: 6m 45s\n",
      "67:\tlearn: 0.6746603\ttotal: 43.6s\tremaining: 6m 45s\n",
      "68:\tlearn: 0.6742897\ttotal: 44.3s\tremaining: 6m 44s\n",
      "69:\tlearn: 0.6742007\ttotal: 44.9s\tremaining: 6m 44s\n",
      "70:\tlearn: 0.6740603\ttotal: 45.6s\tremaining: 6m 44s\n",
      "71:\tlearn: 0.6737926\ttotal: 46.3s\tremaining: 6m 43s\n",
      "72:\tlearn: 0.6736457\ttotal: 46.9s\tremaining: 6m 43s\n",
      "73:\tlearn: 0.6735371\ttotal: 47.6s\tremaining: 6m 42s\n",
      "74:\tlearn: 0.6733743\ttotal: 48.2s\tremaining: 6m 41s\n",
      "75:\tlearn: 0.6730701\ttotal: 48.9s\tremaining: 6m 41s\n",
      "76:\tlearn: 0.6729786\ttotal: 49.5s\tremaining: 6m 40s\n",
      "77:\tlearn: 0.6727360\ttotal: 50.2s\tremaining: 6m 40s\n",
      "78:\tlearn: 0.6725641\ttotal: 50.8s\tremaining: 6m 39s\n",
      "79:\tlearn: 0.6724278\ttotal: 51.5s\tremaining: 6m 39s\n",
      "80:\tlearn: 0.6721390\ttotal: 52.2s\tremaining: 6m 38s\n",
      "81:\tlearn: 0.6719683\ttotal: 52.8s\tremaining: 6m 38s\n",
      "82:\tlearn: 0.6718185\ttotal: 53.5s\tremaining: 6m 37s\n",
      "83:\tlearn: 0.6715998\ttotal: 54.1s\tremaining: 6m 37s\n",
      "84:\tlearn: 0.6715021\ttotal: 54.8s\tremaining: 6m 36s\n",
      "85:\tlearn: 0.6713944\ttotal: 55.4s\tremaining: 6m 35s\n",
      "86:\tlearn: 0.6712017\ttotal: 56.1s\tremaining: 6m 35s\n",
      "87:\tlearn: 0.6711009\ttotal: 56.7s\tremaining: 6m 34s\n",
      "88:\tlearn: 0.6709371\ttotal: 57.4s\tremaining: 6m 33s\n",
      "89:\tlearn: 0.6708137\ttotal: 58s\tremaining: 6m 33s\n",
      "90:\tlearn: 0.6706308\ttotal: 58.7s\tremaining: 6m 32s\n",
      "91:\tlearn: 0.6705352\ttotal: 59.3s\tremaining: 6m 32s\n",
      "92:\tlearn: 0.6704733\ttotal: 60s\tremaining: 6m 31s\n",
      "93:\tlearn: 0.6704011\ttotal: 1m\tremaining: 6m 30s\n",
      "94:\tlearn: 0.6702777\ttotal: 1m 1s\tremaining: 6m 30s\n",
      "95:\tlearn: 0.6701285\ttotal: 1m 1s\tremaining: 6m 29s\n",
      "96:\tlearn: 0.6700159\ttotal: 1m 2s\tremaining: 6m 28s\n",
      "97:\tlearn: 0.6697436\ttotal: 1m 3s\tremaining: 6m 28s\n",
      "98:\tlearn: 0.6696337\ttotal: 1m 3s\tremaining: 6m 27s\n",
      "99:\tlearn: 0.6695678\ttotal: 1m 4s\tremaining: 6m 27s\n",
      "100:\tlearn: 0.6694274\ttotal: 1m 5s\tremaining: 6m 26s\n",
      "101:\tlearn: 0.6692972\ttotal: 1m 5s\tremaining: 6m 25s\n",
      "102:\tlearn: 0.6691745\ttotal: 1m 6s\tremaining: 6m 25s\n",
      "103:\tlearn: 0.6689960\ttotal: 1m 7s\tremaining: 6m 24s\n",
      "104:\tlearn: 0.6689821\ttotal: 1m 7s\tremaining: 6m 20s\n",
      "105:\tlearn: 0.6688632\ttotal: 1m 7s\tremaining: 6m 19s\n",
      "106:\tlearn: 0.6687653\ttotal: 1m 8s\tremaining: 6m 19s\n",
      "107:\tlearn: 0.6686744\ttotal: 1m 9s\tremaining: 6m 18s\n",
      "108:\tlearn: 0.6684694\ttotal: 1m 9s\tremaining: 6m 18s\n",
      "109:\tlearn: 0.6683706\ttotal: 1m 10s\tremaining: 6m 17s\n",
      "110:\tlearn: 0.6682063\ttotal: 1m 11s\tremaining: 6m 16s\n",
      "111:\tlearn: 0.6679802\ttotal: 1m 11s\tremaining: 6m 16s\n",
      "112:\tlearn: 0.6678807\ttotal: 1m 12s\tremaining: 6m 15s\n",
      "113:\tlearn: 0.6675750\ttotal: 1m 13s\tremaining: 6m 15s\n",
      "114:\tlearn: 0.6673191\ttotal: 1m 13s\tremaining: 6m 14s\n",
      "115:\tlearn: 0.6672012\ttotal: 1m 14s\tremaining: 6m 14s\n",
      "116:\tlearn: 0.6669055\ttotal: 1m 14s\tremaining: 6m 13s\n",
      "117:\tlearn: 0.6667895\ttotal: 1m 15s\tremaining: 6m 13s\n",
      "118:\tlearn: 0.6666469\ttotal: 1m 16s\tremaining: 6m 12s\n",
      "119:\tlearn: 0.6664952\ttotal: 1m 16s\tremaining: 6m 12s\n",
      "120:\tlearn: 0.6663531\ttotal: 1m 17s\tremaining: 6m 11s\n",
      "121:\tlearn: 0.6662262\ttotal: 1m 18s\tremaining: 6m 10s\n",
      "122:\tlearn: 0.6661051\ttotal: 1m 18s\tremaining: 6m 10s\n",
      "123:\tlearn: 0.6660028\ttotal: 1m 19s\tremaining: 6m 9s\n",
      "124:\tlearn: 0.6659001\ttotal: 1m 20s\tremaining: 6m 9s\n",
      "125:\tlearn: 0.6658522\ttotal: 1m 20s\tremaining: 6m 8s\n",
      "126:\tlearn: 0.6657563\ttotal: 1m 21s\tremaining: 6m 7s\n",
      "127:\tlearn: 0.6655428\ttotal: 1m 22s\tremaining: 6m 7s\n",
      "128:\tlearn: 0.6654559\ttotal: 1m 22s\tremaining: 6m 6s\n",
      "129:\tlearn: 0.6650640\ttotal: 1m 23s\tremaining: 6m 6s\n",
      "130:\tlearn: 0.6647842\ttotal: 1m 24s\tremaining: 6m 5s\n",
      "131:\tlearn: 0.6647080\ttotal: 1m 24s\tremaining: 6m 4s\n",
      "132:\tlearn: 0.6646485\ttotal: 1m 25s\tremaining: 6m 4s\n",
      "133:\tlearn: 0.6645890\ttotal: 1m 26s\tremaining: 6m 3s\n",
      "134:\tlearn: 0.6644398\ttotal: 1m 26s\tremaining: 6m 3s\n",
      "135:\tlearn: 0.6643110\ttotal: 1m 27s\tremaining: 6m 2s\n",
      "136:\tlearn: 0.6640946\ttotal: 1m 28s\tremaining: 6m 1s\n",
      "137:\tlearn: 0.6640378\ttotal: 1m 28s\tremaining: 6m 1s\n",
      "138:\tlearn: 0.6639792\ttotal: 1m 29s\tremaining: 6m\n",
      "139:\tlearn: 0.6638978\ttotal: 1m 29s\tremaining: 5m 59s\n",
      "140:\tlearn: 0.6637878\ttotal: 1m 30s\tremaining: 5m 59s\n",
      "141:\tlearn: 0.6637090\ttotal: 1m 31s\tremaining: 5m 58s\n",
      "142:\tlearn: 0.6636106\ttotal: 1m 31s\tremaining: 5m 57s\n",
      "143:\tlearn: 0.6634190\ttotal: 1m 32s\tremaining: 5m 57s\n",
      "144:\tlearn: 0.6632808\ttotal: 1m 33s\tremaining: 5m 56s\n",
      "145:\tlearn: 0.6632133\ttotal: 1m 33s\tremaining: 5m 56s\n",
      "146:\tlearn: 0.6628870\ttotal: 1m 34s\tremaining: 5m 55s\n",
      "147:\tlearn: 0.6627695\ttotal: 1m 35s\tremaining: 5m 54s\n",
      "148:\tlearn: 0.6626165\ttotal: 1m 35s\tremaining: 5m 54s\n",
      "149:\tlearn: 0.6625503\ttotal: 1m 36s\tremaining: 5m 53s\n",
      "150:\tlearn: 0.6623720\ttotal: 1m 37s\tremaining: 5m 53s\n",
      "151:\tlearn: 0.6622154\ttotal: 1m 37s\tremaining: 5m 52s\n",
      "152:\tlearn: 0.6621839\ttotal: 1m 38s\tremaining: 5m 51s\n",
      "153:\tlearn: 0.6621066\ttotal: 1m 39s\tremaining: 5m 51s\n",
      "154:\tlearn: 0.6620520\ttotal: 1m 39s\tremaining: 5m 50s\n",
      "155:\tlearn: 0.6618304\ttotal: 1m 40s\tremaining: 5m 49s\n",
      "156:\tlearn: 0.6617617\ttotal: 1m 40s\tremaining: 5m 49s\n",
      "157:\tlearn: 0.6615691\ttotal: 1m 41s\tremaining: 5m 48s\n",
      "158:\tlearn: 0.6615051\ttotal: 1m 42s\tremaining: 5m 48s\n",
      "159:\tlearn: 0.6614244\ttotal: 1m 42s\tremaining: 5m 47s\n",
      "160:\tlearn: 0.6613582\ttotal: 1m 43s\tremaining: 5m 46s\n",
      "161:\tlearn: 0.6612073\ttotal: 1m 44s\tremaining: 5m 46s\n",
      "162:\tlearn: 0.6609810\ttotal: 1m 44s\tremaining: 5m 45s\n",
      "163:\tlearn: 0.6608960\ttotal: 1m 45s\tremaining: 5m 44s\n",
      "164:\tlearn: 0.6608696\ttotal: 1m 46s\tremaining: 5m 44s\n",
      "165:\tlearn: 0.6608030\ttotal: 1m 46s\tremaining: 5m 43s\n",
      "166:\tlearn: 0.6606725\ttotal: 1m 47s\tremaining: 5m 43s\n",
      "167:\tlearn: 0.6605219\ttotal: 1m 48s\tremaining: 5m 42s\n",
      "168:\tlearn: 0.6604394\ttotal: 1m 48s\tremaining: 5m 41s\n",
      "169:\tlearn: 0.6602087\ttotal: 1m 49s\tremaining: 5m 41s\n",
      "170:\tlearn: 0.6599869\ttotal: 1m 50s\tremaining: 5m 40s\n",
      "171:\tlearn: 0.6599508\ttotal: 1m 50s\tremaining: 5m 40s\n",
      "172:\tlearn: 0.6598952\ttotal: 1m 51s\tremaining: 5m 39s\n",
      "173:\tlearn: 0.6598163\ttotal: 1m 52s\tremaining: 5m 38s\n",
      "174:\tlearn: 0.6597761\ttotal: 1m 52s\tremaining: 5m 38s\n",
      "175:\tlearn: 0.6596881\ttotal: 1m 53s\tremaining: 5m 37s\n",
      "176:\tlearn: 0.6594678\ttotal: 1m 53s\tremaining: 5m 36s\n",
      "177:\tlearn: 0.6593923\ttotal: 1m 54s\tremaining: 5m 36s\n",
      "178:\tlearn: 0.6593362\ttotal: 1m 55s\tremaining: 5m 35s\n",
      "179:\tlearn: 0.6592145\ttotal: 1m 55s\tremaining: 5m 34s\n",
      "180:\tlearn: 0.6591705\ttotal: 1m 56s\tremaining: 5m 34s\n",
      "181:\tlearn: 0.6590727\ttotal: 1m 57s\tremaining: 5m 33s\n",
      "182:\tlearn: 0.6590058\ttotal: 1m 57s\tremaining: 5m 33s\n",
      "183:\tlearn: 0.6589376\ttotal: 1m 58s\tremaining: 5m 32s\n",
      "184:\tlearn: 0.6588997\ttotal: 1m 59s\tremaining: 5m 31s\n",
      "185:\tlearn: 0.6587622\ttotal: 1m 59s\tremaining: 5m 31s\n",
      "186:\tlearn: 0.6586999\ttotal: 2m\tremaining: 5m 30s\n",
      "187:\tlearn: 0.6586425\ttotal: 2m 1s\tremaining: 5m 29s\n",
      "188:\tlearn: 0.6585838\ttotal: 2m 1s\tremaining: 5m 29s\n",
      "189:\tlearn: 0.6585458\ttotal: 2m 2s\tremaining: 5m 28s\n",
      "190:\tlearn: 0.6584435\ttotal: 2m 3s\tremaining: 5m 28s\n",
      "191:\tlearn: 0.6584021\ttotal: 2m 3s\tremaining: 5m 27s\n",
      "192:\tlearn: 0.6583519\ttotal: 2m 4s\tremaining: 5m 26s\n",
      "193:\tlearn: 0.6583038\ttotal: 2m 5s\tremaining: 5m 26s\n",
      "194:\tlearn: 0.6582488\ttotal: 2m 5s\tremaining: 5m 25s\n",
      "195:\tlearn: 0.6581217\ttotal: 2m 6s\tremaining: 5m 24s\n",
      "196:\tlearn: 0.6580971\ttotal: 2m 6s\tremaining: 5m 24s\n",
      "197:\tlearn: 0.6579546\ttotal: 2m 7s\tremaining: 5m 23s\n",
      "198:\tlearn: 0.6579129\ttotal: 2m 8s\tremaining: 5m 22s\n",
      "199:\tlearn: 0.6578922\ttotal: 2m 8s\tremaining: 5m 22s\n",
      "200:\tlearn: 0.6578017\ttotal: 2m 9s\tremaining: 5m 21s\n",
      "201:\tlearn: 0.6577443\ttotal: 2m 10s\tremaining: 5m 21s\n",
      "202:\tlearn: 0.6576543\ttotal: 2m 10s\tremaining: 5m 20s\n",
      "203:\tlearn: 0.6576047\ttotal: 2m 11s\tremaining: 5m 19s\n",
      "204:\tlearn: 0.6574189\ttotal: 2m 12s\tremaining: 5m 19s\n",
      "205:\tlearn: 0.6573800\ttotal: 2m 12s\tremaining: 5m 18s\n",
      "206:\tlearn: 0.6573261\ttotal: 2m 13s\tremaining: 5m 17s\n",
      "207:\tlearn: 0.6571926\ttotal: 2m 14s\tremaining: 5m 17s\n",
      "208:\tlearn: 0.6571222\ttotal: 2m 14s\tremaining: 5m 16s\n",
      "209:\tlearn: 0.6570707\ttotal: 2m 15s\tremaining: 5m 16s\n",
      "210:\tlearn: 0.6569497\ttotal: 2m 16s\tremaining: 5m 15s\n",
      "211:\tlearn: 0.6569020\ttotal: 2m 16s\tremaining: 5m 14s\n",
      "212:\tlearn: 0.6568244\ttotal: 2m 17s\tremaining: 5m 14s\n",
      "213:\tlearn: 0.6567638\ttotal: 2m 18s\tremaining: 5m 13s\n",
      "214:\tlearn: 0.6566870\ttotal: 2m 18s\tremaining: 5m 12s\n",
      "215:\tlearn: 0.6566046\ttotal: 2m 19s\tremaining: 5m 12s\n",
      "216:\tlearn: 0.6565660\ttotal: 2m 20s\tremaining: 5m 11s\n",
      "217:\tlearn: 0.6565446\ttotal: 2m 20s\tremaining: 5m 10s\n",
      "218:\tlearn: 0.6565090\ttotal: 2m 21s\tremaining: 5m 10s\n",
      "219:\tlearn: 0.6564531\ttotal: 2m 21s\tremaining: 5m 9s\n",
      "220:\tlearn: 0.6564241\ttotal: 2m 22s\tremaining: 5m 9s\n",
      "221:\tlearn: 0.6563467\ttotal: 2m 23s\tremaining: 5m 8s\n",
      "222:\tlearn: 0.6562438\ttotal: 2m 23s\tremaining: 5m 7s\n",
      "223:\tlearn: 0.6559257\ttotal: 2m 24s\tremaining: 5m 7s\n",
      "224:\tlearn: 0.6558955\ttotal: 2m 25s\tremaining: 5m 6s\n",
      "225:\tlearn: 0.6558712\ttotal: 2m 25s\tremaining: 5m 5s\n",
      "226:\tlearn: 0.6557681\ttotal: 2m 26s\tremaining: 5m 5s\n",
      "227:\tlearn: 0.6557408\ttotal: 2m 27s\tremaining: 5m 4s\n",
      "228:\tlearn: 0.6556901\ttotal: 2m 27s\tremaining: 5m 3s\n",
      "229:\tlearn: 0.6556623\ttotal: 2m 28s\tremaining: 5m 3s\n",
      "230:\tlearn: 0.6556080\ttotal: 2m 29s\tremaining: 5m 2s\n",
      "231:\tlearn: 0.6555212\ttotal: 2m 29s\tremaining: 5m 1s\n",
      "232:\tlearn: 0.6554699\ttotal: 2m 30s\tremaining: 5m 1s\n",
      "233:\tlearn: 0.6554206\ttotal: 2m 31s\tremaining: 5m\n",
      "234:\tlearn: 0.6553457\ttotal: 2m 31s\tremaining: 5m\n",
      "235:\tlearn: 0.6553008\ttotal: 2m 32s\tremaining: 4m 59s\n",
      "236:\tlearn: 0.6552836\ttotal: 2m 32s\tremaining: 4m 58s\n",
      "237:\tlearn: 0.6552612\ttotal: 2m 33s\tremaining: 4m 58s\n",
      "238:\tlearn: 0.6552152\ttotal: 2m 34s\tremaining: 4m 57s\n",
      "239:\tlearn: 0.6551189\ttotal: 2m 34s\tremaining: 4m 56s\n",
      "240:\tlearn: 0.6550403\ttotal: 2m 35s\tremaining: 4m 56s\n",
      "241:\tlearn: 0.6549502\ttotal: 2m 36s\tremaining: 4m 55s\n",
      "242:\tlearn: 0.6548842\ttotal: 2m 36s\tremaining: 4m 54s\n",
      "243:\tlearn: 0.6548502\ttotal: 2m 37s\tremaining: 4m 54s\n",
      "244:\tlearn: 0.6547658\ttotal: 2m 38s\tremaining: 4m 53s\n",
      "245:\tlearn: 0.6547492\ttotal: 2m 38s\tremaining: 4m 53s\n",
      "246:\tlearn: 0.6546773\ttotal: 2m 39s\tremaining: 4m 52s\n",
      "247:\tlearn: 0.6545926\ttotal: 2m 40s\tremaining: 4m 51s\n",
      "248:\tlearn: 0.6545655\ttotal: 2m 40s\tremaining: 4m 51s\n",
      "249:\tlearn: 0.6545325\ttotal: 2m 41s\tremaining: 4m 50s\n",
      "250:\tlearn: 0.6543963\ttotal: 2m 42s\tremaining: 4m 49s\n",
      "251:\tlearn: 0.6543129\ttotal: 2m 42s\tremaining: 4m 49s\n",
      "252:\tlearn: 0.6542543\ttotal: 2m 43s\tremaining: 4m 48s\n",
      "253:\tlearn: 0.6542157\ttotal: 2m 44s\tremaining: 4m 48s\n",
      "254:\tlearn: 0.6541934\ttotal: 2m 44s\tremaining: 4m 47s\n",
      "255:\tlearn: 0.6541298\ttotal: 2m 45s\tremaining: 4m 46s\n",
      "256:\tlearn: 0.6540906\ttotal: 2m 45s\tremaining: 4m 46s\n",
      "257:\tlearn: 0.6540171\ttotal: 2m 46s\tremaining: 4m 45s\n",
      "258:\tlearn: 0.6539823\ttotal: 2m 47s\tremaining: 4m 44s\n",
      "259:\tlearn: 0.6539190\ttotal: 2m 47s\tremaining: 4m 44s\n",
      "260:\tlearn: 0.6538821\ttotal: 2m 48s\tremaining: 4m 43s\n",
      "261:\tlearn: 0.6537659\ttotal: 2m 49s\tremaining: 4m 42s\n",
      "262:\tlearn: 0.6537375\ttotal: 2m 49s\tremaining: 4m 42s\n",
      "263:\tlearn: 0.6536960\ttotal: 2m 50s\tremaining: 4m 41s\n",
      "264:\tlearn: 0.6536726\ttotal: 2m 51s\tremaining: 4m 41s\n",
      "265:\tlearn: 0.6536159\ttotal: 2m 51s\tremaining: 4m 40s\n",
      "266:\tlearn: 0.6535913\ttotal: 2m 52s\tremaining: 4m 39s\n",
      "267:\tlearn: 0.6535651\ttotal: 2m 53s\tremaining: 4m 39s\n",
      "268:\tlearn: 0.6534904\ttotal: 2m 53s\tremaining: 4m 38s\n",
      "269:\tlearn: 0.6534237\ttotal: 2m 54s\tremaining: 4m 37s\n",
      "270:\tlearn: 0.6533276\ttotal: 2m 55s\tremaining: 4m 37s\n",
      "271:\tlearn: 0.6533016\ttotal: 2m 55s\tremaining: 4m 36s\n",
      "272:\tlearn: 0.6532564\ttotal: 2m 56s\tremaining: 4m 35s\n",
      "273:\tlearn: 0.6532147\ttotal: 2m 57s\tremaining: 4m 35s\n",
      "274:\tlearn: 0.6531669\ttotal: 2m 57s\tremaining: 4m 34s\n",
      "275:\tlearn: 0.6530626\ttotal: 2m 58s\tremaining: 4m 33s\n",
      "276:\tlearn: 0.6530350\ttotal: 2m 58s\tremaining: 4m 33s\n",
      "277:\tlearn: 0.6529108\ttotal: 2m 59s\tremaining: 4m 32s\n",
      "278:\tlearn: 0.6528999\ttotal: 3m\tremaining: 4m 32s\n",
      "279:\tlearn: 0.6528616\ttotal: 3m\tremaining: 4m 31s\n",
      "280:\tlearn: 0.6528004\ttotal: 3m 1s\tremaining: 4m 30s\n",
      "281:\tlearn: 0.6527182\ttotal: 3m 2s\tremaining: 4m 30s\n",
      "282:\tlearn: 0.6526665\ttotal: 3m 2s\tremaining: 4m 29s\n",
      "283:\tlearn: 0.6526404\ttotal: 3m 3s\tremaining: 4m 28s\n",
      "284:\tlearn: 0.6525958\ttotal: 3m 4s\tremaining: 4m 28s\n",
      "285:\tlearn: 0.6525544\ttotal: 3m 4s\tremaining: 4m 27s\n",
      "286:\tlearn: 0.6525159\ttotal: 3m 5s\tremaining: 4m 26s\n",
      "287:\tlearn: 0.6524589\ttotal: 3m 6s\tremaining: 4m 26s\n",
      "288:\tlearn: 0.6523976\ttotal: 3m 6s\tremaining: 4m 25s\n",
      "289:\tlearn: 0.6523191\ttotal: 3m 7s\tremaining: 4m 24s\n",
      "290:\tlearn: 0.6522268\ttotal: 3m 8s\tremaining: 4m 24s\n",
      "291:\tlearn: 0.6521956\ttotal: 3m 8s\tremaining: 4m 23s\n",
      "292:\tlearn: 0.6521566\ttotal: 3m 9s\tremaining: 4m 23s\n",
      "293:\tlearn: 0.6521427\ttotal: 3m 10s\tremaining: 4m 22s\n",
      "294:\tlearn: 0.6520650\ttotal: 3m 10s\tremaining: 4m 21s\n",
      "295:\tlearn: 0.6520493\ttotal: 3m 11s\tremaining: 4m 21s\n",
      "296:\tlearn: 0.6520378\ttotal: 3m 11s\tremaining: 4m 20s\n",
      "297:\tlearn: 0.6519720\ttotal: 3m 12s\tremaining: 4m 19s\n",
      "298:\tlearn: 0.6519402\ttotal: 3m 13s\tremaining: 4m 19s\n",
      "299:\tlearn: 0.6518507\ttotal: 3m 13s\tremaining: 4m 18s\n",
      "300:\tlearn: 0.6518243\ttotal: 3m 14s\tremaining: 4m 17s\n",
      "301:\tlearn: 0.6518046\ttotal: 3m 15s\tremaining: 4m 17s\n",
      "302:\tlearn: 0.6517672\ttotal: 3m 15s\tremaining: 4m 16s\n",
      "303:\tlearn: 0.6517118\ttotal: 3m 16s\tremaining: 4m 15s\n",
      "304:\tlearn: 0.6516003\ttotal: 3m 17s\tremaining: 4m 15s\n",
      "305:\tlearn: 0.6514976\ttotal: 3m 17s\tremaining: 4m 14s\n",
      "306:\tlearn: 0.6514705\ttotal: 3m 18s\tremaining: 4m 14s\n",
      "307:\tlearn: 0.6514312\ttotal: 3m 19s\tremaining: 4m 13s\n",
      "308:\tlearn: 0.6513872\ttotal: 3m 19s\tremaining: 4m 12s\n",
      "309:\tlearn: 0.6513206\ttotal: 3m 20s\tremaining: 4m 12s\n",
      "310:\tlearn: 0.6512794\ttotal: 3m 21s\tremaining: 4m 11s\n",
      "311:\tlearn: 0.6512482\ttotal: 3m 21s\tremaining: 4m 10s\n",
      "312:\tlearn: 0.6511999\ttotal: 3m 22s\tremaining: 4m 10s\n",
      "313:\tlearn: 0.6511723\ttotal: 3m 22s\tremaining: 4m 9s\n",
      "314:\tlearn: 0.6511086\ttotal: 3m 23s\tremaining: 4m 8s\n",
      "315:\tlearn: 0.6510662\ttotal: 3m 24s\tremaining: 4m 8s\n",
      "316:\tlearn: 0.6510337\ttotal: 3m 24s\tremaining: 4m 7s\n",
      "317:\tlearn: 0.6509702\ttotal: 3m 25s\tremaining: 4m 6s\n",
      "318:\tlearn: 0.6509291\ttotal: 3m 26s\tremaining: 4m 6s\n",
      "319:\tlearn: 0.6508567\ttotal: 3m 26s\tremaining: 4m 5s\n",
      "320:\tlearn: 0.6508370\ttotal: 3m 27s\tremaining: 4m 5s\n",
      "321:\tlearn: 0.6508095\ttotal: 3m 28s\tremaining: 4m 4s\n",
      "322:\tlearn: 0.6507606\ttotal: 3m 28s\tremaining: 4m 3s\n",
      "323:\tlearn: 0.6507179\ttotal: 3m 29s\tremaining: 4m 3s\n",
      "324:\tlearn: 0.6506879\ttotal: 3m 30s\tremaining: 4m 2s\n",
      "325:\tlearn: 0.6506702\ttotal: 3m 30s\tremaining: 4m 1s\n",
      "326:\tlearn: 0.6506421\ttotal: 3m 31s\tremaining: 4m 1s\n",
      "327:\tlearn: 0.6506150\ttotal: 3m 32s\tremaining: 4m\n",
      "328:\tlearn: 0.6505437\ttotal: 3m 32s\tremaining: 3m 59s\n",
      "329:\tlearn: 0.6504632\ttotal: 3m 33s\tremaining: 3m 59s\n",
      "330:\tlearn: 0.6504438\ttotal: 3m 34s\tremaining: 3m 58s\n",
      "331:\tlearn: 0.6504232\ttotal: 3m 34s\tremaining: 3m 57s\n",
      "332:\tlearn: 0.6503837\ttotal: 3m 35s\tremaining: 3m 57s\n",
      "333:\tlearn: 0.6503555\ttotal: 3m 35s\tremaining: 3m 56s\n",
      "334:\tlearn: 0.6502921\ttotal: 3m 36s\tremaining: 3m 56s\n",
      "335:\tlearn: 0.6502014\ttotal: 3m 37s\tremaining: 3m 55s\n",
      "336:\tlearn: 0.6501773\ttotal: 3m 37s\tremaining: 3m 54s\n",
      "337:\tlearn: 0.6501444\ttotal: 3m 38s\tremaining: 3m 54s\n",
      "338:\tlearn: 0.6500981\ttotal: 3m 39s\tremaining: 3m 53s\n",
      "339:\tlearn: 0.6500413\ttotal: 3m 39s\tremaining: 3m 52s\n",
      "340:\tlearn: 0.6499516\ttotal: 3m 40s\tremaining: 3m 52s\n",
      "341:\tlearn: 0.6499254\ttotal: 3m 41s\tremaining: 3m 51s\n",
      "342:\tlearn: 0.6498927\ttotal: 3m 41s\tremaining: 3m 50s\n",
      "343:\tlearn: 0.6498429\ttotal: 3m 42s\tremaining: 3m 50s\n",
      "344:\tlearn: 0.6497993\ttotal: 3m 43s\tremaining: 3m 49s\n",
      "345:\tlearn: 0.6497071\ttotal: 3m 43s\tremaining: 3m 48s\n",
      "346:\tlearn: 0.6496873\ttotal: 3m 44s\tremaining: 3m 48s\n",
      "347:\tlearn: 0.6493829\ttotal: 3m 45s\tremaining: 3m 47s\n",
      "348:\tlearn: 0.6493567\ttotal: 3m 45s\tremaining: 3m 46s\n",
      "349:\tlearn: 0.6493408\ttotal: 3m 46s\tremaining: 3m 46s\n",
      "350:\tlearn: 0.6492706\ttotal: 3m 46s\tremaining: 3m 45s\n",
      "351:\tlearn: 0.6492455\ttotal: 3m 47s\tremaining: 3m 45s\n",
      "352:\tlearn: 0.6491623\ttotal: 3m 48s\tremaining: 3m 44s\n",
      "353:\tlearn: 0.6491280\ttotal: 3m 48s\tremaining: 3m 43s\n",
      "354:\tlearn: 0.6491081\ttotal: 3m 49s\tremaining: 3m 43s\n",
      "355:\tlearn: 0.6490551\ttotal: 3m 50s\tremaining: 3m 42s\n",
      "356:\tlearn: 0.6490418\ttotal: 3m 50s\tremaining: 3m 41s\n",
      "357:\tlearn: 0.6489965\ttotal: 3m 51s\tremaining: 3m 41s\n",
      "358:\tlearn: 0.6489487\ttotal: 3m 52s\tremaining: 3m 40s\n",
      "359:\tlearn: 0.6489186\ttotal: 3m 52s\tremaining: 3m 39s\n",
      "360:\tlearn: 0.6488820\ttotal: 3m 53s\tremaining: 3m 39s\n",
      "361:\tlearn: 0.6488406\ttotal: 3m 54s\tremaining: 3m 38s\n",
      "362:\tlearn: 0.6488229\ttotal: 3m 54s\tremaining: 3m 37s\n",
      "363:\tlearn: 0.6488005\ttotal: 3m 55s\tremaining: 3m 37s\n",
      "364:\tlearn: 0.6487764\ttotal: 3m 55s\tremaining: 3m 36s\n",
      "365:\tlearn: 0.6487508\ttotal: 3m 56s\tremaining: 3m 35s\n",
      "366:\tlearn: 0.6487200\ttotal: 3m 57s\tremaining: 3m 35s\n",
      "367:\tlearn: 0.6486247\ttotal: 3m 57s\tremaining: 3m 34s\n",
      "368:\tlearn: 0.6485923\ttotal: 3m 58s\tremaining: 3m 34s\n",
      "369:\tlearn: 0.6485605\ttotal: 3m 59s\tremaining: 3m 33s\n",
      "370:\tlearn: 0.6485339\ttotal: 3m 59s\tremaining: 3m 32s\n",
      "371:\tlearn: 0.6484743\ttotal: 4m\tremaining: 3m 32s\n",
      "372:\tlearn: 0.6484564\ttotal: 4m 1s\tremaining: 3m 31s\n",
      "373:\tlearn: 0.6483946\ttotal: 4m 1s\tremaining: 3m 30s\n",
      "374:\tlearn: 0.6483629\ttotal: 4m 2s\tremaining: 3m 30s\n",
      "375:\tlearn: 0.6482812\ttotal: 4m 3s\tremaining: 3m 29s\n",
      "376:\tlearn: 0.6482497\ttotal: 4m 3s\tremaining: 3m 28s\n",
      "377:\tlearn: 0.6482297\ttotal: 4m 4s\tremaining: 3m 28s\n",
      "378:\tlearn: 0.6481509\ttotal: 4m 5s\tremaining: 3m 27s\n",
      "379:\tlearn: 0.6481065\ttotal: 4m 5s\tremaining: 3m 26s\n",
      "380:\tlearn: 0.6480666\ttotal: 4m 6s\tremaining: 3m 26s\n",
      "381:\tlearn: 0.6480396\ttotal: 4m 6s\tremaining: 3m 25s\n",
      "382:\tlearn: 0.6480151\ttotal: 4m 7s\tremaining: 3m 24s\n",
      "383:\tlearn: 0.6479812\ttotal: 4m 8s\tremaining: 3m 24s\n",
      "384:\tlearn: 0.6479389\ttotal: 4m 8s\tremaining: 3m 23s\n",
      "385:\tlearn: 0.6479135\ttotal: 4m 9s\tremaining: 3m 23s\n",
      "386:\tlearn: 0.6478927\ttotal: 4m 10s\tremaining: 3m 22s\n",
      "387:\tlearn: 0.6478659\ttotal: 4m 10s\tremaining: 3m 21s\n",
      "388:\tlearn: 0.6478273\ttotal: 4m 11s\tremaining: 3m 21s\n",
      "389:\tlearn: 0.6477750\ttotal: 4m 12s\tremaining: 3m 20s\n",
      "390:\tlearn: 0.6477113\ttotal: 4m 12s\tremaining: 3m 19s\n",
      "391:\tlearn: 0.6476545\ttotal: 4m 13s\tremaining: 3m 19s\n",
      "392:\tlearn: 0.6475878\ttotal: 4m 14s\tremaining: 3m 18s\n",
      "393:\tlearn: 0.6475615\ttotal: 4m 14s\tremaining: 3m 17s\n",
      "394:\tlearn: 0.6475299\ttotal: 4m 15s\tremaining: 3m 17s\n",
      "395:\tlearn: 0.6474938\ttotal: 4m 16s\tremaining: 3m 16s\n",
      "396:\tlearn: 0.6474738\ttotal: 4m 16s\tremaining: 3m 15s\n",
      "397:\tlearn: 0.6474257\ttotal: 4m 17s\tremaining: 3m 15s\n",
      "398:\tlearn: 0.6474039\ttotal: 4m 18s\tremaining: 3m 14s\n",
      "399:\tlearn: 0.6473621\ttotal: 4m 18s\tremaining: 3m 14s\n",
      "400:\tlearn: 0.6473440\ttotal: 4m 19s\tremaining: 3m 13s\n",
      "401:\tlearn: 0.6473210\ttotal: 4m 19s\tremaining: 3m 12s\n",
      "402:\tlearn: 0.6472491\ttotal: 4m 20s\tremaining: 3m 12s\n",
      "403:\tlearn: 0.6472143\ttotal: 4m 21s\tremaining: 3m 11s\n",
      "404:\tlearn: 0.6471896\ttotal: 4m 21s\tremaining: 3m 10s\n",
      "405:\tlearn: 0.6471716\ttotal: 4m 22s\tremaining: 3m 10s\n",
      "406:\tlearn: 0.6470956\ttotal: 4m 23s\tremaining: 3m 9s\n",
      "407:\tlearn: 0.6470512\ttotal: 4m 23s\tremaining: 3m 8s\n",
      "408:\tlearn: 0.6470280\ttotal: 4m 24s\tremaining: 3m 8s\n",
      "409:\tlearn: 0.6469574\ttotal: 4m 25s\tremaining: 3m 7s\n",
      "410:\tlearn: 0.6469225\ttotal: 4m 25s\tremaining: 3m 6s\n",
      "411:\tlearn: 0.6469022\ttotal: 4m 26s\tremaining: 3m 6s\n",
      "412:\tlearn: 0.6468567\ttotal: 4m 27s\tremaining: 3m 5s\n",
      "413:\tlearn: 0.6468401\ttotal: 4m 27s\tremaining: 3m 4s\n",
      "414:\tlearn: 0.6468001\ttotal: 4m 28s\tremaining: 3m 4s\n",
      "415:\tlearn: 0.6467286\ttotal: 4m 29s\tremaining: 3m 3s\n",
      "416:\tlearn: 0.6466906\ttotal: 4m 29s\tremaining: 3m 3s\n",
      "417:\tlearn: 0.6466701\ttotal: 4m 30s\tremaining: 3m 2s\n",
      "418:\tlearn: 0.6466530\ttotal: 4m 30s\tremaining: 3m 1s\n",
      "419:\tlearn: 0.6466218\ttotal: 4m 31s\tremaining: 3m 1s\n",
      "420:\tlearn: 0.6466037\ttotal: 4m 32s\tremaining: 3m\n",
      "421:\tlearn: 0.6465490\ttotal: 4m 32s\tremaining: 2m 59s\n",
      "422:\tlearn: 0.6464771\ttotal: 4m 33s\tremaining: 2m 59s\n",
      "423:\tlearn: 0.6464598\ttotal: 4m 34s\tremaining: 2m 58s\n",
      "424:\tlearn: 0.6464463\ttotal: 4m 34s\tremaining: 2m 57s\n",
      "425:\tlearn: 0.6464206\ttotal: 4m 35s\tremaining: 2m 57s\n",
      "426:\tlearn: 0.6464050\ttotal: 4m 36s\tremaining: 2m 56s\n",
      "427:\tlearn: 0.6463477\ttotal: 4m 36s\tremaining: 2m 55s\n",
      "428:\tlearn: 0.6463226\ttotal: 4m 37s\tremaining: 2m 55s\n",
      "429:\tlearn: 0.6462711\ttotal: 4m 38s\tremaining: 2m 54s\n",
      "430:\tlearn: 0.6462135\ttotal: 4m 38s\tremaining: 2m 53s\n",
      "431:\tlearn: 0.6461602\ttotal: 4m 39s\tremaining: 2m 53s\n",
      "432:\tlearn: 0.6461373\ttotal: 4m 39s\tremaining: 2m 52s\n",
      "433:\tlearn: 0.6460478\ttotal: 4m 40s\tremaining: 2m 52s\n",
      "434:\tlearn: 0.6460318\ttotal: 4m 41s\tremaining: 2m 51s\n",
      "435:\tlearn: 0.6460031\ttotal: 4m 41s\tremaining: 2m 50s\n",
      "436:\tlearn: 0.6459162\ttotal: 4m 42s\tremaining: 2m 50s\n",
      "437:\tlearn: 0.6458776\ttotal: 4m 43s\tremaining: 2m 49s\n",
      "438:\tlearn: 0.6458388\ttotal: 4m 43s\tremaining: 2m 48s\n",
      "439:\tlearn: 0.6457855\ttotal: 4m 44s\tremaining: 2m 48s\n",
      "440:\tlearn: 0.6455839\ttotal: 4m 45s\tremaining: 2m 47s\n",
      "441:\tlearn: 0.6455259\ttotal: 4m 45s\tremaining: 2m 46s\n",
      "442:\tlearn: 0.6454779\ttotal: 4m 46s\tremaining: 2m 46s\n",
      "443:\tlearn: 0.6454584\ttotal: 4m 47s\tremaining: 2m 45s\n",
      "444:\tlearn: 0.6454018\ttotal: 4m 47s\tremaining: 2m 44s\n",
      "445:\tlearn: 0.6453687\ttotal: 4m 48s\tremaining: 2m 44s\n",
      "446:\tlearn: 0.6453172\ttotal: 4m 49s\tremaining: 2m 43s\n",
      "447:\tlearn: 0.6452734\ttotal: 4m 49s\tremaining: 2m 42s\n",
      "448:\tlearn: 0.6452418\ttotal: 4m 50s\tremaining: 2m 42s\n",
      "449:\tlearn: 0.6452137\ttotal: 4m 50s\tremaining: 2m 41s\n",
      "450:\tlearn: 0.6451973\ttotal: 4m 51s\tremaining: 2m 41s\n",
      "451:\tlearn: 0.6451504\ttotal: 4m 52s\tremaining: 2m 40s\n",
      "452:\tlearn: 0.6450665\ttotal: 4m 52s\tremaining: 2m 39s\n",
      "453:\tlearn: 0.6450540\ttotal: 4m 53s\tremaining: 2m 39s\n",
      "454:\tlearn: 0.6450336\ttotal: 4m 54s\tremaining: 2m 38s\n",
      "455:\tlearn: 0.6449993\ttotal: 4m 54s\tremaining: 2m 37s\n",
      "456:\tlearn: 0.6449566\ttotal: 4m 55s\tremaining: 2m 37s\n",
      "457:\tlearn: 0.6449252\ttotal: 4m 56s\tremaining: 2m 36s\n",
      "458:\tlearn: 0.6449051\ttotal: 4m 56s\tremaining: 2m 35s\n",
      "459:\tlearn: 0.6448786\ttotal: 4m 57s\tremaining: 2m 35s\n",
      "460:\tlearn: 0.6448597\ttotal: 4m 58s\tremaining: 2m 34s\n",
      "461:\tlearn: 0.6448209\ttotal: 4m 58s\tremaining: 2m 33s\n",
      "462:\tlearn: 0.6447889\ttotal: 4m 59s\tremaining: 2m 33s\n",
      "463:\tlearn: 0.6447697\ttotal: 5m\tremaining: 2m 32s\n",
      "464:\tlearn: 0.6447498\ttotal: 5m\tremaining: 2m 31s\n",
      "465:\tlearn: 0.6447244\ttotal: 5m 1s\tremaining: 2m 31s\n",
      "466:\tlearn: 0.6447103\ttotal: 5m 2s\tremaining: 2m 30s\n",
      "467:\tlearn: 0.6446663\ttotal: 5m 2s\tremaining: 2m 30s\n",
      "468:\tlearn: 0.6446416\ttotal: 5m 3s\tremaining: 2m 29s\n",
      "469:\tlearn: 0.6446285\ttotal: 5m 3s\tremaining: 2m 28s\n",
      "470:\tlearn: 0.6446083\ttotal: 5m 4s\tremaining: 2m 28s\n",
      "471:\tlearn: 0.6445787\ttotal: 5m 5s\tremaining: 2m 27s\n",
      "472:\tlearn: 0.6445679\ttotal: 5m 5s\tremaining: 2m 26s\n",
      "473:\tlearn: 0.6445510\ttotal: 5m 6s\tremaining: 2m 26s\n",
      "474:\tlearn: 0.6445286\ttotal: 5m 7s\tremaining: 2m 25s\n",
      "475:\tlearn: 0.6445128\ttotal: 5m 7s\tremaining: 2m 24s\n",
      "476:\tlearn: 0.6444928\ttotal: 5m 8s\tremaining: 2m 24s\n",
      "477:\tlearn: 0.6444219\ttotal: 5m 9s\tremaining: 2m 23s\n",
      "478:\tlearn: 0.6443573\ttotal: 5m 9s\tremaining: 2m 22s\n",
      "479:\tlearn: 0.6441863\ttotal: 5m 10s\tremaining: 2m 22s\n",
      "480:\tlearn: 0.6441633\ttotal: 5m 11s\tremaining: 2m 21s\n",
      "481:\tlearn: 0.6441409\ttotal: 5m 11s\tremaining: 2m 20s\n",
      "482:\tlearn: 0.6441180\ttotal: 5m 12s\tremaining: 2m 20s\n",
      "483:\tlearn: 0.6441026\ttotal: 5m 13s\tremaining: 2m 19s\n",
      "484:\tlearn: 0.6440916\ttotal: 5m 13s\tremaining: 2m 19s\n",
      "485:\tlearn: 0.6440611\ttotal: 5m 14s\tremaining: 2m 18s\n",
      "486:\tlearn: 0.6439406\ttotal: 5m 14s\tremaining: 2m 17s\n",
      "487:\tlearn: 0.6438870\ttotal: 5m 15s\tremaining: 2m 17s\n",
      "488:\tlearn: 0.6438598\ttotal: 5m 16s\tremaining: 2m 16s\n",
      "489:\tlearn: 0.6438492\ttotal: 5m 16s\tremaining: 2m 15s\n",
      "490:\tlearn: 0.6437995\ttotal: 5m 17s\tremaining: 2m 15s\n",
      "491:\tlearn: 0.6437434\ttotal: 5m 18s\tremaining: 2m 14s\n",
      "492:\tlearn: 0.6437095\ttotal: 5m 18s\tremaining: 2m 13s\n",
      "493:\tlearn: 0.6436803\ttotal: 5m 19s\tremaining: 2m 13s\n",
      "494:\tlearn: 0.6436598\ttotal: 5m 20s\tremaining: 2m 12s\n",
      "495:\tlearn: 0.6436393\ttotal: 5m 20s\tremaining: 2m 11s\n",
      "496:\tlearn: 0.6436225\ttotal: 5m 21s\tremaining: 2m 11s\n",
      "497:\tlearn: 0.6435827\ttotal: 5m 22s\tremaining: 2m 10s\n",
      "498:\tlearn: 0.6435619\ttotal: 5m 22s\tremaining: 2m 10s\n",
      "499:\tlearn: 0.6435387\ttotal: 5m 23s\tremaining: 2m 9s\n",
      "500:\tlearn: 0.6434922\ttotal: 5m 24s\tremaining: 2m 8s\n",
      "501:\tlearn: 0.6434549\ttotal: 5m 24s\tremaining: 2m 8s\n",
      "502:\tlearn: 0.6434237\ttotal: 5m 25s\tremaining: 2m 7s\n",
      "503:\tlearn: 0.6434057\ttotal: 5m 26s\tremaining: 2m 6s\n",
      "504:\tlearn: 0.6433296\ttotal: 5m 26s\tremaining: 2m 6s\n",
      "505:\tlearn: 0.6432825\ttotal: 5m 27s\tremaining: 2m 5s\n",
      "506:\tlearn: 0.6432615\ttotal: 5m 27s\tremaining: 2m 4s\n",
      "507:\tlearn: 0.6432447\ttotal: 5m 28s\tremaining: 2m 4s\n",
      "508:\tlearn: 0.6432327\ttotal: 5m 29s\tremaining: 2m 3s\n",
      "509:\tlearn: 0.6431946\ttotal: 5m 29s\tremaining: 2m 2s\n",
      "510:\tlearn: 0.6431128\ttotal: 5m 30s\tremaining: 2m 2s\n",
      "511:\tlearn: 0.6431026\ttotal: 5m 31s\tremaining: 2m 1s\n",
      "512:\tlearn: 0.6430731\ttotal: 5m 31s\tremaining: 2m\n",
      "513:\tlearn: 0.6430099\ttotal: 5m 32s\tremaining: 2m\n",
      "514:\tlearn: 0.6429926\ttotal: 5m 33s\tremaining: 1m 59s\n",
      "515:\tlearn: 0.6429770\ttotal: 5m 33s\tremaining: 1m 59s\n",
      "516:\tlearn: 0.6429534\ttotal: 5m 34s\tremaining: 1m 58s\n",
      "517:\tlearn: 0.6429258\ttotal: 5m 35s\tremaining: 1m 57s\n",
      "518:\tlearn: 0.6429109\ttotal: 5m 35s\tremaining: 1m 57s\n",
      "519:\tlearn: 0.6428563\ttotal: 5m 36s\tremaining: 1m 56s\n",
      "520:\tlearn: 0.6428323\ttotal: 5m 37s\tremaining: 1m 55s\n",
      "521:\tlearn: 0.6428119\ttotal: 5m 37s\tremaining: 1m 55s\n",
      "522:\tlearn: 0.6427903\ttotal: 5m 38s\tremaining: 1m 54s\n",
      "523:\tlearn: 0.6427508\ttotal: 5m 39s\tremaining: 1m 53s\n",
      "524:\tlearn: 0.6427272\ttotal: 5m 39s\tremaining: 1m 53s\n",
      "525:\tlearn: 0.6427054\ttotal: 5m 40s\tremaining: 1m 52s\n",
      "526:\tlearn: 0.6426412\ttotal: 5m 40s\tremaining: 1m 51s\n",
      "527:\tlearn: 0.6426221\ttotal: 5m 41s\tremaining: 1m 51s\n",
      "528:\tlearn: 0.6425839\ttotal: 5m 42s\tremaining: 1m 50s\n",
      "529:\tlearn: 0.6425450\ttotal: 5m 42s\tremaining: 1m 49s\n",
      "530:\tlearn: 0.6425206\ttotal: 5m 43s\tremaining: 1m 49s\n",
      "531:\tlearn: 0.6425006\ttotal: 5m 44s\tremaining: 1m 48s\n",
      "532:\tlearn: 0.6424456\ttotal: 5m 44s\tremaining: 1m 48s\n",
      "533:\tlearn: 0.6423973\ttotal: 5m 45s\tremaining: 1m 47s\n",
      "534:\tlearn: 0.6423629\ttotal: 5m 46s\tremaining: 1m 46s\n",
      "535:\tlearn: 0.6423461\ttotal: 5m 46s\tremaining: 1m 46s\n",
      "536:\tlearn: 0.6423312\ttotal: 5m 47s\tremaining: 1m 45s\n",
      "537:\tlearn: 0.6422893\ttotal: 5m 48s\tremaining: 1m 44s\n",
      "538:\tlearn: 0.6422637\ttotal: 5m 48s\tremaining: 1m 44s\n",
      "539:\tlearn: 0.6422495\ttotal: 5m 49s\tremaining: 1m 43s\n",
      "540:\tlearn: 0.6422245\ttotal: 5m 50s\tremaining: 1m 42s\n",
      "541:\tlearn: 0.6422002\ttotal: 5m 50s\tremaining: 1m 42s\n",
      "542:\tlearn: 0.6421636\ttotal: 5m 51s\tremaining: 1m 41s\n",
      "543:\tlearn: 0.6421496\ttotal: 5m 52s\tremaining: 1m 40s\n",
      "544:\tlearn: 0.6421161\ttotal: 5m 52s\tremaining: 1m 40s\n",
      "545:\tlearn: 0.6420752\ttotal: 5m 53s\tremaining: 1m 39s\n",
      "546:\tlearn: 0.6420477\ttotal: 5m 53s\tremaining: 1m 39s\n",
      "547:\tlearn: 0.6420023\ttotal: 5m 54s\tremaining: 1m 38s\n",
      "548:\tlearn: 0.6419656\ttotal: 5m 55s\tremaining: 1m 37s\n",
      "549:\tlearn: 0.6419185\ttotal: 5m 55s\tremaining: 1m 37s\n",
      "550:\tlearn: 0.6418943\ttotal: 5m 56s\tremaining: 1m 36s\n",
      "551:\tlearn: 0.6418849\ttotal: 5m 57s\tremaining: 1m 35s\n",
      "552:\tlearn: 0.6418485\ttotal: 5m 57s\tremaining: 1m 35s\n",
      "553:\tlearn: 0.6418175\ttotal: 5m 58s\tremaining: 1m 34s\n",
      "554:\tlearn: 0.6417991\ttotal: 5m 59s\tremaining: 1m 33s\n",
      "555:\tlearn: 0.6417573\ttotal: 5m 59s\tremaining: 1m 33s\n",
      "556:\tlearn: 0.6417449\ttotal: 6m\tremaining: 1m 32s\n",
      "557:\tlearn: 0.6417207\ttotal: 6m 1s\tremaining: 1m 31s\n",
      "558:\tlearn: 0.6417017\ttotal: 6m 1s\tremaining: 1m 31s\n",
      "559:\tlearn: 0.6416880\ttotal: 6m 2s\tremaining: 1m 30s\n",
      "560:\tlearn: 0.6416651\ttotal: 6m 3s\tremaining: 1m 29s\n",
      "561:\tlearn: 0.6416460\ttotal: 6m 3s\tremaining: 1m 29s\n",
      "562:\tlearn: 0.6416226\ttotal: 6m 4s\tremaining: 1m 28s\n",
      "563:\tlearn: 0.6416042\ttotal: 6m 4s\tremaining: 1m 28s\n",
      "564:\tlearn: 0.6415455\ttotal: 6m 5s\tremaining: 1m 27s\n",
      "565:\tlearn: 0.6415016\ttotal: 6m 6s\tremaining: 1m 26s\n",
      "566:\tlearn: 0.6414754\ttotal: 6m 6s\tremaining: 1m 26s\n",
      "567:\tlearn: 0.6413927\ttotal: 6m 7s\tremaining: 1m 25s\n",
      "568:\tlearn: 0.6413594\ttotal: 6m 8s\tremaining: 1m 24s\n",
      "569:\tlearn: 0.6413485\ttotal: 6m 8s\tremaining: 1m 24s\n",
      "570:\tlearn: 0.6413193\ttotal: 6m 9s\tremaining: 1m 23s\n",
      "571:\tlearn: 0.6412769\ttotal: 6m 10s\tremaining: 1m 22s\n",
      "572:\tlearn: 0.6412378\ttotal: 6m 10s\tremaining: 1m 22s\n",
      "573:\tlearn: 0.6411698\ttotal: 6m 11s\tremaining: 1m 21s\n",
      "574:\tlearn: 0.6411506\ttotal: 6m 12s\tremaining: 1m 20s\n",
      "575:\tlearn: 0.6411440\ttotal: 6m 12s\tremaining: 1m 20s\n",
      "576:\tlearn: 0.6411121\ttotal: 6m 13s\tremaining: 1m 19s\n",
      "577:\tlearn: 0.6409868\ttotal: 6m 14s\tremaining: 1m 18s\n",
      "578:\tlearn: 0.6409514\ttotal: 6m 14s\tremaining: 1m 18s\n",
      "579:\tlearn: 0.6409402\ttotal: 6m 15s\tremaining: 1m 17s\n",
      "580:\tlearn: 0.6407998\ttotal: 6m 16s\tremaining: 1m 17s\n",
      "581:\tlearn: 0.6407783\ttotal: 6m 16s\tremaining: 1m 16s\n",
      "582:\tlearn: 0.6407572\ttotal: 6m 17s\tremaining: 1m 15s\n",
      "583:\tlearn: 0.6407282\ttotal: 6m 17s\tremaining: 1m 15s\n",
      "584:\tlearn: 0.6407088\ttotal: 6m 18s\tremaining: 1m 14s\n",
      "585:\tlearn: 0.6406760\ttotal: 6m 19s\tremaining: 1m 13s\n",
      "586:\tlearn: 0.6406115\ttotal: 6m 19s\tremaining: 1m 13s\n",
      "587:\tlearn: 0.6405881\ttotal: 6m 20s\tremaining: 1m 12s\n",
      "588:\tlearn: 0.6405338\ttotal: 6m 21s\tremaining: 1m 11s\n",
      "589:\tlearn: 0.6405073\ttotal: 6m 21s\tremaining: 1m 11s\n",
      "590:\tlearn: 0.6404865\ttotal: 6m 22s\tremaining: 1m 10s\n",
      "591:\tlearn: 0.6404590\ttotal: 6m 23s\tremaining: 1m 9s\n",
      "592:\tlearn: 0.6403905\ttotal: 6m 23s\tremaining: 1m 9s\n",
      "593:\tlearn: 0.6403673\ttotal: 6m 24s\tremaining: 1m 8s\n",
      "594:\tlearn: 0.6403487\ttotal: 6m 25s\tremaining: 1m 7s\n",
      "595:\tlearn: 0.6403296\ttotal: 6m 25s\tremaining: 1m 7s\n",
      "596:\tlearn: 0.6403077\ttotal: 6m 26s\tremaining: 1m 6s\n",
      "597:\tlearn: 0.6402938\ttotal: 6m 27s\tremaining: 1m 6s\n",
      "598:\tlearn: 0.6402705\ttotal: 6m 27s\tremaining: 1m 5s\n",
      "599:\tlearn: 0.6402551\ttotal: 6m 28s\tremaining: 1m 4s\n",
      "600:\tlearn: 0.6402474\ttotal: 6m 29s\tremaining: 1m 4s\n",
      "601:\tlearn: 0.6401834\ttotal: 6m 29s\tremaining: 1m 3s\n",
      "602:\tlearn: 0.6401676\ttotal: 6m 30s\tremaining: 1m 2s\n",
      "603:\tlearn: 0.6401366\ttotal: 6m 30s\tremaining: 1m 2s\n",
      "604:\tlearn: 0.6401153\ttotal: 6m 31s\tremaining: 1m 1s\n",
      "605:\tlearn: 0.6400994\ttotal: 6m 32s\tremaining: 1m\n",
      "606:\tlearn: 0.6400429\ttotal: 6m 32s\tremaining: 1m\n",
      "607:\tlearn: 0.6400000\ttotal: 6m 33s\tremaining: 59.6s\n",
      "608:\tlearn: 0.6399831\ttotal: 6m 34s\tremaining: 58.9s\n",
      "609:\tlearn: 0.6399492\ttotal: 6m 34s\tremaining: 58.3s\n",
      "610:\tlearn: 0.6399205\ttotal: 6m 35s\tremaining: 57.6s\n",
      "611:\tlearn: 0.6398709\ttotal: 6m 36s\tremaining: 57s\n",
      "612:\tlearn: 0.6398561\ttotal: 6m 36s\tremaining: 56.3s\n",
      "613:\tlearn: 0.6398221\ttotal: 6m 37s\tremaining: 55.7s\n",
      "614:\tlearn: 0.6397498\ttotal: 6m 38s\tremaining: 55s\n",
      "615:\tlearn: 0.6397285\ttotal: 6m 38s\tremaining: 54.4s\n",
      "616:\tlearn: 0.6396956\ttotal: 6m 39s\tremaining: 53.7s\n",
      "617:\tlearn: 0.6396684\ttotal: 6m 40s\tremaining: 53.1s\n",
      "618:\tlearn: 0.6396366\ttotal: 6m 40s\tremaining: 52.4s\n",
      "619:\tlearn: 0.6396151\ttotal: 6m 41s\tremaining: 51.8s\n",
      "620:\tlearn: 0.6395944\ttotal: 6m 42s\tremaining: 51.1s\n",
      "621:\tlearn: 0.6395727\ttotal: 6m 42s\tremaining: 50.5s\n",
      "622:\tlearn: 0.6394948\ttotal: 6m 43s\tremaining: 49.9s\n",
      "623:\tlearn: 0.6394710\ttotal: 6m 43s\tremaining: 49.2s\n",
      "624:\tlearn: 0.6394320\ttotal: 6m 44s\tremaining: 48.6s\n",
      "625:\tlearn: 0.6394041\ttotal: 6m 45s\tremaining: 47.9s\n",
      "626:\tlearn: 0.6393664\ttotal: 6m 45s\tremaining: 47.3s\n",
      "627:\tlearn: 0.6393313\ttotal: 6m 46s\tremaining: 46.6s\n",
      "628:\tlearn: 0.6393099\ttotal: 6m 47s\tremaining: 46s\n",
      "629:\tlearn: 0.6391809\ttotal: 6m 47s\tremaining: 45.3s\n",
      "630:\tlearn: 0.6391465\ttotal: 6m 48s\tremaining: 44.7s\n",
      "631:\tlearn: 0.6391278\ttotal: 6m 49s\tremaining: 44s\n",
      "632:\tlearn: 0.6391073\ttotal: 6m 49s\tremaining: 43.4s\n",
      "633:\tlearn: 0.6390888\ttotal: 6m 50s\tremaining: 42.7s\n",
      "634:\tlearn: 0.6390555\ttotal: 6m 51s\tremaining: 42.1s\n",
      "635:\tlearn: 0.6390387\ttotal: 6m 51s\tremaining: 41.4s\n",
      "636:\tlearn: 0.6390222\ttotal: 6m 52s\tremaining: 40.8s\n",
      "637:\tlearn: 0.6390011\ttotal: 6m 53s\tremaining: 40.1s\n",
      "638:\tlearn: 0.6389852\ttotal: 6m 53s\tremaining: 39.5s\n",
      "639:\tlearn: 0.6389662\ttotal: 6m 54s\tremaining: 38.9s\n",
      "640:\tlearn: 0.6389480\ttotal: 6m 55s\tremaining: 38.2s\n",
      "641:\tlearn: 0.6389269\ttotal: 6m 55s\tremaining: 37.6s\n",
      "642:\tlearn: 0.6388966\ttotal: 6m 56s\tremaining: 36.9s\n",
      "643:\tlearn: 0.6388323\ttotal: 6m 57s\tremaining: 36.3s\n",
      "644:\tlearn: 0.6388044\ttotal: 6m 57s\tremaining: 35.6s\n",
      "645:\tlearn: 0.6387865\ttotal: 6m 58s\tremaining: 35s\n",
      "646:\tlearn: 0.6387346\ttotal: 6m 59s\tremaining: 34.3s\n",
      "647:\tlearn: 0.6387183\ttotal: 6m 59s\tremaining: 33.7s\n",
      "648:\tlearn: 0.6386884\ttotal: 7m\tremaining: 33s\n",
      "649:\tlearn: 0.6386452\ttotal: 7m\tremaining: 32.4s\n",
      "650:\tlearn: 0.6386276\ttotal: 7m 1s\tremaining: 31.7s\n",
      "651:\tlearn: 0.6386104\ttotal: 7m 2s\tremaining: 31.1s\n",
      "652:\tlearn: 0.6385909\ttotal: 7m 2s\tremaining: 30.4s\n",
      "653:\tlearn: 0.6385588\ttotal: 7m 3s\tremaining: 29.8s\n",
      "654:\tlearn: 0.6385488\ttotal: 7m 4s\tremaining: 29.1s\n",
      "655:\tlearn: 0.6384995\ttotal: 7m 4s\tremaining: 28.5s\n",
      "656:\tlearn: 0.6384811\ttotal: 7m 5s\tremaining: 27.8s\n",
      "657:\tlearn: 0.6384597\ttotal: 7m 6s\tremaining: 27.2s\n",
      "658:\tlearn: 0.6384384\ttotal: 7m 6s\tremaining: 26.6s\n",
      "659:\tlearn: 0.6383924\ttotal: 7m 7s\tremaining: 25.9s\n",
      "660:\tlearn: 0.6381476\ttotal: 7m 8s\tremaining: 25.3s\n",
      "661:\tlearn: 0.6380916\ttotal: 7m 8s\tremaining: 24.6s\n",
      "662:\tlearn: 0.6380189\ttotal: 7m 9s\tremaining: 24s\n",
      "663:\tlearn: 0.6379990\ttotal: 7m 10s\tremaining: 23.3s\n",
      "664:\tlearn: 0.6379808\ttotal: 7m 10s\tremaining: 22.7s\n",
      "665:\tlearn: 0.6379613\ttotal: 7m 11s\tremaining: 22s\n",
      "666:\tlearn: 0.6379392\ttotal: 7m 11s\tremaining: 21.4s\n",
      "667:\tlearn: 0.6379019\ttotal: 7m 12s\tremaining: 20.7s\n",
      "668:\tlearn: 0.6378543\ttotal: 7m 13s\tremaining: 20.1s\n",
      "669:\tlearn: 0.6378144\ttotal: 7m 13s\tremaining: 19.4s\n",
      "670:\tlearn: 0.6377908\ttotal: 7m 14s\tremaining: 18.8s\n",
      "671:\tlearn: 0.6377466\ttotal: 7m 15s\tremaining: 18.1s\n",
      "672:\tlearn: 0.6377109\ttotal: 7m 15s\tremaining: 17.5s\n",
      "673:\tlearn: 0.6376929\ttotal: 7m 16s\tremaining: 16.8s\n",
      "674:\tlearn: 0.6376477\ttotal: 7m 17s\tremaining: 16.2s\n",
      "675:\tlearn: 0.6376055\ttotal: 7m 17s\tremaining: 15.5s\n",
      "676:\tlearn: 0.6375916\ttotal: 7m 18s\tremaining: 14.9s\n",
      "677:\tlearn: 0.6375670\ttotal: 7m 19s\tremaining: 14.2s\n",
      "678:\tlearn: 0.6374161\ttotal: 7m 19s\tremaining: 13.6s\n",
      "679:\tlearn: 0.6374058\ttotal: 7m 20s\tremaining: 13s\n",
      "680:\tlearn: 0.6373530\ttotal: 7m 21s\tremaining: 12.3s\n",
      "681:\tlearn: 0.6373194\ttotal: 7m 21s\tremaining: 11.7s\n",
      "682:\tlearn: 0.6372895\ttotal: 7m 22s\tremaining: 11s\n",
      "683:\tlearn: 0.6372061\ttotal: 7m 22s\tremaining: 10.4s\n",
      "684:\tlearn: 0.6371848\ttotal: 7m 23s\tremaining: 9.71s\n",
      "685:\tlearn: 0.6371561\ttotal: 7m 24s\tremaining: 9.07s\n",
      "686:\tlearn: 0.6371440\ttotal: 7m 24s\tremaining: 8.42s\n",
      "687:\tlearn: 0.6371339\ttotal: 7m 25s\tremaining: 7.77s\n",
      "688:\tlearn: 0.6371197\ttotal: 7m 26s\tremaining: 7.12s\n",
      "689:\tlearn: 0.6370702\ttotal: 7m 26s\tremaining: 6.47s\n",
      "690:\tlearn: 0.6370455\ttotal: 7m 27s\tremaining: 5.83s\n",
      "691:\tlearn: 0.6369204\ttotal: 7m 28s\tremaining: 5.18s\n",
      "692:\tlearn: 0.6368838\ttotal: 7m 28s\tremaining: 4.53s\n",
      "693:\tlearn: 0.6368633\ttotal: 7m 29s\tremaining: 3.88s\n",
      "694:\tlearn: 0.6367925\ttotal: 7m 30s\tremaining: 3.24s\n",
      "695:\tlearn: 0.6367439\ttotal: 7m 30s\tremaining: 2.59s\n",
      "696:\tlearn: 0.6367326\ttotal: 7m 31s\tremaining: 1.94s\n",
      "697:\tlearn: 0.6367122\ttotal: 7m 32s\tremaining: 1.29s\n",
      "698:\tlearn: 0.6366958\ttotal: 7m 32s\tremaining: 648ms\n",
      "699:\tlearn: 0.6366784\ttotal: 7m 33s\tremaining: 0us\n",
      "train score: 0.824449 (+/-0.006048)\n",
      "valid score: 0.594177 (+/-0.001094)\n",
      "best params: {'depth': 12, 'learning_rate': 0.01, 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "param_grid_cat = {\n",
    "    'learning_rate' : [0.01], \n",
    "    'n_estimators' : [700],\n",
    "    'depth' : [12]\n",
    "}\n",
    "\n",
    "if (1):\n",
    "    best_cat_params, best_cat_estimator, best_cat_valid= grid_search_cv(cat_transformer, df_train_x, df_train_y, pipeline_cat, param_grid_cat, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-3-2. Training for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     catboost \u001b[39m=\u001b[39m Pipeline([(\u001b[39m'\u001b[39m\u001b[39mct\u001b[39m\u001b[39m'\u001b[39m, cat_transformer),(\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, CatBoostClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams_static_cat))])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m _ \u001b[39m=\u001b[39m training(df_train_x, df_train_y, catboost)\n",
      "\u001b[1;32m/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb Cell 35\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining\u001b[39m(X_train, y_train, clf):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     score \u001b[39m=\u001b[39m cross_validate(clf, X_train, y_train, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m, return_train_score\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_estimator\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain score: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m (+/-\u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         np\u001b[39m.\u001b[39mmean(score[\u001b[39m'\u001b[39m\u001b[39mtrain_score\u001b[39m\u001b[39m'\u001b[39m]), np\u001b[39m.\u001b[39mstd(score[\u001b[39m'\u001b[39m\u001b[39mtrain_score\u001b[39m\u001b[39m'\u001b[39m])))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mvalid score: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m (+/-\u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249433531227d/users/student/mr111/mfhsieh22/NTHU_Course/NTHU-Deep-Learning/Competition/DataLab_Cup1_Text_Feature_Engineering/src/Text_Feature_Engineering.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         np\u001b[39m.\u001b[39mmean(score[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]), np\u001b[39m.\u001b[39mstd(score[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m])))\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5101\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5102\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_static_cat = {\n",
    "    'eval_metric' : 'AUC',\n",
    "    'n_estimators' : 700,\n",
    "    'depth' : 12,\n",
    "    'learning_rate' : 0.01,\n",
    "    'random_state' : 0,\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    catboost = Pipeline([('ct', cat_transformer),('clf', best_cat_estimator)])\n",
    "else :\n",
    "    catboost = Pipeline([('ct', cat_transformer),('clf', CatBoostClassifier(**params_static_cat))])\n",
    "\n",
    "_ = training(df_train_x, df_train_y, catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-4-1. Grid sizing for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END estimator__max_depth=4, learning_rate=0.001, n_estimators=1500, random_state=0;, score=(train=0.646, test=0.588) total time=16.6min\n",
      "[CV 1/2] END estimator__max_depth=4, learning_rate=0.001, n_estimators=1500, random_state=0;, score=(train=0.662, test=0.584) total time=17.2min\n",
      "train score: 0.654205 (+/-0.008009)\n",
      "valid score: 0.586208 (+/-0.002057)\n",
      "best params: {'estimator__max_depth': 4, 'learning_rate': 0.001, 'n_estimators': 1500, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "params_grid_ada = {\n",
    "    'estimator__max_depth' : [4],\n",
    "    'n_estimators': [1500],\n",
    "    'learning_rate': [0.001],\n",
    "    'random_state' : [0]\n",
    "}\n",
    "\n",
    "if (1):\n",
    "    best_ada_params, best_ada_estimator, best_ada_valid = grid_search_cv(ada_transformer, df_train_x, df_train_y, pipeline_ada, params_grid_ada, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-4-2. Training for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.655976 (+/-0.004430)\n",
      "valid score: 0.581028 (+/-0.002394)\n"
     ]
    }
   ],
   "source": [
    "param_static_ada = {\n",
    "    'estimator' : DecisionTreeClassifier(max_depth = 4), \n",
    "    'learning_rate' : 0.001, \n",
    "    'n_estimators' : 1560\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    adaBoost = Pipeline([('vect', ada_transformer), ('clf', best_ada_estimator)])\n",
    "else :\n",
    "    adaBoost = Pipeline([('vect', ada_transformer), ('clf', AdaBoostClassifier(**param_static_ada))])\n",
    "    \n",
    "_ = training(df_train_x, df_train_y, adaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-5-1. Grid sizing for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END max_depth=90, min_samples_leaf=1, n_estimators=1150;, score=(train=0.998, test=0.578) total time= 6.4min\n",
      "[CV 2/2] END max_depth=90, min_samples_leaf=1, n_estimators=1150;, score=(train=0.999, test=0.578) total time= 6.6min\n",
      "train score: 0.998176 (+/-0.000360)\n",
      "valid score: 0.577714 (+/-0.000072)\n",
      "best params: {'max_depth': 90, 'min_samples_leaf': 1, 'n_estimators': 1150}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params_grid_rf = {\n",
    "    'n_estimators' : [1150],\n",
    "    'max_depth' : [90],\n",
    "    'min_samples_leaf' : [1]\n",
    "}\n",
    "\n",
    "if (1):\n",
    "    best_RF_params, best_RF_estimator, best_RF_valid = grid_search_cv(rfc_transformer, df_train_x, df_train_y, pipeline_rfc, params_grid_rf, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-5-2. Training for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.999345 (+/-0.000056)\n",
      "valid score: 0.573417 (+/-0.000696)\n"
     ]
    }
   ],
   "source": [
    "params_static_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 0,\n",
    "    'n_estimators' : 1200,\n",
    "    'max_depth' : 100,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    RF = Pipeline([('vect', rfc_transformer), ('clf', best_RF_estimator)])\n",
    "else :\n",
    "    RF = Pipeline([('vect', rfc_transformer), ('clf', RandomForestClassifier(**params_static_rf))])\n",
    "\n",
    "_ = training(df_train_x, df_train_y, RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-6. VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-1. Grid sizing for Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_static_xgb = {\n",
    "    'gamma' : 1.2,\n",
    "    'lambda' : 2.5,\n",
    "    'n_estimators': 97,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate' : 0.141,\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 0\n",
    "}\n",
    "\n",
    "params_static_LGBM = {\n",
    "    'random_state': 0, \n",
    "    'learning_rate' : 0.013,\n",
    "    'n_estimators' : 230,\n",
    "    'n_jobs' : -1,\n",
    "    'objective' : 'poisson'\n",
    "}\n",
    "\n",
    "params_static_cat = {\n",
    "    'eval_metric' : 'AUC',\n",
    "    'n_estimators' : 700,\n",
    "    'depth' : 12,\n",
    "    'learning_rate' : 0.01,\n",
    "    'random_state' : 0,\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "param_static_Adaboost = {\n",
    "    'estimator' : DecisionTreeClassifier(max_depth = 4), \n",
    "    'learning_rate' : 0.001, \n",
    "    'n_estimators' : 1560\n",
    "}\n",
    "\n",
    "param_static_RF = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 0,\n",
    "    'n_estimators' : 1200,\n",
    "    'max_depth' : 100,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "\n",
    "voting_pipeline_xgb = Pipeline([('vect', xgb_transformer), ('clf', XGBClassifier(**param_static_xgb))])\n",
    "voting_pipeline_lgb = Pipeline([('vect', lgb_transformer), ('clf',  LGBMClassifier(**params_static_LGBM))])\n",
    "voting_pipeline_cat = Pipeline([('vect', cat_transformer), ('clf',  CatBoostClassifier(**params_static_cat))])\n",
    "voting_pipeline_ada = Pipeline([('vect', ada_transformer), ('clf',  AdaBoostClassifier(**param_static_Adaboost))])\n",
    "voting_pipeline_rfc = Pipeline([('vect', rfc_transformer), ('clf',  RandomForestClassifier(**param_static_RF))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifier = 2\n",
    "# voting_estimator_list = [('pip1', pipeline_xgb), ('pip2', pipeline_lgb), ('pip3', pipeline_cat)]\n",
    "voting_estimator_list = [('pip1', pipeline_xgb), ('pip2', pipeline_lgb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to find the weight combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_list_generator(num_classifier_):   \n",
    "    weight_list = []\n",
    "\n",
    "    binary_values = (1, 3, 5)\n",
    "    weight_list = [list(i) for i in list(itertools.product(binary_values, repeat=num_classifier_))]\n",
    "\n",
    "    print('weight list = ', weight_list)\n",
    "    print('length of weight list = ', len(weight_list))\n",
    "    return weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight list =  [[1, 1], [1, 3], [1, 5], [3, 1], [3, 3], [3, 5], [5, 1], [5, 3], [5, 5]]\n",
      "length of weight list =  9\n"
     ]
    }
   ],
   "source": [
    "weight_list = weight_list_generator(num_classifier_ = num_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* multi-thread grid search for voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-5 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-6 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-7 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "Exception in thread Thread-8 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-9 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "Exception in thread Thread-10 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-11 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "Exception in thread Thread-12 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_130144/152208348.py\", line 17, in process_weight\n",
      "NameError: name 'X_voting_train' is not defined\n",
      "NameError: name 'X_voting_train' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current weight = [1, 1]\n",
      "current weight = [1, 3]\n",
      "current weight = [1, 5]\n",
      "current weight = [3, 1]\n",
      "current weight = [3, 3]\n",
      "current weight = [3, 5]\n",
      "current weight = [5, 1]\n",
      "current weight = [5, 3]\n",
      "current weight = [5, 5]\n",
      "end once\n",
      "best_valid_score = 0.000000\n",
      "best_weight =  None\n"
     ]
    }
   ],
   "source": [
    "param_grid_voting_static = {\n",
    "    'estimators' : voting_estimator_list,\n",
    "    'voting' : 'soft',\n",
    "    'flatten_transform' : True, \n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_weight(weight):\n",
    "    # share in multiple threads\n",
    "    global best_valid_score, best_weight, best_voting\n",
    "\n",
    "    voting = Pipeline([('vect', voting_transformer), ('clf', VotingClassifier(**prarms_static_voting, weights=weight))])\n",
    "    print('current weight =', weight)\n",
    "    clf_voting, _, valid_voting = training(df_train_x, df_train_y, voting)\n",
    "\n",
    "    # to protect the safety of shared variables\n",
    "    with lock:\n",
    "        if valid_voting > best_valid_score:\n",
    "            best_valid_score = valid_voting\n",
    "            best_weight = weight\n",
    "            best_voting = clf_voting\n",
    "    \n",
    "    print(f'{weight} Finish!!')\n",
    "    threadmax.release()\n",
    "        \n",
    "if (1):\n",
    "    best_valid_score = 0\n",
    "    best_weight = None\n",
    "    best_voting = None\n",
    "    mem = []\n",
    "    threadmax = threading.BoundedSemaphore(32)\n",
    "    \n",
    "    for weight in weight_list:\n",
    "        threadmax.acquire()\n",
    "        thread = threading.Thread(target=process_weight, args=(weight,))\n",
    "    \n",
    "        thread.start()\n",
    "        mem.append(thread)\n",
    "\n",
    "    for thread in mem:\n",
    "        thread.join()\n",
    "        mem.remove(thread)\n",
    "    \n",
    "    print('end once')\n",
    "\n",
    "    print('best_valid_score = %.6f' % best_valid_score)\n",
    "    print('best_weight = ', best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (1 of 2) Processing pip1, total=   2.2s\n",
      "[Voting] ..................... (2 of 2) Processing pip2, total=   1.4s\n",
      "[Voting] ..................... (1 of 2) Processing pip1, total=   2.1s\n",
      "[Voting] ..................... (2 of 2) Processing pip2, total=   1.4s\n",
      "train score: 0.887048 (+/-0.003507)\n",
      "valid score: 0.573097 (+/-0.001854)\n",
      "[Voting] ..................... (1 of 2) Processing pip1, total=   4.0s\n",
      "[Voting] ..................... (2 of 2) Processing pip2, total=   2.7s\n"
     ]
    }
   ],
   "source": [
    "# no n_jobs\n",
    "prarms_static_voting = {\n",
    "    'estimators' : voting_estimator_list, \n",
    "    'voting' : 'soft',\n",
    "    'weights' : [1, 2],\n",
    "    'flatten_transform' : True,\n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "if (0):\n",
    "    voting = Pipeline([('vect', voting_transformer), ('clf', VotingClassifier(**param_grid_voting_static, weights=best_weight))])\n",
    "    \n",
    "else :\n",
    "    voting = Pipeline([('vect', voting_transformer), ('clf', VotingClassifier(**prarms_static_voting))])\n",
    "\n",
    "_ = training(df_train_x, df_train_y, voting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = voting\n",
    "\n",
    "y_score = best_model.predict_proba(df_test_x)[:, 1]\n",
    "\n",
    "df_pred = pd.DataFrame({'Id': test_data['Id'], 'Popularity': y_score})\n",
    "df_pred.to_csv('../output/test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
